{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time,glob,sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "\n",
    "from model import U_Net_Generator\n",
    "from model import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(0)\n",
    "os.environ[\"CUDA_VISIBILE_DEVICES\"] = '0,1,2'\n",
    "\n",
    "G_output_path = ('./G_checkpoint/')\n",
    "D_output_path = ('./D_checkpoint/')\n",
    "\n",
    "if not os.path.exists(G_output_path):\n",
    "    os.makedirs(G_output_path)\n",
    "\n",
    "if not os.path.exists(D_output_path):\n",
    "    os.makedirs(D_output_path)    \n",
    "    \n",
    "#history_file = ('./history/history.pth')\n",
    "dataset_dir = ('../train2D3D/train/')\n",
    "   \n",
    "input_list = sorted(glob.glob(os.path.join(dataset_dir, \"input/*.npy\")))\n",
    "output_list = sorted(glob.glob(os.path.join(dataset_dir, \"output/*.npy\")))\n",
    "#print(input_list)\n",
    "#print(output_list)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(input_list, output_list, test_size=0.11,random_state=35)\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(X_train)\n",
    "train_data = Dataset3d(X_train,y_train)\n",
    "valid_data = Dataset3d(X_valid,y_valid)\n",
    "\n",
    "#A = train_data.__getitem__(1)\n",
    "#print(A[0])\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, verbose=True, result_dir=model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,841,949 total parameter.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "epochs = 100\n",
    "\n",
    "D = Discriminator().cuda()\n",
    "G = U_Net_Generator().cuda()\n",
    "D = nn.DataParallel(D,device_ids=[0,1,2])\n",
    "G = nn.DataParallel(G,device_ids=[0,1,2])\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=1e-4 ,weight_decay=1e-6)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4 ,weight_decay=1e-6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss().cuda()\n",
    "\n",
    "#total_params = sum(p.numel() for p in model.parameters())\n",
    "#print(f'{total_params:,} total parameter.')\n",
    "\n",
    "dataloader_train = DataLoader(train_data,batch_size,shuffle=True)\n",
    "dataloader_valid = DataLoader(valid_data,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no saved model, train from scratch\n",
      "Epoch: 0 Iter 19 Train_loss: 0.003860319731757045\n",
      "Epoch: 0 Iter 39 Train_loss: 0.002400939352810383\n",
      "Epoch: 0 Iter 59 Train_loss: 0.001738624065183103\n",
      "Epoch: 0 Iter 79 Train_loss: 0.0018319766968488693\n",
      "Epoch: 0 Iter 99 Train_loss: 0.0011994453379884362\n",
      "Epoch: 0 Iter 119 Train_loss: 0.0010930723510682583\n",
      "Epoch: 0 Iter 139 Train_loss: 0.001053541898727417\n",
      "Epoch: 0 Iter 159 Train_loss: 0.001280846307054162\n",
      "Epoch: 0 Iter 179 Train_loss: 0.0009932882385328412\n",
      "Epoch: 0 Iter 199 Train_loss: 0.0008485711296088994\n",
      "Epoch: 0 Iter 219 Train_loss: 0.0010615827050060034\n",
      "Epoch: 0 Iter 239 Train_loss: 0.000733082415536046\n",
      "Epoch: 0 Iter 259 Train_loss: 0.0007653427892364562\n",
      "Epoch: 0 Iter 279 Train_loss: 0.0007625942234881222\n",
      "Epoch: 0 Iter 299 Train_loss: 0.0006758671370334923\n",
      "Epoch: 0 Iter 319 Train_loss: 0.000746016507036984\n",
      "Epoch: 0 Iter 339 Train_loss: 0.0007792756077833474\n",
      "Epoch: 0 Iter 359 Train_loss: 0.0006829961785115302\n",
      "Epoch: 0 Iter 379 Train_loss: 0.0007704853196628392\n",
      "Epoch: 0 Iter 399 Train_loss: 0.0006720490055158734\n",
      "Epoch: 0 Iter 419 Train_loss: 0.0006731173489242792\n",
      "Epoch: 0 Iter 439 Train_loss: 0.0007208180031739175\n",
      "Epoch: 0 Iter 459 Train_loss: 0.0006925315828993917\n",
      "Epoch: 0 Iter 479 Train_loss: 0.0006058652652427554\n",
      "Epoch: 0 Iter 499 Train_loss: 0.0005440505919978023\n",
      "Epoch: 0 Iter 519 Train_loss: 0.0007633065106347203\n",
      "Epoch: 0 Iter 539 Train_loss: 0.0008821882074698806\n",
      "Epoch: 0 Iter 559 Train_loss: 0.0005862729158252478\n",
      "Epoch: 0 Iter 579 Train_loss: 0.0005818482022732496\n",
      "Epoch: 0 Iter 599 Train_loss: 0.0005929877515882254\n",
      "Epoch: 0 Iter 619 Train_loss: 0.0005897203809581697\n",
      "Epoch: 0 Iter 639 Train_loss: 0.0005873733316548169\n",
      "Epoch: 0 Iter 659 Train_loss: 0.0006166197126731277\n",
      "Epoch: 0 Iter 679 Train_loss: 0.000570292875636369\n",
      "Epoch: 0 Iter 699 Train_loss: 0.0005566971958614886\n",
      "Epoch: 0 Iter 719 Train_loss: 0.0007139669614844024\n",
      "Epoch: 0 Iter 739 Train_loss: 0.0005633070832118392\n",
      "Epoch: 0 Iter 759 Train_loss: 0.0005616479320451617\n",
      "Epoch: 0 Iter 779 Train_loss: 0.0005362899973988533\n",
      "Epoch: 0 Iter 799 Train_loss: 0.0005341451033018529\n",
      "Epoch: 0 Iter 819 Train_loss: 0.0004994327900931239\n",
      "Epoch: 0 Iter 839 Train_loss: 0.00042430043686181307\n",
      "Epoch: 0 Iter 859 Train_loss: 0.00045464825234375894\n",
      "Epoch: 0 Iter 879 Train_loss: 0.0005037646624259651\n",
      "Epoch: 0 Iter 899 Train_loss: 0.0004677780088968575\n",
      "Epoch: 0 Iter 919 Train_loss: 0.0004898429615423083\n",
      "Epoch: 0 Iter 939 Train_loss: 0.00047066330444067717\n",
      "Epoch: 0 Iter 959 Train_loss: 0.0004886247334070504\n",
      "Epoch: 0 Iter 979 Train_loss: 0.0006050879019312561\n",
      "Epoch: 0 Iter 999 Train_loss: 0.0004876873572356999\n",
      "Epoch: 0 Iter 1019 Train_loss: 0.00048124007298611104\n",
      "Epoch: 0 Iter 1039 Train_loss: 0.0005093802465125918\n",
      "Epoch: 0 Iter 1059 Train_loss: 0.000450819730758667\n",
      "[  0/100]train_loss:0.00122valid_loss:0.00050\n",
      "Validation loss decreased (inf --> 0.000500).  Saving model ...\n",
      "Epoch: 1 Iter 19 Train_loss: 0.0005310785491019487\n",
      "Epoch: 1 Iter 39 Train_loss: 0.0006590954726561904\n",
      "Epoch: 1 Iter 59 Train_loss: 0.000417233764892444\n",
      "Epoch: 1 Iter 79 Train_loss: 0.0004720496363006532\n",
      "Epoch: 1 Iter 99 Train_loss: 0.0005763423396274447\n",
      "Epoch: 1 Iter 119 Train_loss: 0.0004877032188232988\n",
      "Epoch: 1 Iter 139 Train_loss: 0.0005052135093137622\n",
      "Epoch: 1 Iter 159 Train_loss: 0.0005962280556559563\n",
      "Epoch: 1 Iter 179 Train_loss: 0.0004325701156631112\n",
      "Epoch: 1 Iter 199 Train_loss: 0.00046821468276903033\n",
      "Epoch: 1 Iter 219 Train_loss: 0.0005350494175218046\n",
      "Epoch: 1 Iter 239 Train_loss: 0.00045765453251078725\n",
      "Epoch: 1 Iter 259 Train_loss: 0.0004494791501201689\n",
      "Epoch: 1 Iter 279 Train_loss: 0.0004132570466026664\n",
      "Epoch: 1 Iter 299 Train_loss: 0.0005698786117136478\n",
      "Epoch: 1 Iter 319 Train_loss: 0.00048078803229145706\n",
      "Epoch: 1 Iter 339 Train_loss: 0.0005300664342939854\n",
      "Epoch: 1 Iter 359 Train_loss: 0.0003984884242527187\n",
      "Epoch: 1 Iter 379 Train_loss: 0.0004876613093074411\n",
      "Epoch: 1 Iter 399 Train_loss: 0.00042825762648135424\n",
      "Epoch: 1 Iter 419 Train_loss: 0.0003833652881439775\n",
      "Epoch: 1 Iter 439 Train_loss: 0.00044288646313361824\n",
      "Epoch: 1 Iter 459 Train_loss: 0.00047969582374207675\n",
      "Epoch: 1 Iter 479 Train_loss: 0.0004372734983917326\n",
      "Epoch: 1 Iter 499 Train_loss: 0.00040585987153463066\n",
      "Epoch: 1 Iter 519 Train_loss: 0.0006048565846867859\n",
      "Epoch: 1 Iter 539 Train_loss: 0.0004083979583811015\n",
      "Epoch: 1 Iter 559 Train_loss: 0.00045335094910115004\n",
      "Epoch: 1 Iter 579 Train_loss: 0.0004891593125648797\n",
      "Epoch: 1 Iter 599 Train_loss: 0.00038342815241776407\n",
      "Epoch: 1 Iter 619 Train_loss: 0.0004531089507509023\n",
      "Epoch: 1 Iter 639 Train_loss: 0.00044859034824185073\n",
      "Epoch: 1 Iter 659 Train_loss: 0.0005643082549795508\n",
      "Epoch: 1 Iter 679 Train_loss: 0.00041538215009495616\n",
      "Epoch: 1 Iter 699 Train_loss: 0.000427098450018093\n",
      "Epoch: 1 Iter 719 Train_loss: 0.0004850227851420641\n",
      "Epoch: 1 Iter 739 Train_loss: 0.0003945556818507612\n",
      "Epoch: 1 Iter 759 Train_loss: 0.0004278913838788867\n",
      "Epoch: 1 Iter 779 Train_loss: 0.000405517581384629\n",
      "Epoch: 1 Iter 799 Train_loss: 0.0006709592998959124\n",
      "Epoch: 1 Iter 819 Train_loss: 0.0004986599669791758\n",
      "Epoch: 1 Iter 839 Train_loss: 0.0003632612060755491\n",
      "Epoch: 1 Iter 859 Train_loss: 0.0003739972016774118\n",
      "Epoch: 1 Iter 879 Train_loss: 0.0005084715085104108\n",
      "Epoch: 1 Iter 899 Train_loss: 0.00041962519753724337\n",
      "Epoch: 1 Iter 919 Train_loss: 0.0005374179454520345\n",
      "Epoch: 1 Iter 939 Train_loss: 0.0004481702926568687\n",
      "Epoch: 1 Iter 959 Train_loss: 0.0003574382863007486\n",
      "Epoch: 1 Iter 979 Train_loss: 0.0004338158469181508\n",
      "Epoch: 1 Iter 999 Train_loss: 0.00040046064532361925\n",
      "Epoch: 1 Iter 1019 Train_loss: 0.0003680841764435172\n",
      "Epoch: 1 Iter 1039 Train_loss: 0.00043000251753255725\n",
      "Epoch: 1 Iter 1059 Train_loss: 0.00043973824358545244\n",
      "[  1/100]train_loss:0.00047valid_loss:0.00045\n",
      "Validation loss decreased (0.000500 --> 0.000453).  Saving model ...\n",
      "Epoch: 2 Iter 19 Train_loss: 0.00043015021947212517\n",
      "Epoch: 2 Iter 39 Train_loss: 0.00038029791903682053\n",
      "Epoch: 2 Iter 59 Train_loss: 0.00036306976107880473\n",
      "Epoch: 2 Iter 79 Train_loss: 0.0003564748913049698\n",
      "Epoch: 2 Iter 99 Train_loss: 0.00037299629184417427\n",
      "Epoch: 2 Iter 119 Train_loss: 0.0004187237354926765\n",
      "Epoch: 2 Iter 139 Train_loss: 0.00036847975570708513\n",
      "Epoch: 2 Iter 159 Train_loss: 0.00044711510417982936\n",
      "Epoch: 2 Iter 179 Train_loss: 0.0004933541640639305\n",
      "Epoch: 2 Iter 199 Train_loss: 0.0005170837393961847\n",
      "Epoch: 2 Iter 219 Train_loss: 0.0004215981753077358\n",
      "Epoch: 2 Iter 239 Train_loss: 0.0003568233223631978\n",
      "Epoch: 2 Iter 259 Train_loss: 0.0006222408264875412\n",
      "Epoch: 2 Iter 279 Train_loss: 0.0004264980088919401\n",
      "Epoch: 2 Iter 299 Train_loss: 0.0004959420184604824\n",
      "Epoch: 2 Iter 319 Train_loss: 0.00040051175164990127\n",
      "Epoch: 2 Iter 339 Train_loss: 0.00043178131454624236\n",
      "Epoch: 2 Iter 359 Train_loss: 0.0004276512481737882\n",
      "Epoch: 2 Iter 379 Train_loss: 0.00035504173138178885\n",
      "Epoch: 2 Iter 399 Train_loss: 0.0004931383882649243\n",
      "Epoch: 2 Iter 419 Train_loss: 0.0004155502829235047\n",
      "Epoch: 2 Iter 439 Train_loss: 0.0004192829073872417\n",
      "Epoch: 2 Iter 459 Train_loss: 0.0004586401046253741\n",
      "Epoch: 2 Iter 479 Train_loss: 0.0003685886331368238\n",
      "Epoch: 2 Iter 499 Train_loss: 0.00038526373100467026\n",
      "Epoch: 2 Iter 519 Train_loss: 0.00042185778147540987\n",
      "Epoch: 2 Iter 539 Train_loss: 0.0004635543446056545\n",
      "Epoch: 2 Iter 559 Train_loss: 0.0005090075428597629\n",
      "Epoch: 2 Iter 579 Train_loss: 0.0003946447977796197\n",
      "Epoch: 2 Iter 599 Train_loss: 0.00047282749437727034\n",
      "Epoch: 2 Iter 619 Train_loss: 0.00036221495247446\n",
      "Epoch: 2 Iter 639 Train_loss: 0.0003491202078294009\n",
      "Epoch: 2 Iter 659 Train_loss: 0.0004930715658701956\n",
      "Epoch: 2 Iter 679 Train_loss: 0.00038277162821032107\n",
      "Epoch: 2 Iter 699 Train_loss: 0.0004150578170083463\n",
      "Epoch: 2 Iter 719 Train_loss: 0.0004048855626024306\n",
      "Epoch: 2 Iter 739 Train_loss: 0.0003998595930170268\n",
      "Epoch: 2 Iter 759 Train_loss: 0.0004483160737436265\n",
      "Epoch: 2 Iter 779 Train_loss: 0.0003861961595248431\n",
      "Epoch: 2 Iter 799 Train_loss: 0.0004710483772214502\n",
      "Epoch: 2 Iter 819 Train_loss: 0.00040780947892926633\n",
      "Epoch: 2 Iter 839 Train_loss: 0.0003245631232857704\n",
      "Epoch: 2 Iter 859 Train_loss: 0.0004226529854349792\n",
      "Epoch: 2 Iter 879 Train_loss: 0.00036503697629086673\n",
      "Epoch: 2 Iter 899 Train_loss: 0.00039557565469294786\n",
      "Epoch: 2 Iter 919 Train_loss: 0.00042065075831487775\n",
      "Epoch: 2 Iter 939 Train_loss: 0.0004237213870510459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Iter 959 Train_loss: 0.00036649464163929224\n",
      "Epoch: 2 Iter 979 Train_loss: 0.00042932346696034074\n",
      "Epoch: 2 Iter 999 Train_loss: 0.00039318008930422366\n",
      "Epoch: 2 Iter 1019 Train_loss: 0.00036267799441702664\n",
      "Epoch: 2 Iter 1039 Train_loss: 0.0005297793541103601\n",
      "Epoch: 2 Iter 1059 Train_loss: 0.0003707322757691145\n",
      "[  2/100]train_loss:0.00041valid_loss:0.00041\n",
      "Validation loss decreased (0.000453 --> 0.000413).  Saving model ...\n",
      "Epoch: 3 Iter 19 Train_loss: 0.0003464403562247753\n",
      "Epoch: 3 Iter 39 Train_loss: 0.0004074102034792304\n",
      "Epoch: 3 Iter 59 Train_loss: 0.00035100162494927645\n",
      "Epoch: 3 Iter 79 Train_loss: 0.0003288763982709497\n",
      "Epoch: 3 Iter 99 Train_loss: 0.00037121440982446074\n",
      "Epoch: 3 Iter 119 Train_loss: 0.000359410943929106\n",
      "Epoch: 3 Iter 139 Train_loss: 0.00035293822293169796\n",
      "Epoch: 3 Iter 159 Train_loss: 0.0003687366843223572\n",
      "Epoch: 3 Iter 179 Train_loss: 0.0003765181463677436\n",
      "Epoch: 3 Iter 199 Train_loss: 0.000399526470573619\n",
      "Epoch: 3 Iter 219 Train_loss: 0.00037063605850562453\n",
      "Epoch: 3 Iter 239 Train_loss: 0.0005128135671839118\n",
      "Epoch: 3 Iter 259 Train_loss: 0.0003593068104237318\n",
      "Epoch: 3 Iter 279 Train_loss: 0.00036139992880634964\n",
      "Epoch: 3 Iter 299 Train_loss: 0.00044410830014385283\n",
      "Epoch: 3 Iter 319 Train_loss: 0.0004502470255829394\n",
      "Epoch: 3 Iter 339 Train_loss: 0.0003776462108362466\n",
      "Epoch: 3 Iter 359 Train_loss: 0.00040825270116329193\n",
      "Epoch: 3 Iter 379 Train_loss: 0.00034435518318787217\n",
      "Epoch: 3 Iter 399 Train_loss: 0.00037541190977208316\n",
      "Epoch: 3 Iter 419 Train_loss: 0.0004347096255514771\n",
      "Epoch: 3 Iter 439 Train_loss: 0.00038777891313657165\n",
      "Epoch: 3 Iter 459 Train_loss: 0.0004260527202859521\n",
      "Epoch: 3 Iter 479 Train_loss: 0.0003306854923721403\n",
      "Epoch: 3 Iter 499 Train_loss: 0.0004105706175323576\n",
      "Epoch: 3 Iter 519 Train_loss: 0.00036680843913927674\n",
      "Epoch: 3 Iter 539 Train_loss: 0.0003392419312149286\n",
      "Epoch: 3 Iter 559 Train_loss: 0.00041958424844779074\n",
      "Epoch: 3 Iter 579 Train_loss: 0.00038321572355926037\n",
      "Epoch: 3 Iter 599 Train_loss: 0.00041826008236967027\n",
      "Epoch: 3 Iter 619 Train_loss: 0.00032106920843943954\n",
      "Epoch: 3 Iter 639 Train_loss: 0.00038121925899758935\n",
      "Epoch: 3 Iter 659 Train_loss: 0.0003208939451724291\n",
      "Epoch: 3 Iter 679 Train_loss: 0.0003798839170485735\n",
      "Epoch: 3 Iter 699 Train_loss: 0.00034522844362072647\n",
      "Epoch: 3 Iter 719 Train_loss: 0.000392958230804652\n",
      "Epoch: 3 Iter 739 Train_loss: 0.0004122560494579375\n",
      "Epoch: 3 Iter 759 Train_loss: 0.0003721701505128294\n",
      "Epoch: 3 Iter 779 Train_loss: 0.00037532762507908046\n",
      "Epoch: 3 Iter 799 Train_loss: 0.0004948780406266451\n",
      "Epoch: 3 Iter 819 Train_loss: 0.0003932351537514478\n",
      "Epoch: 3 Iter 839 Train_loss: 0.00035922747338190675\n",
      "Epoch: 3 Iter 859 Train_loss: 0.0003673675237223506\n",
      "Epoch: 3 Iter 879 Train_loss: 0.0003747666487470269\n",
      "Epoch: 3 Iter 899 Train_loss: 0.0003531971597112715\n",
      "Epoch: 3 Iter 919 Train_loss: 0.00040519025060348213\n",
      "Epoch: 3 Iter 939 Train_loss: 0.0003651101142168045\n",
      "Epoch: 3 Iter 959 Train_loss: 0.0003499540616758168\n",
      "Epoch: 3 Iter 979 Train_loss: 0.0003537102311383933\n",
      "Epoch: 3 Iter 999 Train_loss: 0.00041499585495330393\n",
      "Epoch: 3 Iter 1019 Train_loss: 0.00041443220106884837\n",
      "Epoch: 3 Iter 1039 Train_loss: 0.0003350779879838228\n",
      "Epoch: 3 Iter 1059 Train_loss: 0.0004087601264473051\n",
      "[  3/100]train_loss:0.00038valid_loss:0.00039\n",
      "Validation loss decreased (0.000413 --> 0.000387).  Saving model ...\n",
      "Epoch: 4 Iter 19 Train_loss: 0.00037007915670983493\n",
      "Epoch: 4 Iter 39 Train_loss: 0.00040516682201996446\n",
      "Epoch: 4 Iter 59 Train_loss: 0.00035439422936178744\n",
      "Epoch: 4 Iter 79 Train_loss: 0.0003628095437306911\n",
      "Epoch: 4 Iter 99 Train_loss: 0.00033947778865695\n",
      "Epoch: 4 Iter 119 Train_loss: 0.00040030412492342293\n",
      "Epoch: 4 Iter 139 Train_loss: 0.0003403767477720976\n",
      "Epoch: 4 Iter 159 Train_loss: 0.00042523141019046307\n",
      "Epoch: 4 Iter 179 Train_loss: 0.00034092756686732173\n",
      "Epoch: 4 Iter 199 Train_loss: 0.0003427254850976169\n",
      "Epoch: 4 Iter 219 Train_loss: 0.0003539500175975263\n",
      "Epoch: 4 Iter 239 Train_loss: 0.0003703026450239122\n",
      "Epoch: 4 Iter 259 Train_loss: 0.0003643798700068146\n",
      "Epoch: 4 Iter 279 Train_loss: 0.0003774938522838056\n",
      "Epoch: 4 Iter 299 Train_loss: 0.00037328890175558627\n",
      "Epoch: 4 Iter 319 Train_loss: 0.00033727462869137526\n",
      "Epoch: 4 Iter 339 Train_loss: 0.00028413947438821197\n",
      "Epoch: 4 Iter 359 Train_loss: 0.00033049724879674613\n",
      "Epoch: 4 Iter 379 Train_loss: 0.00032966164872050285\n",
      "Epoch: 4 Iter 399 Train_loss: 0.00040352443465963006\n",
      "Epoch: 4 Iter 419 Train_loss: 0.00041371240513399243\n",
      "Epoch: 4 Iter 439 Train_loss: 0.0003927607904188335\n",
      "Epoch: 4 Iter 459 Train_loss: 0.0003566019586287439\n",
      "Epoch: 4 Iter 479 Train_loss: 0.00034886901266872883\n",
      "Epoch: 4 Iter 499 Train_loss: 0.000363897648639977\n",
      "Epoch: 4 Iter 519 Train_loss: 0.00035223783925175667\n",
      "Epoch: 4 Iter 539 Train_loss: 0.0004010019183624536\n",
      "Epoch: 4 Iter 559 Train_loss: 0.00035589400795288384\n",
      "Epoch: 4 Iter 579 Train_loss: 0.0003577088355086744\n",
      "Epoch: 4 Iter 599 Train_loss: 0.0004312293021939695\n",
      "Epoch: 4 Iter 619 Train_loss: 0.00035711718373931944\n",
      "Epoch: 4 Iter 639 Train_loss: 0.000361318961950019\n",
      "Epoch: 4 Iter 659 Train_loss: 0.00035327233490534127\n",
      "Epoch: 4 Iter 679 Train_loss: 0.00029990432085469365\n",
      "Epoch: 4 Iter 699 Train_loss: 0.0003526505606714636\n",
      "Epoch: 4 Iter 719 Train_loss: 0.0003502116014715284\n",
      "Epoch: 4 Iter 739 Train_loss: 0.00032680624281056225\n",
      "Epoch: 4 Iter 759 Train_loss: 0.0003434702812228352\n",
      "Epoch: 4 Iter 779 Train_loss: 0.0003070769307669252\n",
      "Epoch: 4 Iter 799 Train_loss: 0.0003145390364807099\n",
      "Epoch: 4 Iter 819 Train_loss: 0.0003275728377047926\n",
      "Epoch: 4 Iter 839 Train_loss: 0.00033127196365967393\n",
      "Epoch: 4 Iter 859 Train_loss: 0.00036039770930074155\n",
      "Epoch: 4 Iter 879 Train_loss: 0.0003472769458312541\n",
      "Epoch: 4 Iter 899 Train_loss: 0.00041659048292785883\n",
      "Epoch: 4 Iter 919 Train_loss: 0.0003091928665526211\n",
      "Epoch: 4 Iter 939 Train_loss: 0.00034027628134936094\n",
      "Epoch: 4 Iter 959 Train_loss: 0.0003240705409552902\n",
      "Epoch: 4 Iter 979 Train_loss: 0.00036988232750445604\n",
      "Epoch: 4 Iter 999 Train_loss: 0.00031406054040417075\n",
      "Epoch: 4 Iter 1019 Train_loss: 0.0003185942186973989\n",
      "Epoch: 4 Iter 1039 Train_loss: 0.00038245259202085435\n",
      "Epoch: 4 Iter 1059 Train_loss: 0.0004473678709473461\n",
      "[  4/100]train_loss:0.00036valid_loss:0.00037\n",
      "Validation loss decreased (0.000387 --> 0.000369).  Saving model ...\n",
      "Epoch: 5 Iter 19 Train_loss: 0.0003603928489610553\n",
      "Epoch: 5 Iter 39 Train_loss: 0.00035327248042449355\n",
      "Epoch: 5 Iter 59 Train_loss: 0.0004054715682286769\n",
      "Epoch: 5 Iter 79 Train_loss: 0.00031284583383239806\n",
      "Epoch: 5 Iter 99 Train_loss: 0.000317391415592283\n",
      "Epoch: 5 Iter 119 Train_loss: 0.00030452568898908794\n",
      "Epoch: 5 Iter 139 Train_loss: 0.0003306462022010237\n",
      "Epoch: 5 Iter 159 Train_loss: 0.0002854233898688108\n",
      "Epoch: 5 Iter 179 Train_loss: 0.00033850286854431033\n",
      "Epoch: 5 Iter 199 Train_loss: 0.00037507337401621044\n",
      "Epoch: 5 Iter 219 Train_loss: 0.0003981307672802359\n",
      "Epoch: 5 Iter 239 Train_loss: 0.00036129492218606174\n",
      "Epoch: 5 Iter 259 Train_loss: 0.00045401923125609756\n",
      "Epoch: 5 Iter 279 Train_loss: 0.0003388297336641699\n",
      "Epoch: 5 Iter 299 Train_loss: 0.00026170097407884896\n",
      "Epoch: 5 Iter 319 Train_loss: 0.00042017389205284417\n",
      "Epoch: 5 Iter 339 Train_loss: 0.00035805287188850343\n",
      "Epoch: 5 Iter 359 Train_loss: 0.0003134471771772951\n",
      "Epoch: 5 Iter 379 Train_loss: 0.0004105322004761547\n",
      "Epoch: 5 Iter 399 Train_loss: 0.0004043079388793558\n",
      "Epoch: 5 Iter 419 Train_loss: 0.0003160190535709262\n",
      "Epoch: 5 Iter 439 Train_loss: 0.0003106517833657563\n",
      "Epoch: 5 Iter 459 Train_loss: 0.0003383297589607537\n",
      "Epoch: 5 Iter 479 Train_loss: 0.00039813865441828966\n",
      "Epoch: 5 Iter 499 Train_loss: 0.0003567931125871837\n",
      "Epoch: 5 Iter 519 Train_loss: 0.0003296206414233893\n",
      "Epoch: 5 Iter 539 Train_loss: 0.0003570739063434303\n",
      "Epoch: 5 Iter 559 Train_loss: 0.0003654761821962893\n",
      "Epoch: 5 Iter 579 Train_loss: 0.00029984588036313653\n",
      "Epoch: 5 Iter 599 Train_loss: 0.0002904332068283111\n",
      "Epoch: 5 Iter 619 Train_loss: 0.0003073599946219474\n",
      "Epoch: 5 Iter 639 Train_loss: 0.0003381424176041037\n",
      "Epoch: 5 Iter 659 Train_loss: 0.0003656827029772103\n",
      "Epoch: 5 Iter 679 Train_loss: 0.0003558929602149874\n",
      "Epoch: 5 Iter 699 Train_loss: 0.00030227017123252153\n",
      "Epoch: 5 Iter 719 Train_loss: 0.00031001746538095176\n",
      "Epoch: 5 Iter 739 Train_loss: 0.0003161899803671986\n",
      "Epoch: 5 Iter 759 Train_loss: 0.00029357083258219063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Iter 779 Train_loss: 0.0003282076504547149\n",
      "Epoch: 5 Iter 799 Train_loss: 0.00032083041151054204\n",
      "Epoch: 5 Iter 819 Train_loss: 0.00034558234619908035\n",
      "Epoch: 5 Iter 839 Train_loss: 0.00038053534808568656\n",
      "Epoch: 5 Iter 859 Train_loss: 0.0003024791949428618\n",
      "Epoch: 5 Iter 879 Train_loss: 0.00038380431942641735\n",
      "Epoch: 5 Iter 899 Train_loss: 0.0003388583136256784\n",
      "Epoch: 5 Iter 919 Train_loss: 0.00032948050647974014\n",
      "Epoch: 5 Iter 939 Train_loss: 0.0003103483759332448\n",
      "Epoch: 5 Iter 959 Train_loss: 0.0002949774789158255\n",
      "Epoch: 5 Iter 979 Train_loss: 0.00037920119939371943\n",
      "Epoch: 5 Iter 999 Train_loss: 0.00034985211095772684\n",
      "Epoch: 5 Iter 1019 Train_loss: 0.0003238807839807123\n",
      "Epoch: 5 Iter 1039 Train_loss: 0.00030868829344399273\n",
      "Epoch: 5 Iter 1059 Train_loss: 0.0004209483740851283\n",
      "[  5/100]train_loss:0.00034valid_loss:0.00034\n",
      "Validation loss decreased (0.000369 --> 0.000340).  Saving model ...\n",
      "Epoch: 6 Iter 19 Train_loss: 0.0003934211272280663\n",
      "Epoch: 6 Iter 39 Train_loss: 0.0003788600442931056\n",
      "Epoch: 6 Iter 59 Train_loss: 0.0003179815539624542\n",
      "Epoch: 6 Iter 79 Train_loss: 0.00032302289037033916\n",
      "Epoch: 6 Iter 99 Train_loss: 0.0003884218749590218\n",
      "Epoch: 6 Iter 119 Train_loss: 0.00028425376513041556\n",
      "Epoch: 6 Iter 139 Train_loss: 0.00029243409517221153\n",
      "Epoch: 6 Iter 159 Train_loss: 0.0003450234071351588\n",
      "Epoch: 6 Iter 179 Train_loss: 0.0003495695418678224\n",
      "Epoch: 6 Iter 199 Train_loss: 0.0003517928998917341\n",
      "Epoch: 6 Iter 219 Train_loss: 0.0003191995492670685\n",
      "Epoch: 6 Iter 239 Train_loss: 0.0003103475901298225\n",
      "Epoch: 6 Iter 259 Train_loss: 0.0002811256272252649\n",
      "Epoch: 6 Iter 279 Train_loss: 0.0003215945325791836\n",
      "Epoch: 6 Iter 299 Train_loss: 0.00044901989167556167\n",
      "Epoch: 6 Iter 319 Train_loss: 0.0002961255086120218\n",
      "Epoch: 6 Iter 339 Train_loss: 0.0003752162156160921\n",
      "Epoch: 6 Iter 359 Train_loss: 0.0003193463780917227\n",
      "Epoch: 6 Iter 379 Train_loss: 0.0003025878977496177\n",
      "Epoch: 6 Iter 399 Train_loss: 0.00031621241942048073\n",
      "Epoch: 6 Iter 419 Train_loss: 0.0003248846041969955\n",
      "Epoch: 6 Iter 439 Train_loss: 0.00028363175806589425\n",
      "Epoch: 6 Iter 459 Train_loss: 0.00040680525125935674\n",
      "Epoch: 6 Iter 479 Train_loss: 0.0003046006604563445\n",
      "Epoch: 6 Iter 499 Train_loss: 0.0003482632455416024\n",
      "Epoch: 6 Iter 519 Train_loss: 0.00038519719964824617\n",
      "Epoch: 6 Iter 539 Train_loss: 0.00031821735319681466\n",
      "Epoch: 6 Iter 559 Train_loss: 0.0003922923933714628\n",
      "Epoch: 6 Iter 579 Train_loss: 0.0003879328432958573\n",
      "Epoch: 6 Iter 599 Train_loss: 0.00030075031099841\n",
      "Epoch: 6 Iter 619 Train_loss: 0.0003177930775564164\n",
      "Epoch: 6 Iter 639 Train_loss: 0.00034961753408424556\n",
      "Epoch: 6 Iter 659 Train_loss: 0.00038696284173056483\n",
      "Epoch: 6 Iter 679 Train_loss: 0.0003501554310787469\n",
      "Epoch: 6 Iter 699 Train_loss: 0.0002978492993861437\n",
      "Epoch: 6 Iter 719 Train_loss: 0.00039915466913953424\n",
      "Epoch: 6 Iter 739 Train_loss: 0.0003487945068627596\n",
      "Epoch: 6 Iter 759 Train_loss: 0.0003852969966828823\n",
      "Epoch: 6 Iter 779 Train_loss: 0.0003135119332000613\n",
      "Epoch: 6 Iter 799 Train_loss: 0.0002688460808712989\n",
      "Epoch: 6 Iter 819 Train_loss: 0.00027541120653040707\n",
      "Epoch: 6 Iter 839 Train_loss: 0.0003613909357227385\n",
      "Epoch: 6 Iter 859 Train_loss: 0.00028292855131439865\n",
      "Epoch: 6 Iter 879 Train_loss: 0.00037854889524169266\n",
      "Epoch: 6 Iter 899 Train_loss: 0.0003943783522117883\n",
      "Epoch: 6 Iter 919 Train_loss: 0.00030103937024250627\n",
      "Epoch: 6 Iter 939 Train_loss: 0.0003034368855878711\n",
      "Epoch: 6 Iter 959 Train_loss: 0.00029009542777203023\n",
      "Epoch: 6 Iter 979 Train_loss: 0.00033055219682864845\n",
      "Epoch: 6 Iter 999 Train_loss: 0.00032131135230883956\n",
      "Epoch: 6 Iter 1019 Train_loss: 0.0003669254947453737\n",
      "Epoch: 6 Iter 1039 Train_loss: 0.00033516669645905495\n",
      "Epoch: 6 Iter 1059 Train_loss: 0.00032451897277496755\n",
      "[  6/100]train_loss:0.00033valid_loss:0.00034\n",
      "Validation loss decreased (0.000340 --> 0.000339).  Saving model ...\n",
      "Epoch: 7 Iter 19 Train_loss: 0.0003041772870346904\n",
      "Epoch: 7 Iter 39 Train_loss: 0.00031677179504185915\n",
      "Epoch: 7 Iter 59 Train_loss: 0.0002686372317839414\n",
      "Epoch: 7 Iter 79 Train_loss: 0.0003052024694625288\n",
      "Epoch: 7 Iter 99 Train_loss: 0.00030032338690944016\n",
      "Epoch: 7 Iter 119 Train_loss: 0.0003276732168160379\n",
      "Epoch: 7 Iter 139 Train_loss: 0.00036225360236130655\n",
      "Epoch: 7 Iter 159 Train_loss: 0.0003788217145483941\n",
      "Epoch: 7 Iter 179 Train_loss: 0.0003057763387914747\n",
      "Epoch: 7 Iter 199 Train_loss: 0.00029688741778954864\n",
      "Epoch: 7 Iter 219 Train_loss: 0.000264251691987738\n",
      "Epoch: 7 Iter 239 Train_loss: 0.0003641309740487486\n",
      "Epoch: 7 Iter 259 Train_loss: 0.00041896768379956484\n",
      "Epoch: 7 Iter 279 Train_loss: 0.00040212736348621547\n",
      "Epoch: 7 Iter 299 Train_loss: 0.0003157172759529203\n",
      "Epoch: 7 Iter 319 Train_loss: 0.00030485904426313937\n",
      "Epoch: 7 Iter 339 Train_loss: 0.00034632350434549153\n",
      "Epoch: 7 Iter 359 Train_loss: 0.0003100152825936675\n",
      "Epoch: 7 Iter 379 Train_loss: 0.000302994652884081\n",
      "Epoch: 7 Iter 399 Train_loss: 0.0002985245664604008\n",
      "Epoch: 7 Iter 419 Train_loss: 0.000354377378243953\n",
      "Epoch: 7 Iter 439 Train_loss: 0.0003251846064813435\n",
      "Epoch: 7 Iter 459 Train_loss: 0.0002965256862808019\n",
      "Epoch: 7 Iter 479 Train_loss: 0.0003244936524424702\n",
      "Epoch: 7 Iter 499 Train_loss: 0.0003105690120719373\n",
      "Epoch: 7 Iter 519 Train_loss: 0.00035573230707086623\n",
      "Epoch: 7 Iter 539 Train_loss: 0.0002986198232974857\n",
      "Epoch: 7 Iter 559 Train_loss: 0.00034796897671185434\n",
      "Epoch: 7 Iter 579 Train_loss: 0.0003668470017146319\n",
      "Epoch: 7 Iter 599 Train_loss: 0.00028550243587233126\n",
      "Epoch: 7 Iter 619 Train_loss: 0.0004050674906466156\n",
      "Epoch: 7 Iter 639 Train_loss: 0.0002861008979380131\n",
      "Epoch: 7 Iter 659 Train_loss: 0.0003460505686234683\n",
      "Epoch: 7 Iter 679 Train_loss: 0.00027101949672214687\n",
      "Epoch: 7 Iter 699 Train_loss: 0.00031163974199444056\n",
      "Epoch: 7 Iter 719 Train_loss: 0.00030968012288212776\n",
      "Epoch: 7 Iter 739 Train_loss: 0.0002693918359000236\n",
      "Epoch: 7 Iter 759 Train_loss: 0.0003151420096401125\n",
      "Epoch: 7 Iter 779 Train_loss: 0.00028860551537945867\n",
      "Epoch: 7 Iter 799 Train_loss: 0.00039378993096761405\n",
      "Epoch: 7 Iter 819 Train_loss: 0.00030215238803066313\n",
      "Epoch: 7 Iter 839 Train_loss: 0.0003018632414750755\n",
      "Epoch: 7 Iter 859 Train_loss: 0.000291877833660692\n",
      "Epoch: 7 Iter 879 Train_loss: 0.0003335172077640891\n",
      "Epoch: 7 Iter 899 Train_loss: 0.00031319152913056314\n",
      "Epoch: 7 Iter 919 Train_loss: 0.0003146798408124596\n",
      "Epoch: 7 Iter 939 Train_loss: 0.0002958683471661061\n",
      "Epoch: 7 Iter 959 Train_loss: 0.0003081844770349562\n",
      "Epoch: 7 Iter 979 Train_loss: 0.0002974673407152295\n",
      "Epoch: 7 Iter 999 Train_loss: 0.0003192835138179362\n",
      "Epoch: 7 Iter 1019 Train_loss: 0.0002804576652124524\n",
      "Epoch: 7 Iter 1039 Train_loss: 0.0003508988884277642\n",
      "Epoch: 7 Iter 1059 Train_loss: 0.0002825747069437057\n",
      "[  7/100]train_loss:0.00032valid_loss:0.00032\n",
      "Validation loss decreased (0.000339 --> 0.000322).  Saving model ...\n",
      "Epoch: 8 Iter 19 Train_loss: 0.00030340958619490266\n",
      "Epoch: 8 Iter 39 Train_loss: 0.00031252671033143997\n",
      "Epoch: 8 Iter 59 Train_loss: 0.00029224014724604785\n",
      "Epoch: 8 Iter 79 Train_loss: 0.0003704896371345967\n",
      "Epoch: 8 Iter 99 Train_loss: 0.00028731973725371063\n",
      "Epoch: 8 Iter 119 Train_loss: 0.00026411679573357105\n",
      "Epoch: 8 Iter 139 Train_loss: 0.0003307345323264599\n",
      "Epoch: 8 Iter 159 Train_loss: 0.0002929997572209686\n",
      "Epoch: 8 Iter 179 Train_loss: 0.0002779151836875826\n",
      "Epoch: 8 Iter 199 Train_loss: 0.0002825188566930592\n",
      "Epoch: 8 Iter 219 Train_loss: 0.00035970666795037687\n",
      "Epoch: 8 Iter 239 Train_loss: 0.000366568478057161\n",
      "Epoch: 8 Iter 259 Train_loss: 0.00032981904223561287\n",
      "Epoch: 8 Iter 279 Train_loss: 0.0002997783594764769\n",
      "Epoch: 8 Iter 299 Train_loss: 0.00029499593074433506\n",
      "Epoch: 8 Iter 319 Train_loss: 0.00030556830461136997\n",
      "Epoch: 8 Iter 339 Train_loss: 0.00029697560239583254\n",
      "Epoch: 8 Iter 359 Train_loss: 0.00032251467928290367\n",
      "Epoch: 8 Iter 379 Train_loss: 0.0003475039266049862\n",
      "Epoch: 8 Iter 399 Train_loss: 0.00032109912717714906\n",
      "Epoch: 8 Iter 419 Train_loss: 0.0004356378340162337\n",
      "Epoch: 8 Iter 439 Train_loss: 0.0002611151721794158\n",
      "Epoch: 8 Iter 459 Train_loss: 0.00032017979538068175\n",
      "Epoch: 8 Iter 479 Train_loss: 0.00028547702822834253\n",
      "Epoch: 8 Iter 499 Train_loss: 0.0002687003870960325\n",
      "Epoch: 8 Iter 519 Train_loss: 0.00038229822530411184\n",
      "Epoch: 8 Iter 539 Train_loss: 0.00026362267090007663\n",
      "Epoch: 8 Iter 559 Train_loss: 0.00029880492365919054\n",
      "Epoch: 8 Iter 579 Train_loss: 0.0003544661740306765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Iter 599 Train_loss: 0.00029098583036102355\n",
      "Epoch: 8 Iter 619 Train_loss: 0.00027751404559239745\n",
      "Epoch: 8 Iter 639 Train_loss: 0.0003160088381264359\n",
      "Epoch: 8 Iter 659 Train_loss: 0.00029739568708464503\n",
      "Epoch: 8 Iter 679 Train_loss: 0.0002532482030801475\n",
      "Epoch: 8 Iter 699 Train_loss: 0.00028331458452157676\n",
      "Epoch: 8 Iter 719 Train_loss: 0.0002590969670563936\n",
      "Epoch: 8 Iter 739 Train_loss: 0.0003023133613169193\n",
      "Epoch: 8 Iter 759 Train_loss: 0.0002799698559101671\n",
      "Epoch: 8 Iter 779 Train_loss: 0.00027889697230421007\n",
      "Epoch: 8 Iter 799 Train_loss: 0.0002735483867581934\n",
      "Epoch: 8 Iter 819 Train_loss: 0.00028166608535684645\n",
      "Epoch: 8 Iter 839 Train_loss: 0.00030560456798411906\n",
      "Epoch: 8 Iter 859 Train_loss: 0.0003264923579990864\n",
      "Epoch: 8 Iter 879 Train_loss: 0.00031276760273613036\n",
      "Epoch: 8 Iter 899 Train_loss: 0.00029112424817867577\n",
      "Epoch: 8 Iter 919 Train_loss: 0.00033705413807183504\n",
      "Epoch: 8 Iter 939 Train_loss: 0.00031280884286388755\n",
      "Epoch: 8 Iter 959 Train_loss: 0.0003870878426823765\n",
      "Epoch: 8 Iter 979 Train_loss: 0.000340177706675604\n",
      "Epoch: 8 Iter 999 Train_loss: 0.00035035627661272883\n",
      "Epoch: 8 Iter 1019 Train_loss: 0.0003295136848464608\n",
      "Epoch: 8 Iter 1039 Train_loss: 0.0002940785198006779\n",
      "Epoch: 8 Iter 1059 Train_loss: 0.0003068495134357363\n",
      "[  8/100]train_loss:0.00031valid_loss:0.00032\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 9 Iter 19 Train_loss: 0.00027097013662569225\n",
      "Epoch: 9 Iter 39 Train_loss: 0.0002874053898267448\n",
      "Epoch: 9 Iter 59 Train_loss: 0.0002839616790879518\n",
      "Epoch: 9 Iter 79 Train_loss: 0.00023335673904512078\n",
      "Epoch: 9 Iter 99 Train_loss: 0.0002813454775605351\n",
      "Epoch: 9 Iter 119 Train_loss: 0.00030188937671482563\n",
      "Epoch: 9 Iter 139 Train_loss: 0.0003088751982431859\n",
      "Epoch: 9 Iter 159 Train_loss: 0.0002628396905492991\n",
      "Epoch: 9 Iter 179 Train_loss: 0.0002586248447187245\n",
      "Epoch: 9 Iter 199 Train_loss: 0.0002517573011573404\n",
      "Epoch: 9 Iter 219 Train_loss: 0.00029623255250044167\n",
      "Epoch: 9 Iter 239 Train_loss: 0.0003061289608012885\n",
      "Epoch: 9 Iter 259 Train_loss: 0.00026502084801904857\n",
      "Epoch: 9 Iter 279 Train_loss: 0.0002723307115957141\n",
      "Epoch: 9 Iter 299 Train_loss: 0.0003163326473440975\n",
      "Epoch: 9 Iter 319 Train_loss: 0.00030342256650328636\n",
      "Epoch: 9 Iter 339 Train_loss: 0.0003004229802172631\n",
      "Epoch: 9 Iter 359 Train_loss: 0.00030122644966468215\n",
      "Epoch: 9 Iter 379 Train_loss: 0.00030123049509711564\n",
      "Epoch: 9 Iter 399 Train_loss: 0.00029256462585181\n",
      "Epoch: 9 Iter 419 Train_loss: 0.00026309036184102297\n",
      "Epoch: 9 Iter 439 Train_loss: 0.0002656606666278094\n",
      "Epoch: 9 Iter 459 Train_loss: 0.0002935491211246699\n",
      "Epoch: 9 Iter 479 Train_loss: 0.0003019955474883318\n",
      "Epoch: 9 Iter 499 Train_loss: 0.00029314920539036393\n",
      "Epoch: 9 Iter 519 Train_loss: 0.0002652794646564871\n",
      "Epoch: 9 Iter 539 Train_loss: 0.0003670400765258819\n",
      "Epoch: 9 Iter 559 Train_loss: 0.0003220407816115767\n",
      "Epoch: 9 Iter 579 Train_loss: 0.00032949497108347714\n",
      "Epoch: 9 Iter 599 Train_loss: 0.00031833082903176546\n",
      "Epoch: 9 Iter 619 Train_loss: 0.00029339140746742487\n",
      "Epoch: 9 Iter 639 Train_loss: 0.00027029335615225136\n",
      "Epoch: 9 Iter 659 Train_loss: 0.0003251409507356584\n",
      "Epoch: 9 Iter 679 Train_loss: 0.00029812834691256285\n",
      "Epoch: 9 Iter 699 Train_loss: 0.0002729841216932982\n",
      "Epoch: 9 Iter 719 Train_loss: 0.00031021019094623625\n",
      "Epoch: 9 Iter 739 Train_loss: 0.0002839165390469134\n",
      "Epoch: 9 Iter 759 Train_loss: 0.00036443365388549864\n",
      "Epoch: 9 Iter 779 Train_loss: 0.00027735994081012905\n",
      "Epoch: 9 Iter 799 Train_loss: 0.0002968441986013204\n",
      "Epoch: 9 Iter 819 Train_loss: 0.0002864463604055345\n",
      "Epoch: 9 Iter 839 Train_loss: 0.0002965955645777285\n",
      "Epoch: 9 Iter 859 Train_loss: 0.00029345735674723983\n",
      "Epoch: 9 Iter 879 Train_loss: 0.00027292437152937055\n",
      "Epoch: 9 Iter 899 Train_loss: 0.0003258327778894454\n",
      "Epoch: 9 Iter 919 Train_loss: 0.0003020901931449771\n",
      "Epoch: 9 Iter 939 Train_loss: 0.0002929994079750031\n",
      "Epoch: 9 Iter 959 Train_loss: 0.0002689227694645524\n",
      "Epoch: 9 Iter 979 Train_loss: 0.0002444448182359338\n",
      "Epoch: 9 Iter 999 Train_loss: 0.00044375911238603294\n",
      "Epoch: 9 Iter 1019 Train_loss: 0.00030069545027799904\n",
      "Epoch: 9 Iter 1039 Train_loss: 0.00029477517819032073\n",
      "Epoch: 9 Iter 1059 Train_loss: 0.0002930902410298586\n",
      "[  9/100]train_loss:0.00030valid_loss:0.00032\n",
      "Validation loss decreased (0.000322 --> 0.000316).  Saving model ...\n",
      "Epoch: 10 Iter 19 Train_loss: 0.0002681869955267757\n",
      "Epoch: 10 Iter 39 Train_loss: 0.00031806048355065286\n",
      "Epoch: 10 Iter 59 Train_loss: 0.0003022130695171654\n",
      "Epoch: 10 Iter 79 Train_loss: 0.0002953771618194878\n",
      "Epoch: 10 Iter 99 Train_loss: 0.00029339041793718934\n",
      "Epoch: 10 Iter 119 Train_loss: 0.0002539356064517051\n",
      "Epoch: 10 Iter 139 Train_loss: 0.00030725542455911636\n",
      "Epoch: 10 Iter 159 Train_loss: 0.00025707337772473693\n",
      "Epoch: 10 Iter 179 Train_loss: 0.0002652760304044932\n",
      "Epoch: 10 Iter 199 Train_loss: 0.00024536155979149044\n",
      "Epoch: 10 Iter 219 Train_loss: 0.0003073990228585899\n",
      "Epoch: 10 Iter 239 Train_loss: 0.0003058555885218084\n",
      "Epoch: 10 Iter 259 Train_loss: 0.0002692377893254161\n",
      "Epoch: 10 Iter 279 Train_loss: 0.00028967123944312334\n",
      "Epoch: 10 Iter 299 Train_loss: 0.00032330324756912887\n",
      "Epoch: 10 Iter 319 Train_loss: 0.00027643635985441506\n",
      "Epoch: 10 Iter 339 Train_loss: 0.000271065830020234\n",
      "Epoch: 10 Iter 359 Train_loss: 0.00027765912818722427\n",
      "Epoch: 10 Iter 379 Train_loss: 0.0002846920979209244\n",
      "Epoch: 10 Iter 399 Train_loss: 0.00031176183256320655\n",
      "Epoch: 10 Iter 419 Train_loss: 0.0002799915673676878\n",
      "Epoch: 10 Iter 439 Train_loss: 0.0002550851204432547\n",
      "Epoch: 10 Iter 459 Train_loss: 0.0003475138801150024\n",
      "Epoch: 10 Iter 479 Train_loss: 0.0002763369120657444\n",
      "Epoch: 10 Iter 499 Train_loss: 0.00023948709713295102\n",
      "Epoch: 10 Iter 519 Train_loss: 0.0004111922753509134\n",
      "Epoch: 10 Iter 539 Train_loss: 0.00029909558361396194\n",
      "Epoch: 10 Iter 559 Train_loss: 0.0002453443012200296\n",
      "Epoch: 10 Iter 579 Train_loss: 0.0002895350335165858\n",
      "Epoch: 10 Iter 599 Train_loss: 0.00032192416256293654\n",
      "Epoch: 10 Iter 619 Train_loss: 0.00032394411391578615\n",
      "Epoch: 10 Iter 639 Train_loss: 0.00025999589706771076\n",
      "Epoch: 10 Iter 659 Train_loss: 0.00025880514294840395\n",
      "Epoch: 10 Iter 679 Train_loss: 0.00032614741940051317\n",
      "Epoch: 10 Iter 699 Train_loss: 0.00028993835439905524\n",
      "Epoch: 10 Iter 719 Train_loss: 0.00024619148462079465\n",
      "Epoch: 10 Iter 739 Train_loss: 0.00022796864504925907\n",
      "Epoch: 10 Iter 759 Train_loss: 0.0002814816834870726\n",
      "Epoch: 10 Iter 779 Train_loss: 0.00027537092682905495\n",
      "Epoch: 10 Iter 799 Train_loss: 0.00032006524270400405\n",
      "Epoch: 10 Iter 819 Train_loss: 0.00031074899015948176\n",
      "Epoch: 10 Iter 839 Train_loss: 0.000263861904386431\n",
      "Epoch: 10 Iter 859 Train_loss: 0.0002741859061643481\n",
      "Epoch: 10 Iter 879 Train_loss: 0.0002445114660076797\n",
      "Epoch: 10 Iter 899 Train_loss: 0.000344902160577476\n",
      "Epoch: 10 Iter 919 Train_loss: 0.00032511542667634785\n",
      "Epoch: 10 Iter 939 Train_loss: 0.00027452828362584114\n",
      "Epoch: 10 Iter 959 Train_loss: 0.00026890254230238497\n",
      "Epoch: 10 Iter 979 Train_loss: 0.0002750164712779224\n",
      "Epoch: 10 Iter 999 Train_loss: 0.00025070394622161984\n",
      "Epoch: 10 Iter 1019 Train_loss: 0.00025659106904640794\n",
      "Epoch: 10 Iter 1039 Train_loss: 0.0002854685881175101\n",
      "Epoch: 10 Iter 1059 Train_loss: 0.00024999873130582273\n",
      "[ 10/100]train_loss:0.00029valid_loss:0.00032\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 11 Iter 19 Train_loss: 0.0003069702070206404\n",
      "Epoch: 11 Iter 39 Train_loss: 0.0002883840643335134\n",
      "Epoch: 11 Iter 59 Train_loss: 0.00029368718969635665\n",
      "Epoch: 11 Iter 79 Train_loss: 0.00023474347835872322\n",
      "Epoch: 11 Iter 99 Train_loss: 0.00026073039043694735\n",
      "Epoch: 11 Iter 119 Train_loss: 0.0003115911385975778\n",
      "Epoch: 11 Iter 139 Train_loss: 0.0002744318335317075\n",
      "Epoch: 11 Iter 159 Train_loss: 0.0003070737875532359\n",
      "Epoch: 11 Iter 179 Train_loss: 0.0002793580642901361\n",
      "Epoch: 11 Iter 199 Train_loss: 0.00025726042804308236\n",
      "Epoch: 11 Iter 219 Train_loss: 0.00029630481731146574\n",
      "Epoch: 11 Iter 239 Train_loss: 0.00032771032419987023\n",
      "Epoch: 11 Iter 259 Train_loss: 0.00033806730061769485\n",
      "Epoch: 11 Iter 279 Train_loss: 0.0002598122810013592\n",
      "Epoch: 11 Iter 299 Train_loss: 0.00030068622436374426\n",
      "Epoch: 11 Iter 319 Train_loss: 0.00032238761195912957\n",
      "Epoch: 11 Iter 339 Train_loss: 0.00024120400485116988\n",
      "Epoch: 11 Iter 359 Train_loss: 0.0003037195128854364\n",
      "Epoch: 11 Iter 379 Train_loss: 0.0003234055475331843\n",
      "Epoch: 11 Iter 399 Train_loss: 0.0002908187743742019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Iter 419 Train_loss: 0.0002762777148745954\n",
      "Epoch: 11 Iter 439 Train_loss: 0.00026055690250359476\n",
      "Epoch: 11 Iter 459 Train_loss: 0.00027922019944526255\n",
      "Epoch: 11 Iter 479 Train_loss: 0.00029892034945078194\n",
      "Epoch: 11 Iter 499 Train_loss: 0.0003472555836196989\n",
      "Epoch: 11 Iter 519 Train_loss: 0.0002525754680391401\n",
      "Epoch: 11 Iter 539 Train_loss: 0.000262852554442361\n",
      "Epoch: 11 Iter 559 Train_loss: 0.0003000217257067561\n",
      "Epoch: 11 Iter 579 Train_loss: 0.0002926667802967131\n",
      "Epoch: 11 Iter 599 Train_loss: 0.00025837536668404937\n",
      "Epoch: 11 Iter 619 Train_loss: 0.00024831006885506213\n",
      "Epoch: 11 Iter 639 Train_loss: 0.0003711448225658387\n",
      "Epoch: 11 Iter 659 Train_loss: 0.0003123295318800956\n",
      "Epoch: 11 Iter 679 Train_loss: 0.0002938737743534148\n",
      "Epoch: 11 Iter 699 Train_loss: 0.0003058289585169405\n",
      "Epoch: 11 Iter 719 Train_loss: 0.00026659498689696193\n",
      "Epoch: 11 Iter 739 Train_loss: 0.0003309982712380588\n",
      "Epoch: 11 Iter 759 Train_loss: 0.0003177290491294116\n",
      "Epoch: 11 Iter 779 Train_loss: 0.0002654037089087069\n",
      "Epoch: 11 Iter 799 Train_loss: 0.000256258383160457\n",
      "Epoch: 11 Iter 819 Train_loss: 0.0003208319831173867\n",
      "Epoch: 11 Iter 839 Train_loss: 0.0002740624768193811\n",
      "Epoch: 11 Iter 859 Train_loss: 0.00028670215397141874\n",
      "Epoch: 11 Iter 879 Train_loss: 0.0003239683574065566\n",
      "Epoch: 11 Iter 899 Train_loss: 0.0002634924603626132\n",
      "Epoch: 11 Iter 919 Train_loss: 0.0003309376770630479\n",
      "Epoch: 11 Iter 939 Train_loss: 0.00029525483842007816\n",
      "Epoch: 11 Iter 959 Train_loss: 0.0002976809919346124\n",
      "Epoch: 11 Iter 979 Train_loss: 0.00029686439665965736\n",
      "Epoch: 11 Iter 999 Train_loss: 0.00031982018845155835\n",
      "Epoch: 11 Iter 1019 Train_loss: 0.0002598919963929802\n",
      "Epoch: 11 Iter 1039 Train_loss: 0.0002886333386413753\n",
      "Epoch: 11 Iter 1059 Train_loss: 0.0003458455903455615\n",
      "[ 11/100]train_loss:0.00028valid_loss:0.00030\n",
      "Validation loss decreased (0.000316 --> 0.000299).  Saving model ...\n",
      "Epoch: 12 Iter 19 Train_loss: 0.0002544955350458622\n",
      "Epoch: 12 Iter 39 Train_loss: 0.0002862213586922735\n",
      "Epoch: 12 Iter 59 Train_loss: 0.0002455533540342003\n",
      "Epoch: 12 Iter 79 Train_loss: 0.00026556651573628187\n",
      "Epoch: 12 Iter 99 Train_loss: 0.0002228635858045891\n",
      "Epoch: 12 Iter 119 Train_loss: 0.00031416030833497643\n",
      "Epoch: 12 Iter 139 Train_loss: 0.0002967201580759138\n",
      "Epoch: 12 Iter 159 Train_loss: 0.0002770047285594046\n",
      "Epoch: 12 Iter 179 Train_loss: 0.00023557960230391473\n",
      "Epoch: 12 Iter 199 Train_loss: 0.00025742017896845937\n",
      "Epoch: 12 Iter 219 Train_loss: 0.0002854465274140239\n",
      "Epoch: 12 Iter 239 Train_loss: 0.00025265131262131035\n",
      "Epoch: 12 Iter 259 Train_loss: 0.00024059998395387083\n",
      "Epoch: 12 Iter 279 Train_loss: 0.00024597501032985747\n",
      "Epoch: 12 Iter 299 Train_loss: 0.00027669270639307797\n",
      "Epoch: 12 Iter 319 Train_loss: 0.0003125292423646897\n",
      "Epoch: 12 Iter 339 Train_loss: 0.0002733724541030824\n",
      "Epoch: 12 Iter 359 Train_loss: 0.00025856634601950645\n",
      "Epoch: 12 Iter 379 Train_loss: 0.00026076092035509646\n",
      "Epoch: 12 Iter 399 Train_loss: 0.0002960296405944973\n",
      "Epoch: 12 Iter 419 Train_loss: 0.00024835779913701117\n",
      "Epoch: 12 Iter 439 Train_loss: 0.00027709928690455854\n",
      "Epoch: 12 Iter 459 Train_loss: 0.00027350836899131536\n",
      "Epoch: 12 Iter 479 Train_loss: 0.000281916611129418\n",
      "Epoch: 12 Iter 499 Train_loss: 0.0002797427587211132\n",
      "Epoch: 12 Iter 519 Train_loss: 0.00025080578052438796\n",
      "Epoch: 12 Iter 539 Train_loss: 0.00026152157806791365\n",
      "Epoch: 12 Iter 559 Train_loss: 0.00024338923685718328\n",
      "Epoch: 12 Iter 579 Train_loss: 0.00029430811991915107\n",
      "Epoch: 12 Iter 599 Train_loss: 0.00033880723640322685\n",
      "Epoch: 12 Iter 619 Train_loss: 0.0002981260768137872\n",
      "Epoch: 12 Iter 639 Train_loss: 0.00025661426479928195\n",
      "Epoch: 12 Iter 659 Train_loss: 0.0002955885720439255\n",
      "Epoch: 12 Iter 679 Train_loss: 0.0002609536168165505\n",
      "Epoch: 12 Iter 699 Train_loss: 0.0003204979293514043\n",
      "Epoch: 12 Iter 719 Train_loss: 0.00027370965108275414\n",
      "Epoch: 12 Iter 739 Train_loss: 0.0002418507356196642\n",
      "Epoch: 12 Iter 759 Train_loss: 0.00029627533513121307\n",
      "Epoch: 12 Iter 779 Train_loss: 0.00027814562781713903\n",
      "Epoch: 12 Iter 799 Train_loss: 0.000276735721854493\n",
      "Epoch: 12 Iter 819 Train_loss: 0.0002476210065651685\n",
      "Epoch: 12 Iter 839 Train_loss: 0.0002411481982562691\n",
      "Epoch: 12 Iter 859 Train_loss: 0.0003082770563196391\n",
      "Epoch: 12 Iter 879 Train_loss: 0.00025837469729594886\n",
      "Epoch: 12 Iter 899 Train_loss: 0.0003193454467691481\n",
      "Epoch: 12 Iter 919 Train_loss: 0.0003001599106937647\n",
      "Epoch: 12 Iter 939 Train_loss: 0.00026333864661864936\n",
      "Epoch: 12 Iter 959 Train_loss: 0.0002760518400464207\n",
      "Epoch: 12 Iter 979 Train_loss: 0.00027175553259439766\n",
      "Epoch: 12 Iter 999 Train_loss: 0.00028972659492865205\n",
      "Epoch: 12 Iter 1019 Train_loss: 0.00026800393243320286\n",
      "Epoch: 12 Iter 1039 Train_loss: 0.0002418814692646265\n",
      "Epoch: 12 Iter 1059 Train_loss: 0.0002658982411958277\n",
      "[ 12/100]train_loss:0.00027valid_loss:0.00031\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 13 Iter 19 Train_loss: 0.00028099730843678117\n",
      "Epoch: 13 Iter 39 Train_loss: 0.00024063384626060724\n",
      "Epoch: 13 Iter 59 Train_loss: 0.00023855881590861827\n",
      "Epoch: 13 Iter 79 Train_loss: 0.000285767629975453\n",
      "Epoch: 13 Iter 99 Train_loss: 0.00023400489590130746\n",
      "Epoch: 13 Iter 119 Train_loss: 0.00028031354304403067\n",
      "Epoch: 13 Iter 139 Train_loss: 0.00024604337522760034\n",
      "Epoch: 13 Iter 159 Train_loss: 0.00028276917873881757\n",
      "Epoch: 13 Iter 179 Train_loss: 0.000261070323176682\n",
      "Epoch: 13 Iter 199 Train_loss: 0.00025366031331941485\n",
      "Epoch: 13 Iter 219 Train_loss: 0.0002454215136822313\n",
      "Epoch: 13 Iter 239 Train_loss: 0.0003202660591341555\n",
      "Epoch: 13 Iter 259 Train_loss: 0.0002543791488278657\n",
      "Epoch: 13 Iter 279 Train_loss: 0.0003014854737557471\n",
      "Epoch: 13 Iter 299 Train_loss: 0.0002728881372604519\n",
      "Epoch: 13 Iter 319 Train_loss: 0.00027467802283354104\n",
      "Epoch: 13 Iter 339 Train_loss: 0.00028735626256093383\n",
      "Epoch: 13 Iter 359 Train_loss: 0.0002450898173265159\n",
      "Epoch: 13 Iter 379 Train_loss: 0.00026668442296795547\n",
      "Epoch: 13 Iter 399 Train_loss: 0.00023876687919255346\n",
      "Epoch: 13 Iter 419 Train_loss: 0.0002980588178616017\n",
      "Epoch: 13 Iter 439 Train_loss: 0.00027079469873569906\n",
      "Epoch: 13 Iter 459 Train_loss: 0.0002930656191892922\n",
      "Epoch: 13 Iter 479 Train_loss: 0.00023755150323268026\n",
      "Epoch: 13 Iter 499 Train_loss: 0.00023742220946587622\n",
      "Epoch: 13 Iter 519 Train_loss: 0.00026445521507412195\n",
      "Epoch: 13 Iter 539 Train_loss: 0.00023668068752158433\n",
      "Epoch: 13 Iter 559 Train_loss: 0.0003047171630896628\n",
      "Epoch: 13 Iter 579 Train_loss: 0.00029120323597453535\n",
      "Epoch: 13 Iter 599 Train_loss: 0.00026057290961034596\n",
      "Epoch: 13 Iter 619 Train_loss: 0.0002996335970237851\n",
      "Epoch: 13 Iter 639 Train_loss: 0.00023542952840216458\n",
      "Epoch: 13 Iter 659 Train_loss: 0.000247856427449733\n",
      "Epoch: 13 Iter 679 Train_loss: 0.00026083210832439363\n",
      "Epoch: 13 Iter 699 Train_loss: 0.00024565233616158366\n",
      "Epoch: 13 Iter 719 Train_loss: 0.0002453756460454315\n",
      "Epoch: 13 Iter 739 Train_loss: 0.00024002250574994832\n",
      "Epoch: 13 Iter 759 Train_loss: 0.00025021188776008785\n",
      "Epoch: 13 Iter 779 Train_loss: 0.00025414308765903115\n",
      "Epoch: 13 Iter 799 Train_loss: 0.0002686895604711026\n",
      "Epoch: 13 Iter 819 Train_loss: 0.00028143933741375804\n",
      "Epoch: 13 Iter 839 Train_loss: 0.0002758183691184968\n",
      "Epoch: 13 Iter 859 Train_loss: 0.0002754565211944282\n",
      "Epoch: 13 Iter 879 Train_loss: 0.00024020533601287752\n",
      "Epoch: 13 Iter 899 Train_loss: 0.0003166804672218859\n",
      "Epoch: 13 Iter 919 Train_loss: 0.0002594272082205862\n",
      "Epoch: 13 Iter 939 Train_loss: 0.000263940921286121\n",
      "Epoch: 13 Iter 959 Train_loss: 0.0002299729094374925\n",
      "Epoch: 13 Iter 979 Train_loss: 0.00024197393213398755\n",
      "Epoch: 13 Iter 999 Train_loss: 0.00027537436108104885\n",
      "Epoch: 13 Iter 1019 Train_loss: 0.0003202590742148459\n",
      "Epoch: 13 Iter 1039 Train_loss: 0.00023443668032996356\n",
      "Epoch: 13 Iter 1059 Train_loss: 0.00027609095559455454\n",
      "[ 13/100]train_loss:0.00027valid_loss:0.00030\n",
      "Validation loss decreased (0.000299 --> 0.000297).  Saving model ...\n",
      "Epoch: 14 Iter 19 Train_loss: 0.0002935120719484985\n",
      "Epoch: 14 Iter 39 Train_loss: 0.0002469437604304403\n",
      "Epoch: 14 Iter 59 Train_loss: 0.0002907221205532551\n",
      "Epoch: 14 Iter 79 Train_loss: 0.00030715481261722744\n",
      "Epoch: 14 Iter 99 Train_loss: 0.00027143777697347105\n",
      "Epoch: 14 Iter 119 Train_loss: 0.00023735492140986025\n",
      "Epoch: 14 Iter 139 Train_loss: 0.0002460827527102083\n",
      "Epoch: 14 Iter 159 Train_loss: 0.00030614581191912293\n",
      "Epoch: 14 Iter 179 Train_loss: 0.00024241067876573652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Iter 199 Train_loss: 0.0002166198391932994\n",
      "Epoch: 14 Iter 219 Train_loss: 0.000247171672526747\n",
      "Epoch: 14 Iter 239 Train_loss: 0.0002553472586441785\n",
      "Epoch: 14 Iter 259 Train_loss: 0.0002521095739211887\n",
      "Epoch: 14 Iter 279 Train_loss: 0.00023709515517111868\n",
      "Epoch: 14 Iter 299 Train_loss: 0.0002519069821573794\n",
      "Epoch: 14 Iter 319 Train_loss: 0.00027155125280842185\n",
      "Epoch: 14 Iter 339 Train_loss: 0.0002687644155230373\n",
      "Epoch: 14 Iter 359 Train_loss: 0.0002494950604159385\n",
      "Epoch: 14 Iter 379 Train_loss: 0.0002585461479611695\n",
      "Epoch: 14 Iter 399 Train_loss: 0.0002702415513340384\n",
      "Epoch: 14 Iter 419 Train_loss: 0.00025792085216380656\n",
      "Epoch: 14 Iter 439 Train_loss: 0.0002590602380223572\n",
      "Epoch: 14 Iter 459 Train_loss: 0.0002578800776973367\n",
      "Epoch: 14 Iter 479 Train_loss: 0.00027041893918067217\n",
      "Epoch: 14 Iter 499 Train_loss: 0.000259249412920326\n",
      "Epoch: 14 Iter 519 Train_loss: 0.00023873175086919218\n",
      "Epoch: 14 Iter 539 Train_loss: 0.00028130310238339007\n",
      "Epoch: 14 Iter 559 Train_loss: 0.00028882289188914\n",
      "Epoch: 14 Iter 579 Train_loss: 0.00026995057123713195\n",
      "Epoch: 14 Iter 599 Train_loss: 0.0002518058172427118\n",
      "Epoch: 14 Iter 619 Train_loss: 0.00025540945352986455\n",
      "Epoch: 14 Iter 639 Train_loss: 0.00025517394533380866\n",
      "Epoch: 14 Iter 659 Train_loss: 0.0002546901232562959\n",
      "Epoch: 14 Iter 679 Train_loss: 0.0002748514525592327\n",
      "Epoch: 14 Iter 699 Train_loss: 0.00026848854031413794\n",
      "Epoch: 14 Iter 719 Train_loss: 0.0002132703084498644\n",
      "Epoch: 14 Iter 739 Train_loss: 0.00024882450816221535\n",
      "Epoch: 14 Iter 759 Train_loss: 0.00023664858599659055\n",
      "Epoch: 14 Iter 779 Train_loss: 0.0002455231733620167\n",
      "Epoch: 14 Iter 799 Train_loss: 0.00025179662043228745\n",
      "Epoch: 14 Iter 819 Train_loss: 0.00022969904239289463\n",
      "Epoch: 14 Iter 839 Train_loss: 0.00027516199043020606\n",
      "Epoch: 14 Iter 859 Train_loss: 0.00025936609017662704\n",
      "Epoch: 14 Iter 879 Train_loss: 0.0002584883477538824\n",
      "Epoch: 14 Iter 899 Train_loss: 0.0002374321047682315\n",
      "Epoch: 14 Iter 919 Train_loss: 0.00028479131287895143\n",
      "Epoch: 14 Iter 939 Train_loss: 0.00019761791918426752\n",
      "Epoch: 14 Iter 959 Train_loss: 0.00025384596665389836\n",
      "Epoch: 14 Iter 979 Train_loss: 0.00020318952738307416\n",
      "Epoch: 14 Iter 999 Train_loss: 0.00025366112822666764\n",
      "Epoch: 14 Iter 1019 Train_loss: 0.0002707627136260271\n",
      "Epoch: 14 Iter 1039 Train_loss: 0.00028858703444711864\n",
      "Epoch: 14 Iter 1059 Train_loss: 0.0002347672125324607\n",
      "[ 14/100]train_loss:0.00027valid_loss:0.00029\n",
      "Validation loss decreased (0.000297 --> 0.000285).  Saving model ...\n",
      "Epoch: 15 Iter 19 Train_loss: 0.0002509841579012573\n",
      "Epoch: 15 Iter 39 Train_loss: 0.0002647269575390965\n",
      "Epoch: 15 Iter 59 Train_loss: 0.00027281520306132734\n",
      "Epoch: 15 Iter 79 Train_loss: 0.0002342918305657804\n",
      "Epoch: 15 Iter 99 Train_loss: 0.0002595745900180191\n",
      "Epoch: 15 Iter 119 Train_loss: 0.00021216725872363895\n",
      "Epoch: 15 Iter 139 Train_loss: 0.00022269025794230402\n",
      "Epoch: 15 Iter 159 Train_loss: 0.00030432280618697405\n",
      "Epoch: 15 Iter 179 Train_loss: 0.00023461323871742934\n",
      "Epoch: 15 Iter 199 Train_loss: 0.00023471021268051118\n",
      "Epoch: 15 Iter 219 Train_loss: 0.0002531752979848534\n",
      "Epoch: 15 Iter 239 Train_loss: 0.0002773447195068002\n",
      "Epoch: 15 Iter 259 Train_loss: 0.0002777025511022657\n",
      "Epoch: 15 Iter 279 Train_loss: 0.00027480567223392427\n",
      "Epoch: 15 Iter 299 Train_loss: 0.0002559559070505202\n",
      "Epoch: 15 Iter 319 Train_loss: 0.0002440028329147026\n",
      "Epoch: 15 Iter 339 Train_loss: 0.00028372660744935274\n",
      "Epoch: 15 Iter 359 Train_loss: 0.000238545035244897\n",
      "Epoch: 15 Iter 379 Train_loss: 0.0002577047562226653\n",
      "Epoch: 15 Iter 399 Train_loss: 0.000237461703363806\n",
      "Epoch: 15 Iter 419 Train_loss: 0.0002836116182152182\n",
      "Epoch: 15 Iter 439 Train_loss: 0.00029452156741172075\n",
      "Epoch: 15 Iter 459 Train_loss: 0.0002549242926761508\n",
      "Epoch: 15 Iter 479 Train_loss: 0.0002790905418805778\n",
      "Epoch: 15 Iter 499 Train_loss: 0.00026868819259107113\n",
      "Epoch: 15 Iter 519 Train_loss: 0.00025619540247134864\n",
      "Epoch: 15 Iter 539 Train_loss: 0.00025471477420069277\n",
      "Epoch: 15 Iter 559 Train_loss: 0.00023256326676346362\n",
      "Epoch: 15 Iter 579 Train_loss: 0.00025089195696637034\n",
      "Epoch: 15 Iter 599 Train_loss: 0.0002983606536872685\n",
      "Epoch: 15 Iter 619 Train_loss: 0.00029748782981187105\n",
      "Epoch: 15 Iter 639 Train_loss: 0.0003406943869777024\n",
      "Epoch: 15 Iter 659 Train_loss: 0.00023304145724978298\n",
      "Epoch: 15 Iter 679 Train_loss: 0.00025342372828163207\n",
      "Epoch: 15 Iter 699 Train_loss: 0.0003110390971414745\n",
      "Epoch: 15 Iter 719 Train_loss: 0.00026969751343131065\n",
      "Epoch: 15 Iter 739 Train_loss: 0.0002653079282026738\n",
      "Epoch: 15 Iter 759 Train_loss: 0.00024273637973237783\n",
      "Epoch: 15 Iter 779 Train_loss: 0.00024615952861495316\n",
      "Epoch: 15 Iter 799 Train_loss: 0.00024086266057565808\n",
      "Epoch: 15 Iter 819 Train_loss: 0.0002413923793938011\n",
      "Epoch: 15 Iter 839 Train_loss: 0.00024920664145611227\n",
      "Epoch: 15 Iter 859 Train_loss: 0.0002636873396113515\n",
      "Epoch: 15 Iter 879 Train_loss: 0.00027130625676363707\n",
      "Epoch: 15 Iter 899 Train_loss: 0.00028064922662451863\n",
      "Epoch: 15 Iter 919 Train_loss: 0.00041061313822865486\n",
      "Epoch: 15 Iter 939 Train_loss: 0.00027376736397854984\n",
      "Epoch: 15 Iter 959 Train_loss: 0.00019802579481620342\n",
      "Epoch: 15 Iter 979 Train_loss: 0.00024041146389208734\n",
      "Epoch: 15 Iter 999 Train_loss: 0.000240819324972108\n",
      "Epoch: 15 Iter 1019 Train_loss: 0.0003131045959889889\n",
      "Epoch: 15 Iter 1039 Train_loss: 0.00026473068282939494\n",
      "Epoch: 15 Iter 1059 Train_loss: 0.0002651828108355403\n",
      "[ 15/100]train_loss:0.00026valid_loss:0.00030\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 16 Iter 19 Train_loss: 0.00027270239661447704\n",
      "Epoch: 16 Iter 39 Train_loss: 0.0002936673117801547\n",
      "Epoch: 16 Iter 59 Train_loss: 0.000251120567554608\n",
      "Epoch: 16 Iter 79 Train_loss: 0.0002390003646723926\n",
      "Epoch: 16 Iter 99 Train_loss: 0.0002526724128983915\n",
      "Epoch: 16 Iter 119 Train_loss: 0.0002494696818757802\n",
      "Epoch: 16 Iter 139 Train_loss: 0.0002603804168757051\n",
      "Epoch: 16 Iter 159 Train_loss: 0.00025599851505830884\n",
      "Epoch: 16 Iter 179 Train_loss: 0.00024838995886966586\n",
      "Epoch: 16 Iter 199 Train_loss: 0.00022930283739697188\n",
      "Epoch: 16 Iter 219 Train_loss: 0.00023043929832056165\n",
      "Epoch: 16 Iter 239 Train_loss: 0.00022472294222097844\n",
      "Epoch: 16 Iter 259 Train_loss: 0.0002100926503771916\n",
      "Epoch: 16 Iter 279 Train_loss: 0.0002569036732893437\n",
      "Epoch: 16 Iter 299 Train_loss: 0.00024791440228000283\n",
      "Epoch: 16 Iter 319 Train_loss: 0.00023047429567668587\n",
      "Epoch: 16 Iter 339 Train_loss: 0.00026032011373899877\n",
      "Epoch: 16 Iter 359 Train_loss: 0.00023097854864317924\n",
      "Epoch: 16 Iter 379 Train_loss: 0.00028055283473804593\n",
      "Epoch: 16 Iter 399 Train_loss: 0.0002580703585408628\n",
      "Epoch: 16 Iter 419 Train_loss: 0.00026477695791982114\n",
      "Epoch: 16 Iter 439 Train_loss: 0.0002306908427271992\n",
      "Epoch: 16 Iter 459 Train_loss: 0.0002840318775270134\n",
      "Epoch: 16 Iter 479 Train_loss: 0.00021630139963235706\n",
      "Epoch: 16 Iter 499 Train_loss: 0.0002639450249262154\n",
      "Epoch: 16 Iter 519 Train_loss: 0.0002668720262590796\n",
      "Epoch: 16 Iter 539 Train_loss: 0.00026696297572925687\n",
      "Epoch: 16 Iter 559 Train_loss: 0.0002503885480109602\n",
      "Epoch: 16 Iter 579 Train_loss: 0.00023499673989135772\n",
      "Epoch: 16 Iter 599 Train_loss: 0.00026113883359357715\n",
      "Epoch: 16 Iter 619 Train_loss: 0.00026209515635855496\n",
      "Epoch: 16 Iter 639 Train_loss: 0.0002729218977037817\n",
      "Epoch: 16 Iter 659 Train_loss: 0.0003002542944159359\n",
      "Epoch: 16 Iter 679 Train_loss: 0.0002490068436600268\n",
      "Epoch: 16 Iter 699 Train_loss: 0.0003541688492987305\n",
      "Epoch: 16 Iter 719 Train_loss: 0.00027217617025598884\n",
      "Epoch: 16 Iter 739 Train_loss: 0.0002408059372100979\n",
      "Epoch: 16 Iter 759 Train_loss: 0.00028909181128256023\n",
      "Epoch: 16 Iter 779 Train_loss: 0.00034508586395531893\n",
      "Epoch: 16 Iter 799 Train_loss: 0.0002381996309850365\n",
      "Epoch: 16 Iter 819 Train_loss: 0.00025440595345571637\n",
      "Epoch: 16 Iter 839 Train_loss: 0.00021547252254094929\n",
      "Epoch: 16 Iter 859 Train_loss: 0.0002679253229871392\n",
      "Epoch: 16 Iter 879 Train_loss: 0.00024062552256509662\n",
      "Epoch: 16 Iter 899 Train_loss: 0.0002750869607552886\n",
      "Epoch: 16 Iter 919 Train_loss: 0.00028189370641484857\n",
      "Epoch: 16 Iter 939 Train_loss: 0.00024330410815309733\n",
      "Epoch: 16 Iter 959 Train_loss: 0.00022789476497564465\n",
      "Epoch: 16 Iter 979 Train_loss: 0.0002046123699983582\n",
      "Epoch: 16 Iter 999 Train_loss: 0.0002463853743392974\n",
      "Epoch: 16 Iter 1019 Train_loss: 0.00023652083473280072\n",
      "Epoch: 16 Iter 1039 Train_loss: 0.0002260021719848737\n",
      "Epoch: 16 Iter 1059 Train_loss: 0.00024939983268268406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16/100]train_loss:0.00026valid_loss:0.00032\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 17 Iter 19 Train_loss: 0.0002861390239559114\n",
      "Epoch: 17 Iter 39 Train_loss: 0.0002634353004395962\n",
      "Epoch: 17 Iter 59 Train_loss: 0.00020676484564319253\n",
      "Epoch: 17 Iter 79 Train_loss: 0.0002443699340801686\n",
      "Epoch: 17 Iter 99 Train_loss: 0.0002567683986853808\n",
      "Epoch: 17 Iter 119 Train_loss: 0.00023623266315553337\n",
      "Epoch: 17 Iter 139 Train_loss: 0.0002701368648558855\n",
      "Epoch: 17 Iter 159 Train_loss: 0.0002309224655618891\n",
      "Epoch: 17 Iter 179 Train_loss: 0.0002654653799254447\n",
      "Epoch: 17 Iter 199 Train_loss: 0.00027698741178028286\n",
      "Epoch: 17 Iter 219 Train_loss: 0.000254279759246856\n",
      "Epoch: 17 Iter 239 Train_loss: 0.0002604022447485477\n",
      "Epoch: 17 Iter 259 Train_loss: 0.0002800876391120255\n",
      "Epoch: 17 Iter 279 Train_loss: 0.0002216290740761906\n",
      "Epoch: 17 Iter 299 Train_loss: 0.00022378863650374115\n",
      "Epoch: 17 Iter 319 Train_loss: 0.00024443049915134907\n",
      "Epoch: 17 Iter 339 Train_loss: 0.00025765562895685434\n",
      "Epoch: 17 Iter 359 Train_loss: 0.00021574960555881262\n",
      "Epoch: 17 Iter 379 Train_loss: 0.0002536496031098068\n",
      "Epoch: 17 Iter 399 Train_loss: 0.00021846924209967256\n",
      "Epoch: 17 Iter 419 Train_loss: 0.0002186326455557719\n",
      "Epoch: 17 Iter 439 Train_loss: 0.0002687514934223145\n",
      "Epoch: 17 Iter 459 Train_loss: 0.00025701397680677474\n",
      "Epoch: 17 Iter 479 Train_loss: 0.00025738219846971333\n",
      "Epoch: 17 Iter 499 Train_loss: 0.00022039571194909513\n",
      "Epoch: 17 Iter 519 Train_loss: 0.0002211929822806269\n",
      "Epoch: 17 Iter 539 Train_loss: 0.00023580723791383207\n",
      "Epoch: 17 Iter 559 Train_loss: 0.0002552392252255231\n",
      "Epoch: 17 Iter 579 Train_loss: 0.00023712284746579826\n",
      "Epoch: 17 Iter 599 Train_loss: 0.00023470060841646045\n",
      "Epoch: 17 Iter 619 Train_loss: 0.00024121397291310132\n",
      "Epoch: 17 Iter 639 Train_loss: 0.0002584498724900186\n",
      "Epoch: 17 Iter 659 Train_loss: 0.000254537706496194\n",
      "Epoch: 17 Iter 679 Train_loss: 0.0002447697625029832\n",
      "Epoch: 17 Iter 699 Train_loss: 0.00022782474115956575\n",
      "Epoch: 17 Iter 719 Train_loss: 0.0002423745027044788\n",
      "Epoch: 17 Iter 739 Train_loss: 0.0002109523629769683\n",
      "Epoch: 17 Iter 759 Train_loss: 0.00031210333690978587\n",
      "Epoch: 17 Iter 779 Train_loss: 0.00026993019855581224\n",
      "Epoch: 17 Iter 799 Train_loss: 0.0002715853333938867\n",
      "Epoch: 17 Iter 819 Train_loss: 0.00025010042008943856\n",
      "Epoch: 17 Iter 839 Train_loss: 0.0002403659891569987\n",
      "Epoch: 17 Iter 859 Train_loss: 0.00019607781723607332\n",
      "Epoch: 17 Iter 879 Train_loss: 0.0002594570687506348\n",
      "Epoch: 17 Iter 899 Train_loss: 0.0002580058353487402\n",
      "Epoch: 17 Iter 919 Train_loss: 0.00019959175551775843\n",
      "Epoch: 17 Iter 939 Train_loss: 0.0002970485365949571\n",
      "Epoch: 17 Iter 959 Train_loss: 0.00020752058480866253\n",
      "Epoch: 17 Iter 979 Train_loss: 0.00025233556516468525\n",
      "Epoch: 17 Iter 999 Train_loss: 0.0002949860645458102\n",
      "Epoch: 17 Iter 1019 Train_loss: 0.00022316689137369394\n",
      "Epoch: 17 Iter 1039 Train_loss: 0.00025486433878540993\n",
      "Epoch: 17 Iter 1059 Train_loss: 0.0002470574981998652\n",
      "[ 17/100]train_loss:0.00025valid_loss:0.00029\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 18 Iter 19 Train_loss: 0.00023353775031864643\n",
      "Epoch: 18 Iter 39 Train_loss: 0.00025611804448999465\n",
      "Epoch: 18 Iter 59 Train_loss: 0.00024531144299544394\n",
      "Epoch: 18 Iter 79 Train_loss: 0.00024341045354958624\n",
      "Epoch: 18 Iter 99 Train_loss: 0.00023995521769393235\n",
      "Epoch: 18 Iter 119 Train_loss: 0.00023966151638887823\n",
      "Epoch: 18 Iter 139 Train_loss: 0.0002582106098998338\n",
      "Epoch: 18 Iter 159 Train_loss: 0.0002795756154228002\n",
      "Epoch: 18 Iter 179 Train_loss: 0.00020741669868584722\n",
      "Epoch: 18 Iter 199 Train_loss: 0.00025598594220355153\n",
      "Epoch: 18 Iter 219 Train_loss: 0.00024490777286700904\n",
      "Epoch: 18 Iter 239 Train_loss: 0.000256131257629022\n",
      "Epoch: 18 Iter 259 Train_loss: 0.00024516135454177856\n",
      "Epoch: 18 Iter 279 Train_loss: 0.00023349527327809483\n",
      "Epoch: 18 Iter 299 Train_loss: 0.00022067007375881076\n",
      "Epoch: 18 Iter 319 Train_loss: 0.00021561398170888424\n",
      "Epoch: 18 Iter 339 Train_loss: 0.0002541127032600343\n",
      "Epoch: 18 Iter 359 Train_loss: 0.0002601856249384582\n",
      "Epoch: 18 Iter 379 Train_loss: 0.00026186875766143203\n",
      "Epoch: 18 Iter 399 Train_loss: 0.00023042940301820636\n",
      "Epoch: 18 Iter 419 Train_loss: 0.00024274922907352448\n",
      "Epoch: 18 Iter 439 Train_loss: 0.00022129698481876403\n",
      "Epoch: 18 Iter 459 Train_loss: 0.0002719630138017237\n",
      "Epoch: 18 Iter 479 Train_loss: 0.00024184049107134342\n",
      "Epoch: 18 Iter 499 Train_loss: 0.00024274927272927016\n",
      "Epoch: 18 Iter 519 Train_loss: 0.00027770688757300377\n",
      "Epoch: 18 Iter 539 Train_loss: 0.0002409900480415672\n",
      "Epoch: 18 Iter 559 Train_loss: 0.0002567973861005157\n",
      "Epoch: 18 Iter 579 Train_loss: 0.0002194355329265818\n",
      "Epoch: 18 Iter 599 Train_loss: 0.00022523992811329663\n",
      "Epoch: 18 Iter 619 Train_loss: 0.00024360006500501186\n",
      "Epoch: 18 Iter 639 Train_loss: 0.0002612212847452611\n",
      "Epoch: 18 Iter 659 Train_loss: 0.0002440635726088658\n",
      "Epoch: 18 Iter 679 Train_loss: 0.0003356490342412144\n",
      "Epoch: 18 Iter 699 Train_loss: 0.0002320462663192302\n",
      "Epoch: 18 Iter 719 Train_loss: 0.00023177640105132014\n",
      "Epoch: 18 Iter 739 Train_loss: 0.0002699336619116366\n",
      "Epoch: 18 Iter 759 Train_loss: 0.0002496903471183032\n",
      "Epoch: 18 Iter 779 Train_loss: 0.0002484919677954167\n",
      "Epoch: 18 Iter 799 Train_loss: 0.00024277700867969543\n",
      "Epoch: 18 Iter 819 Train_loss: 0.000247423246037215\n",
      "Epoch: 18 Iter 839 Train_loss: 0.0002346251130802557\n",
      "Epoch: 18 Iter 859 Train_loss: 0.0002395305345999077\n",
      "Epoch: 18 Iter 879 Train_loss: 0.0002586421906016767\n",
      "Epoch: 18 Iter 899 Train_loss: 0.0002111887006321922\n",
      "Epoch: 18 Iter 919 Train_loss: 0.0002715479349717498\n",
      "Epoch: 18 Iter 939 Train_loss: 0.00023916955979075283\n",
      "Epoch: 18 Iter 959 Train_loss: 0.00020639128342736512\n",
      "Epoch: 18 Iter 979 Train_loss: 0.00028309569461271167\n",
      "Epoch: 18 Iter 999 Train_loss: 0.00024065710022114217\n",
      "Epoch: 18 Iter 1019 Train_loss: 0.0002507898607291281\n",
      "Epoch: 18 Iter 1039 Train_loss: 0.00025494370493106544\n",
      "Epoch: 18 Iter 1059 Train_loss: 0.00023982326092664152\n",
      "[ 18/100]train_loss:0.00025valid_loss:0.00028\n",
      "Validation loss decreased (0.000285 --> 0.000276).  Saving model ...\n",
      "Epoch: 19 Iter 19 Train_loss: 0.0002403433172730729\n",
      "Epoch: 19 Iter 39 Train_loss: 0.0002838856016751379\n",
      "Epoch: 19 Iter 59 Train_loss: 0.0002554507809691131\n",
      "Epoch: 19 Iter 79 Train_loss: 0.000289878313196823\n",
      "Epoch: 19 Iter 99 Train_loss: 0.0002501802227925509\n",
      "Epoch: 19 Iter 119 Train_loss: 0.00024919718271121383\n",
      "Epoch: 19 Iter 139 Train_loss: 0.0002742178621701896\n",
      "Epoch: 19 Iter 159 Train_loss: 0.0002749706036411226\n",
      "Epoch: 19 Iter 179 Train_loss: 0.0002827948483172804\n",
      "Epoch: 19 Iter 199 Train_loss: 0.00020719386520795524\n",
      "Epoch: 19 Iter 219 Train_loss: 0.00023973155475687236\n",
      "Epoch: 19 Iter 239 Train_loss: 0.00021763793483842164\n",
      "Epoch: 19 Iter 259 Train_loss: 0.00022688675380777568\n",
      "Epoch: 19 Iter 279 Train_loss: 0.00023906174465082586\n",
      "Epoch: 19 Iter 299 Train_loss: 0.00022870021348353475\n",
      "Epoch: 19 Iter 319 Train_loss: 0.00024987079086713493\n",
      "Epoch: 19 Iter 339 Train_loss: 0.0002028463059104979\n",
      "Epoch: 19 Iter 359 Train_loss: 0.000247970107011497\n",
      "Epoch: 19 Iter 379 Train_loss: 0.00027739143115468323\n",
      "Epoch: 19 Iter 399 Train_loss: 0.00023774048895575106\n",
      "Epoch: 19 Iter 419 Train_loss: 0.00025304738664999604\n",
      "Epoch: 19 Iter 439 Train_loss: 0.00022441759938374162\n",
      "Epoch: 19 Iter 459 Train_loss: 0.0002612257085274905\n",
      "Epoch: 19 Iter 479 Train_loss: 0.00027724014944396913\n",
      "Epoch: 19 Iter 499 Train_loss: 0.0002892000775318593\n",
      "Epoch: 19 Iter 519 Train_loss: 0.00021914643002673984\n",
      "Epoch: 19 Iter 539 Train_loss: 0.00023617873375769705\n",
      "Epoch: 19 Iter 559 Train_loss: 0.000249171513132751\n",
      "Epoch: 19 Iter 579 Train_loss: 0.0002562045119702816\n",
      "Epoch: 19 Iter 599 Train_loss: 0.0002136816328857094\n",
      "Epoch: 19 Iter 619 Train_loss: 0.00029812834691256285\n",
      "Epoch: 19 Iter 639 Train_loss: 0.00022376877313945442\n",
      "Epoch: 19 Iter 659 Train_loss: 0.0002691708505153656\n",
      "Epoch: 19 Iter 679 Train_loss: 0.0002327680413145572\n",
      "Epoch: 19 Iter 699 Train_loss: 0.0002958861005026847\n",
      "Epoch: 19 Iter 719 Train_loss: 0.00023577854153700173\n",
      "Epoch: 19 Iter 739 Train_loss: 0.0003259844961576164\n",
      "Epoch: 19 Iter 759 Train_loss: 0.00024176423903554678\n",
      "Epoch: 19 Iter 779 Train_loss: 0.0002179873117711395\n",
      "Epoch: 19 Iter 799 Train_loss: 0.0002125882456311956\n",
      "Epoch: 19 Iter 819 Train_loss: 0.00020882851094938815\n",
      "Epoch: 19 Iter 839 Train_loss: 0.00022687754244543612\n",
      "Epoch: 19 Iter 859 Train_loss: 0.00026223488384857774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Iter 879 Train_loss: 0.0002412749017821625\n",
      "Epoch: 19 Iter 899 Train_loss: 0.0003226921253371984\n",
      "Epoch: 19 Iter 919 Train_loss: 0.00024495567777194083\n",
      "Epoch: 19 Iter 939 Train_loss: 0.00022659794194623828\n",
      "Epoch: 19 Iter 959 Train_loss: 0.00024851164198480546\n",
      "Epoch: 19 Iter 979 Train_loss: 0.00021991001267451793\n",
      "Epoch: 19 Iter 999 Train_loss: 0.0002163282479159534\n",
      "Epoch: 19 Iter 1019 Train_loss: 0.0002624576154630631\n",
      "Epoch: 19 Iter 1039 Train_loss: 0.00024165620561689138\n",
      "Epoch: 19 Iter 1059 Train_loss: 0.0002727921528276056\n",
      "[ 19/100]train_loss:0.00025valid_loss:0.00028\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 20 Iter 19 Train_loss: 0.00025664365966804326\n",
      "Epoch: 20 Iter 39 Train_loss: 0.00025554292369633913\n",
      "Epoch: 20 Iter 59 Train_loss: 0.00022840309247840196\n",
      "Epoch: 20 Iter 79 Train_loss: 0.00025508349062874913\n",
      "Epoch: 20 Iter 99 Train_loss: 0.0002334315504413098\n",
      "Epoch: 20 Iter 119 Train_loss: 0.00025223271222785115\n",
      "Epoch: 20 Iter 139 Train_loss: 0.00022057477326598018\n",
      "Epoch: 20 Iter 159 Train_loss: 0.0002451322216074914\n",
      "Epoch: 20 Iter 179 Train_loss: 0.00022312581131700426\n",
      "Epoch: 20 Iter 199 Train_loss: 0.00022229891328606755\n",
      "Epoch: 20 Iter 219 Train_loss: 0.00019591388991102576\n",
      "Epoch: 20 Iter 239 Train_loss: 0.00022031778644304723\n",
      "Epoch: 20 Iter 259 Train_loss: 0.00023562049318570644\n",
      "Epoch: 20 Iter 279 Train_loss: 0.00028705093427561224\n",
      "Epoch: 20 Iter 299 Train_loss: 0.00022572818852495402\n",
      "Epoch: 20 Iter 319 Train_loss: 0.0002575733233243227\n",
      "Epoch: 20 Iter 339 Train_loss: 0.00025178861687891185\n",
      "Epoch: 20 Iter 359 Train_loss: 0.00023439162760041654\n",
      "Epoch: 20 Iter 379 Train_loss: 0.00021582763292826712\n",
      "Epoch: 20 Iter 399 Train_loss: 0.00023518840316683054\n",
      "Epoch: 20 Iter 419 Train_loss: 0.0002676375152077526\n",
      "Epoch: 20 Iter 439 Train_loss: 0.0002573094388935715\n",
      "Epoch: 20 Iter 459 Train_loss: 0.0002336794277653098\n",
      "Epoch: 20 Iter 479 Train_loss: 0.00023304113710764796\n",
      "Epoch: 20 Iter 499 Train_loss: 0.00026764493668451905\n",
      "Epoch: 20 Iter 519 Train_loss: 0.00022342627926263958\n",
      "Epoch: 20 Iter 539 Train_loss: 0.00021292087330948561\n",
      "Epoch: 20 Iter 559 Train_loss: 0.0002583506575319916\n",
      "Epoch: 20 Iter 579 Train_loss: 0.0003002287121489644\n",
      "Epoch: 20 Iter 599 Train_loss: 0.0002362697123317048\n",
      "Epoch: 20 Iter 619 Train_loss: 0.00023866933770477772\n",
      "Epoch: 20 Iter 639 Train_loss: 0.00022736069513484836\n",
      "Epoch: 20 Iter 659 Train_loss: 0.0002675121941138059\n",
      "Epoch: 20 Iter 679 Train_loss: 0.00025480828480795026\n",
      "Epoch: 20 Iter 699 Train_loss: 0.0002464841236360371\n",
      "Epoch: 20 Iter 719 Train_loss: 0.0002246605872642249\n",
      "Epoch: 20 Iter 739 Train_loss: 0.0002523600123822689\n",
      "Epoch: 20 Iter 759 Train_loss: 0.00022210495080798864\n",
      "Epoch: 20 Iter 779 Train_loss: 0.00022429296222981066\n",
      "Epoch: 20 Iter 799 Train_loss: 0.00021194145665504038\n",
      "Epoch: 20 Iter 819 Train_loss: 0.0002846962888725102\n",
      "Epoch: 20 Iter 839 Train_loss: 0.0002635279670357704\n",
      "Epoch: 20 Iter 859 Train_loss: 0.00025534204905852675\n",
      "Epoch: 20 Iter 879 Train_loss: 0.0001960572408279404\n",
      "Epoch: 20 Iter 899 Train_loss: 0.00023829344718251377\n",
      "Epoch: 20 Iter 919 Train_loss: 0.000263920403085649\n",
      "Epoch: 20 Iter 939 Train_loss: 0.00027393316850066185\n",
      "Epoch: 20 Iter 959 Train_loss: 0.0002372922608628869\n",
      "Epoch: 20 Iter 979 Train_loss: 0.0002608928771223873\n",
      "Epoch: 20 Iter 999 Train_loss: 0.0002352915471419692\n",
      "Epoch: 20 Iter 1019 Train_loss: 0.000246377574512735\n",
      "Epoch: 20 Iter 1039 Train_loss: 0.0002585653564892709\n",
      "Epoch: 20 Iter 1059 Train_loss: 0.00025374212418682873\n",
      "[ 20/100]train_loss:0.00024valid_loss:0.00027\n",
      "Validation loss decreased (0.000276 --> 0.000269).  Saving model ...\n",
      "Epoch: 21 Iter 19 Train_loss: 0.00023228257487062365\n",
      "Epoch: 21 Iter 39 Train_loss: 0.0002442592231091112\n",
      "Epoch: 21 Iter 59 Train_loss: 0.00020277794101275504\n",
      "Epoch: 21 Iter 79 Train_loss: 0.0002209064841736108\n",
      "Epoch: 21 Iter 99 Train_loss: 0.00025329214986413717\n",
      "Epoch: 21 Iter 119 Train_loss: 0.0002699292672332376\n",
      "Epoch: 21 Iter 139 Train_loss: 0.000300552521366626\n",
      "Epoch: 21 Iter 159 Train_loss: 0.00022634549532085657\n",
      "Epoch: 21 Iter 179 Train_loss: 0.00021428683248814195\n",
      "Epoch: 21 Iter 199 Train_loss: 0.00023597518156748265\n",
      "Epoch: 21 Iter 219 Train_loss: 0.0002271838893648237\n",
      "Epoch: 21 Iter 239 Train_loss: 0.00026869907742366195\n",
      "Epoch: 21 Iter 259 Train_loss: 0.0002325822861166671\n",
      "Epoch: 21 Iter 279 Train_loss: 0.00022047400125302374\n",
      "Epoch: 21 Iter 299 Train_loss: 0.00024029116320889443\n",
      "Epoch: 21 Iter 319 Train_loss: 0.00024006811145227402\n",
      "Epoch: 21 Iter 339 Train_loss: 0.00024738788488321006\n",
      "Epoch: 21 Iter 359 Train_loss: 0.00024064345052465796\n",
      "Epoch: 21 Iter 379 Train_loss: 0.0002232023689430207\n",
      "Epoch: 21 Iter 399 Train_loss: 0.0002477049420122057\n",
      "Epoch: 21 Iter 419 Train_loss: 0.0002729981788434088\n",
      "Epoch: 21 Iter 439 Train_loss: 0.00025355734396725893\n",
      "Epoch: 21 Iter 459 Train_loss: 0.00022738079132977873\n",
      "Epoch: 21 Iter 479 Train_loss: 0.00026236785924993455\n",
      "Epoch: 21 Iter 499 Train_loss: 0.00022453436395153403\n",
      "Epoch: 21 Iter 519 Train_loss: 0.00022502752835862339\n",
      "Epoch: 21 Iter 539 Train_loss: 0.00023572103236801922\n",
      "Epoch: 21 Iter 559 Train_loss: 0.0002747549151536077\n",
      "Epoch: 21 Iter 579 Train_loss: 0.0002495234366506338\n",
      "Epoch: 21 Iter 599 Train_loss: 0.00022663528216071427\n",
      "Epoch: 21 Iter 619 Train_loss: 0.00022751746291760355\n",
      "Epoch: 21 Iter 639 Train_loss: 0.00021942077728454024\n",
      "Epoch: 21 Iter 659 Train_loss: 0.00022724684095010161\n",
      "Epoch: 21 Iter 679 Train_loss: 0.0002324427623534575\n",
      "Epoch: 21 Iter 699 Train_loss: 0.00023271649843081832\n",
      "Epoch: 21 Iter 719 Train_loss: 0.00021848313917871565\n",
      "Epoch: 21 Iter 739 Train_loss: 0.00023504506680183113\n",
      "Epoch: 21 Iter 759 Train_loss: 0.0002463183191139251\n",
      "Epoch: 21 Iter 779 Train_loss: 0.0002467790327500552\n",
      "Epoch: 21 Iter 799 Train_loss: 0.0002155124384444207\n",
      "Epoch: 21 Iter 819 Train_loss: 0.0002680258185137063\n",
      "Epoch: 21 Iter 839 Train_loss: 0.0002762111835181713\n",
      "Epoch: 21 Iter 859 Train_loss: 0.00024473899975419044\n",
      "Epoch: 21 Iter 879 Train_loss: 0.0002535477979108691\n",
      "Epoch: 21 Iter 899 Train_loss: 0.00023992046772036701\n",
      "Epoch: 21 Iter 919 Train_loss: 0.00025301051209680736\n",
      "Epoch: 21 Iter 939 Train_loss: 0.00024101098824758083\n",
      "Epoch: 21 Iter 959 Train_loss: 0.00023235920525621623\n",
      "Epoch: 21 Iter 979 Train_loss: 0.00025191527674905956\n",
      "Epoch: 21 Iter 999 Train_loss: 0.00021580213797278702\n",
      "Epoch: 21 Iter 1019 Train_loss: 0.0002203424519393593\n",
      "Epoch: 21 Iter 1039 Train_loss: 0.000223379916860722\n",
      "Epoch: 21 Iter 1059 Train_loss: 0.00025870828540064394\n",
      "[ 21/100]train_loss:0.00024valid_loss:0.00028\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 22 Iter 19 Train_loss: 0.0002642632171045989\n",
      "Epoch: 22 Iter 39 Train_loss: 0.00021886081958655268\n",
      "Epoch: 22 Iter 59 Train_loss: 0.00023082368716131896\n",
      "Epoch: 22 Iter 79 Train_loss: 0.0002120485733030364\n",
      "Epoch: 22 Iter 99 Train_loss: 0.00024900599964894354\n",
      "Epoch: 22 Iter 119 Train_loss: 0.000239442044403404\n",
      "Epoch: 22 Iter 139 Train_loss: 0.0002335931349080056\n",
      "Epoch: 22 Iter 159 Train_loss: 0.00024861886049620807\n",
      "Epoch: 22 Iter 179 Train_loss: 0.00023392096045427024\n",
      "Epoch: 22 Iter 199 Train_loss: 0.00022232261835597456\n",
      "Epoch: 22 Iter 219 Train_loss: 0.00026538956444710493\n",
      "Epoch: 22 Iter 239 Train_loss: 0.00028932758141309023\n",
      "Epoch: 22 Iter 259 Train_loss: 0.0002643451443873346\n",
      "Epoch: 22 Iter 279 Train_loss: 0.0002017303486354649\n",
      "Epoch: 22 Iter 299 Train_loss: 0.00018710254516918212\n",
      "Epoch: 22 Iter 319 Train_loss: 0.0002422185061732307\n",
      "Epoch: 22 Iter 339 Train_loss: 0.00022889632964506745\n",
      "Epoch: 22 Iter 359 Train_loss: 0.0002618633152451366\n",
      "Epoch: 22 Iter 379 Train_loss: 0.00023183805751614273\n",
      "Epoch: 22 Iter 399 Train_loss: 0.00022692758648190647\n",
      "Epoch: 22 Iter 419 Train_loss: 0.00026633060770109296\n",
      "Epoch: 22 Iter 439 Train_loss: 0.00021447114704642445\n",
      "Epoch: 22 Iter 459 Train_loss: 0.0002737573522608727\n",
      "Epoch: 22 Iter 479 Train_loss: 0.00024631520500406623\n",
      "Epoch: 22 Iter 499 Train_loss: 0.000244370341533795\n",
      "Epoch: 22 Iter 519 Train_loss: 0.00022929778788238764\n",
      "Epoch: 22 Iter 539 Train_loss: 0.0002084363513858989\n",
      "Epoch: 22 Iter 559 Train_loss: 0.00025392096722498536\n",
      "Epoch: 22 Iter 579 Train_loss: 0.0002587058406788856\n",
      "Epoch: 22 Iter 599 Train_loss: 0.00021686994296032935\n",
      "Epoch: 22 Iter 619 Train_loss: 0.00021993026894051582\n",
      "Epoch: 22 Iter 639 Train_loss: 0.0002375743060838431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Iter 659 Train_loss: 0.0002627979847602546\n",
      "Epoch: 22 Iter 679 Train_loss: 0.00020863943791482598\n",
      "Epoch: 22 Iter 699 Train_loss: 0.00028181920060887933\n",
      "Epoch: 22 Iter 719 Train_loss: 0.00022934220032766461\n",
      "Epoch: 22 Iter 739 Train_loss: 0.00020598947594407946\n",
      "Epoch: 22 Iter 759 Train_loss: 0.00026595877716317773\n",
      "Epoch: 22 Iter 779 Train_loss: 0.00023124401923269033\n",
      "Epoch: 22 Iter 799 Train_loss: 0.00020908938313368708\n",
      "Epoch: 22 Iter 819 Train_loss: 0.0001911060098791495\n",
      "Epoch: 22 Iter 839 Train_loss: 0.00022928773250896484\n",
      "Epoch: 22 Iter 859 Train_loss: 0.00022900948533788323\n",
      "Epoch: 22 Iter 879 Train_loss: 0.00031126823159866035\n",
      "Epoch: 22 Iter 899 Train_loss: 0.00023806747049093246\n",
      "Epoch: 22 Iter 919 Train_loss: 0.0002245515352115035\n",
      "Epoch: 22 Iter 939 Train_loss: 0.00022364399046637118\n",
      "Epoch: 22 Iter 959 Train_loss: 0.00021068615023978055\n",
      "Epoch: 22 Iter 979 Train_loss: 0.00021758863294962794\n",
      "Epoch: 22 Iter 999 Train_loss: 0.00022020396136213094\n",
      "Epoch: 22 Iter 1019 Train_loss: 0.0002676885633263737\n",
      "Epoch: 22 Iter 1039 Train_loss: 0.00021513781393878162\n",
      "Epoch: 22 Iter 1059 Train_loss: 0.00025309776538051665\n",
      "[ 22/100]train_loss:0.00024valid_loss:0.00027\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 23 Iter 19 Train_loss: 0.0002204424818046391\n",
      "Epoch: 23 Iter 39 Train_loss: 0.0002897858212236315\n",
      "Epoch: 23 Iter 59 Train_loss: 0.00020534104260150343\n",
      "Epoch: 23 Iter 79 Train_loss: 0.0002240201720269397\n",
      "Epoch: 23 Iter 99 Train_loss: 0.00017860945081338286\n",
      "Epoch: 23 Iter 119 Train_loss: 0.0002213668340118602\n",
      "Epoch: 23 Iter 139 Train_loss: 0.0002333216107217595\n",
      "Epoch: 23 Iter 159 Train_loss: 0.0002382777165621519\n",
      "Epoch: 23 Iter 179 Train_loss: 0.00021786631259601563\n",
      "Epoch: 23 Iter 199 Train_loss: 0.00026136331143788993\n",
      "Epoch: 23 Iter 219 Train_loss: 0.00021003859001211822\n",
      "Epoch: 23 Iter 239 Train_loss: 0.00027213006978854537\n",
      "Epoch: 23 Iter 259 Train_loss: 0.0002239300956716761\n",
      "Epoch: 23 Iter 279 Train_loss: 0.00025972365983761847\n",
      "Epoch: 23 Iter 299 Train_loss: 0.00022060620540287346\n",
      "Epoch: 23 Iter 319 Train_loss: 0.00020467730064410716\n",
      "Epoch: 23 Iter 339 Train_loss: 0.00021809907048009336\n",
      "Epoch: 23 Iter 359 Train_loss: 0.0002537265536375344\n",
      "Epoch: 23 Iter 379 Train_loss: 0.0003151824639644474\n",
      "Epoch: 23 Iter 399 Train_loss: 0.00019279358093626797\n",
      "Epoch: 23 Iter 419 Train_loss: 0.00025124047533608973\n",
      "Epoch: 23 Iter 439 Train_loss: 0.0002995183749590069\n",
      "Epoch: 23 Iter 459 Train_loss: 0.00020318085444159806\n",
      "Epoch: 23 Iter 479 Train_loss: 0.00027989150839857757\n",
      "Epoch: 23 Iter 499 Train_loss: 0.0002153354580514133\n",
      "Epoch: 23 Iter 519 Train_loss: 0.00021749666484538466\n",
      "Epoch: 23 Iter 539 Train_loss: 0.0002435455098748207\n",
      "Epoch: 23 Iter 559 Train_loss: 0.00022228645684663206\n",
      "Epoch: 23 Iter 579 Train_loss: 0.00026625089230947196\n",
      "Epoch: 23 Iter 599 Train_loss: 0.00025916172307915986\n",
      "Epoch: 23 Iter 619 Train_loss: 0.00020141432469245046\n",
      "Epoch: 23 Iter 639 Train_loss: 0.0002452282060403377\n",
      "Epoch: 23 Iter 659 Train_loss: 0.0002430278982501477\n",
      "Epoch: 23 Iter 679 Train_loss: 0.00023886577400844544\n",
      "Epoch: 23 Iter 699 Train_loss: 0.0002727292594499886\n",
      "Epoch: 23 Iter 719 Train_loss: 0.0002405857085250318\n",
      "Epoch: 23 Iter 739 Train_loss: 0.0002648600493557751\n",
      "Epoch: 23 Iter 759 Train_loss: 0.00019119313219562173\n",
      "Epoch: 23 Iter 779 Train_loss: 0.00022340846771840006\n",
      "Epoch: 23 Iter 799 Train_loss: 0.00023260217858478427\n",
      "Epoch: 23 Iter 819 Train_loss: 0.00023086286091711372\n",
      "Epoch: 23 Iter 839 Train_loss: 0.00022858627198729664\n",
      "Epoch: 23 Iter 859 Train_loss: 0.00020049743761774153\n",
      "Epoch: 23 Iter 879 Train_loss: 0.00020801872597076\n",
      "Epoch: 23 Iter 899 Train_loss: 0.00027472598594613373\n",
      "Epoch: 23 Iter 919 Train_loss: 0.00022267548774834722\n",
      "Epoch: 23 Iter 939 Train_loss: 0.00023272770340554416\n",
      "Epoch: 23 Iter 959 Train_loss: 0.00027413995121605694\n",
      "Epoch: 23 Iter 979 Train_loss: 0.0002985628671012819\n",
      "Epoch: 23 Iter 999 Train_loss: 0.00020827673142775893\n",
      "Epoch: 23 Iter 1019 Train_loss: 0.00025181067758239806\n",
      "Epoch: 23 Iter 1039 Train_loss: 0.0002836165076587349\n",
      "Epoch: 23 Iter 1059 Train_loss: 0.0002822904207278043\n",
      "[ 23/100]train_loss:0.00024valid_loss:0.00027\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 24 Iter 19 Train_loss: 0.00022254764917306602\n",
      "Epoch: 24 Iter 39 Train_loss: 0.0002648461377248168\n",
      "Epoch: 24 Iter 59 Train_loss: 0.00021800196554977447\n",
      "Epoch: 24 Iter 79 Train_loss: 0.00021610620024148375\n",
      "Epoch: 24 Iter 99 Train_loss: 0.00023127958411350846\n",
      "Epoch: 24 Iter 119 Train_loss: 0.00030614054412581027\n",
      "Epoch: 24 Iter 139 Train_loss: 0.00024732842575758696\n",
      "Epoch: 24 Iter 159 Train_loss: 0.00022795410768594593\n",
      "Epoch: 24 Iter 179 Train_loss: 0.00023361662169918418\n",
      "Epoch: 24 Iter 199 Train_loss: 0.00021414006187114865\n",
      "Epoch: 24 Iter 219 Train_loss: 0.00020771264098584652\n",
      "Epoch: 24 Iter 239 Train_loss: 0.00022287377214524895\n",
      "Epoch: 24 Iter 259 Train_loss: 0.00023787487589288503\n",
      "Epoch: 24 Iter 279 Train_loss: 0.0002452101616654545\n",
      "Epoch: 24 Iter 299 Train_loss: 0.00021804709103889763\n",
      "Epoch: 24 Iter 319 Train_loss: 0.00024714518804103136\n",
      "Epoch: 24 Iter 339 Train_loss: 0.00023408875858876854\n",
      "Epoch: 24 Iter 359 Train_loss: 0.0002777094196062535\n",
      "Epoch: 24 Iter 379 Train_loss: 0.00022768352937418967\n",
      "Epoch: 24 Iter 399 Train_loss: 0.00022763328161090612\n",
      "Epoch: 24 Iter 419 Train_loss: 0.00024169331300072372\n",
      "Epoch: 24 Iter 439 Train_loss: 0.0002121410652762279\n",
      "Epoch: 24 Iter 459 Train_loss: 0.00023118211538530886\n",
      "Epoch: 24 Iter 479 Train_loss: 0.00019781713490374386\n",
      "Epoch: 24 Iter 499 Train_loss: 0.0002389769651927054\n",
      "Epoch: 24 Iter 519 Train_loss: 0.00022404480841942132\n",
      "Epoch: 24 Iter 539 Train_loss: 0.00025551661383360624\n",
      "Epoch: 24 Iter 559 Train_loss: 0.00020667145145125687\n",
      "Epoch: 24 Iter 579 Train_loss: 0.0002610470983199775\n",
      "Epoch: 24 Iter 599 Train_loss: 0.0002059816033579409\n",
      "Epoch: 24 Iter 619 Train_loss: 0.000223667491809465\n",
      "Epoch: 24 Iter 639 Train_loss: 0.00021669101261068135\n",
      "Epoch: 24 Iter 659 Train_loss: 0.0002311756688868627\n",
      "Epoch: 24 Iter 679 Train_loss: 0.00023908373259473592\n",
      "Epoch: 24 Iter 699 Train_loss: 0.00023106258595362306\n",
      "Epoch: 24 Iter 719 Train_loss: 0.00024178448074962944\n",
      "Epoch: 24 Iter 739 Train_loss: 0.00021878635743632913\n",
      "Epoch: 24 Iter 759 Train_loss: 0.00023691462411079556\n",
      "Epoch: 24 Iter 779 Train_loss: 0.00021616840967908502\n",
      "Epoch: 24 Iter 799 Train_loss: 0.00022272761270869523\n",
      "Epoch: 24 Iter 819 Train_loss: 0.00024193657736759633\n",
      "Epoch: 24 Iter 839 Train_loss: 0.0003009832289535552\n",
      "Epoch: 24 Iter 859 Train_loss: 0.00025903101777657866\n",
      "Epoch: 24 Iter 879 Train_loss: 0.00028940269839949906\n",
      "Epoch: 24 Iter 899 Train_loss: 0.00028820199077017605\n",
      "Epoch: 24 Iter 919 Train_loss: 0.0002574009995441884\n",
      "Epoch: 24 Iter 939 Train_loss: 0.00025210599415004253\n",
      "Epoch: 24 Iter 959 Train_loss: 0.00023346305533777922\n",
      "Epoch: 24 Iter 979 Train_loss: 0.00024946036865003407\n",
      "Epoch: 24 Iter 999 Train_loss: 0.0002637480793055147\n",
      "Epoch: 24 Iter 1019 Train_loss: 0.00020619128190446645\n",
      "Epoch: 24 Iter 1039 Train_loss: 0.00022809725487604737\n",
      "Epoch: 24 Iter 1059 Train_loss: 0.00026127256569452584\n",
      "[ 24/100]train_loss:0.00024valid_loss:0.00026\n",
      "Validation loss decreased (0.000269 --> 0.000260).  Saving model ...\n",
      "Epoch: 25 Iter 19 Train_loss: 0.0002578986168373376\n",
      "Epoch: 25 Iter 39 Train_loss: 0.00023759342730045319\n",
      "Epoch: 25 Iter 59 Train_loss: 0.00022660702234134078\n",
      "Epoch: 25 Iter 79 Train_loss: 0.00022339174756780267\n",
      "Epoch: 25 Iter 99 Train_loss: 0.00021893078519497067\n",
      "Epoch: 25 Iter 119 Train_loss: 0.00020256295101717114\n",
      "Epoch: 25 Iter 139 Train_loss: 0.00025904897483997047\n",
      "Epoch: 25 Iter 159 Train_loss: 0.00023222313029691577\n",
      "Epoch: 25 Iter 179 Train_loss: 0.00025067789829336107\n",
      "Epoch: 25 Iter 199 Train_loss: 0.00025880071916617453\n",
      "Epoch: 25 Iter 219 Train_loss: 0.0002022839616984129\n",
      "Epoch: 25 Iter 239 Train_loss: 0.00021158301387913525\n",
      "Epoch: 25 Iter 259 Train_loss: 0.0002163658064091578\n",
      "Epoch: 25 Iter 279 Train_loss: 0.0002312452852493152\n",
      "Epoch: 25 Iter 299 Train_loss: 0.0001975774794118479\n",
      "Epoch: 25 Iter 319 Train_loss: 0.00023967973538674414\n",
      "Epoch: 25 Iter 339 Train_loss: 0.00023919381783343852\n",
      "Epoch: 25 Iter 359 Train_loss: 0.0002511161146685481\n",
      "Epoch: 25 Iter 379 Train_loss: 0.00022600321972277015\n",
      "Epoch: 25 Iter 399 Train_loss: 0.00022939783229958266\n",
      "Epoch: 25 Iter 419 Train_loss: 0.0002568606287240982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 Iter 439 Train_loss: 0.00024105761258397251\n",
      "Epoch: 25 Iter 459 Train_loss: 0.00021891255164518952\n",
      "Epoch: 25 Iter 479 Train_loss: 0.00029329757671803236\n",
      "Epoch: 25 Iter 499 Train_loss: 0.00043361770804040134\n",
      "Epoch: 25 Iter 519 Train_loss: 0.00026920143864117563\n",
      "Epoch: 25 Iter 539 Train_loss: 0.00021142997138667852\n",
      "Epoch: 25 Iter 559 Train_loss: 0.0002421597164357081\n",
      "Epoch: 25 Iter 579 Train_loss: 0.00024654733715578914\n",
      "Epoch: 25 Iter 599 Train_loss: 0.0002714437432587147\n",
      "Epoch: 25 Iter 619 Train_loss: 0.0002207997313234955\n",
      "Epoch: 25 Iter 639 Train_loss: 0.00028925773221999407\n",
      "Epoch: 25 Iter 659 Train_loss: 0.0002400567609583959\n",
      "Epoch: 25 Iter 679 Train_loss: 0.00023046282876748592\n",
      "Epoch: 25 Iter 699 Train_loss: 0.0002216415450675413\n",
      "Epoch: 25 Iter 719 Train_loss: 0.00023195416724774987\n",
      "Epoch: 25 Iter 739 Train_loss: 0.00026045815320685506\n",
      "Epoch: 25 Iter 759 Train_loss: 0.00018774830095935613\n",
      "Epoch: 25 Iter 779 Train_loss: 0.00022523535881191492\n",
      "Epoch: 25 Iter 799 Train_loss: 0.00024278378987219185\n",
      "Epoch: 25 Iter 819 Train_loss: 0.00023218931164592505\n",
      "Epoch: 25 Iter 839 Train_loss: 0.00020276324357837439\n",
      "Epoch: 25 Iter 859 Train_loss: 0.00020273160771466792\n",
      "Epoch: 25 Iter 879 Train_loss: 0.00019839068409055471\n",
      "Epoch: 25 Iter 899 Train_loss: 0.000220936126424931\n",
      "Epoch: 25 Iter 919 Train_loss: 0.0002191971434513107\n",
      "Epoch: 25 Iter 939 Train_loss: 0.00021653377916663885\n",
      "Epoch: 25 Iter 959 Train_loss: 0.0002094869560096413\n",
      "Epoch: 25 Iter 979 Train_loss: 0.00021957933495286852\n",
      "Epoch: 25 Iter 999 Train_loss: 0.00021717962226830423\n",
      "Epoch: 25 Iter 1019 Train_loss: 0.000214614556171\n",
      "Epoch: 25 Iter 1039 Train_loss: 0.00019373628310859203\n",
      "Epoch: 25 Iter 1059 Train_loss: 0.00023797932954039425\n",
      "[ 25/100]train_loss:0.00023valid_loss:0.00028\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 26 Iter 19 Train_loss: 0.00021036705584265292\n",
      "Epoch: 26 Iter 39 Train_loss: 0.00024113508698064834\n",
      "Epoch: 26 Iter 59 Train_loss: 0.0002201767492806539\n",
      "Epoch: 26 Iter 79 Train_loss: 0.00023299574968405068\n",
      "Epoch: 26 Iter 99 Train_loss: 0.00022205102141015232\n",
      "Epoch: 26 Iter 119 Train_loss: 0.00022156441991683096\n",
      "Epoch: 26 Iter 139 Train_loss: 0.00020534450595732778\n",
      "Epoch: 26 Iter 159 Train_loss: 0.00024082338495645672\n",
      "Epoch: 26 Iter 179 Train_loss: 0.00019451491243671626\n",
      "Epoch: 26 Iter 199 Train_loss: 0.00019805731426458806\n",
      "Epoch: 26 Iter 219 Train_loss: 0.00021383156126830727\n",
      "Epoch: 26 Iter 239 Train_loss: 0.00021906703477725387\n",
      "Epoch: 26 Iter 259 Train_loss: 0.00029567189631052315\n",
      "Epoch: 26 Iter 279 Train_loss: 0.00021038415434304625\n",
      "Epoch: 26 Iter 299 Train_loss: 0.00025090391864068806\n",
      "Epoch: 26 Iter 319 Train_loss: 0.0002682612102944404\n",
      "Epoch: 26 Iter 339 Train_loss: 0.00021363538689911366\n",
      "Epoch: 26 Iter 359 Train_loss: 0.00021312051103450358\n",
      "Epoch: 26 Iter 379 Train_loss: 0.00025156920310109854\n",
      "Epoch: 26 Iter 399 Train_loss: 0.00025384253240190446\n",
      "Epoch: 26 Iter 419 Train_loss: 0.0002858723164536059\n",
      "Epoch: 26 Iter 439 Train_loss: 0.00030453663202933967\n",
      "Epoch: 26 Iter 459 Train_loss: 0.00021075749828014523\n",
      "Epoch: 26 Iter 479 Train_loss: 0.00023305107606574893\n",
      "Epoch: 26 Iter 499 Train_loss: 0.0002327363472431898\n",
      "Epoch: 26 Iter 519 Train_loss: 0.00022912163694854826\n",
      "Epoch: 26 Iter 539 Train_loss: 0.00025390737573616207\n",
      "Epoch: 26 Iter 559 Train_loss: 0.00020400967332534492\n",
      "Epoch: 26 Iter 579 Train_loss: 0.00022555144096259028\n",
      "Epoch: 26 Iter 599 Train_loss: 0.00022125484247226268\n",
      "Epoch: 26 Iter 619 Train_loss: 0.00025488834944553673\n",
      "Epoch: 26 Iter 639 Train_loss: 0.00026637158589437604\n",
      "Epoch: 26 Iter 659 Train_loss: 0.00022772507509216666\n",
      "Epoch: 26 Iter 679 Train_loss: 0.0003359980182722211\n",
      "Epoch: 26 Iter 699 Train_loss: 0.00021259006462059915\n",
      "Epoch: 26 Iter 719 Train_loss: 0.0002585746406111866\n",
      "Epoch: 26 Iter 739 Train_loss: 0.00023046131536830217\n",
      "Epoch: 26 Iter 759 Train_loss: 0.00021000448032282293\n",
      "Epoch: 26 Iter 779 Train_loss: 0.0002465230936650187\n",
      "Epoch: 26 Iter 799 Train_loss: 0.00024291127920150757\n",
      "Epoch: 26 Iter 819 Train_loss: 0.0002882127882912755\n",
      "Epoch: 26 Iter 839 Train_loss: 0.000266249175183475\n",
      "Epoch: 26 Iter 859 Train_loss: 0.0002682017511688173\n",
      "Epoch: 26 Iter 879 Train_loss: 0.0002160341973649338\n",
      "Epoch: 26 Iter 899 Train_loss: 0.00024279051285702735\n",
      "Epoch: 26 Iter 919 Train_loss: 0.00024992358521558344\n",
      "Epoch: 26 Iter 939 Train_loss: 0.00021072897652629763\n",
      "Epoch: 26 Iter 959 Train_loss: 0.00019243138376623392\n",
      "Epoch: 26 Iter 979 Train_loss: 0.0002501793787814677\n",
      "Epoch: 26 Iter 999 Train_loss: 0.00021954101976007223\n",
      "Epoch: 26 Iter 1019 Train_loss: 0.00022496783640235662\n",
      "Epoch: 26 Iter 1039 Train_loss: 0.00019126244296785444\n",
      "Epoch: 26 Iter 1059 Train_loss: 0.0002238372399006039\n",
      "[ 26/100]train_loss:0.00023valid_loss:0.00027\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 27 Iter 19 Train_loss: 0.00021213597210589796\n",
      "Epoch: 27 Iter 39 Train_loss: 0.0002379208744969219\n",
      "Epoch: 27 Iter 59 Train_loss: 0.00021549314260482788\n",
      "Epoch: 27 Iter 79 Train_loss: 0.00018746823479887098\n",
      "Epoch: 27 Iter 99 Train_loss: 0.000277148763416335\n",
      "Epoch: 27 Iter 119 Train_loss: 0.0002091703499900177\n",
      "Epoch: 27 Iter 139 Train_loss: 0.00024895695969462395\n",
      "Epoch: 27 Iter 159 Train_loss: 0.0002156733680749312\n",
      "Epoch: 27 Iter 179 Train_loss: 0.0002173012908315286\n",
      "Epoch: 27 Iter 199 Train_loss: 0.00020770577248185873\n",
      "Epoch: 27 Iter 219 Train_loss: 0.00022870847897138447\n",
      "Epoch: 27 Iter 239 Train_loss: 0.00027553457766771317\n",
      "Epoch: 27 Iter 259 Train_loss: 0.0002325392997590825\n",
      "Epoch: 27 Iter 279 Train_loss: 0.00023438967764377594\n",
      "Epoch: 27 Iter 299 Train_loss: 0.0002071690687444061\n",
      "Epoch: 27 Iter 319 Train_loss: 0.0002179891016567126\n",
      "Epoch: 27 Iter 339 Train_loss: 0.00019060642807744443\n",
      "Epoch: 27 Iter 359 Train_loss: 0.0002625076158437878\n",
      "Epoch: 27 Iter 379 Train_loss: 0.0002357105549890548\n",
      "Epoch: 27 Iter 399 Train_loss: 0.00024265555839519948\n",
      "Epoch: 27 Iter 419 Train_loss: 0.00022319293930195272\n",
      "Epoch: 27 Iter 439 Train_loss: 0.000298439001198858\n",
      "Epoch: 27 Iter 459 Train_loss: 0.00022315027308650315\n",
      "Epoch: 27 Iter 479 Train_loss: 0.0002198662841692567\n",
      "Epoch: 27 Iter 499 Train_loss: 0.00023109730682335794\n",
      "Epoch: 27 Iter 519 Train_loss: 0.00021946639753878117\n",
      "Epoch: 27 Iter 539 Train_loss: 0.00023964587308000773\n",
      "Epoch: 27 Iter 559 Train_loss: 0.00024723043316043913\n",
      "Epoch: 27 Iter 579 Train_loss: 0.00020307321392465383\n",
      "Epoch: 27 Iter 599 Train_loss: 0.0002629866939969361\n",
      "Epoch: 27 Iter 619 Train_loss: 0.0002210541715612635\n",
      "Epoch: 27 Iter 639 Train_loss: 0.000280291133094579\n",
      "Epoch: 27 Iter 659 Train_loss: 0.00021830853074789047\n",
      "Epoch: 27 Iter 679 Train_loss: 0.00022351075313054025\n",
      "Epoch: 27 Iter 699 Train_loss: 0.00027837936067953706\n",
      "Epoch: 27 Iter 719 Train_loss: 0.00023676078126300126\n",
      "Epoch: 27 Iter 739 Train_loss: 0.00020809986745007336\n",
      "Epoch: 27 Iter 759 Train_loss: 0.0002484807337168604\n",
      "Epoch: 27 Iter 779 Train_loss: 0.0002368294954067096\n",
      "Epoch: 27 Iter 799 Train_loss: 0.00021655243472196162\n",
      "Epoch: 27 Iter 819 Train_loss: 0.0002346290129935369\n",
      "Epoch: 27 Iter 839 Train_loss: 0.0002463403798174113\n",
      "Epoch: 27 Iter 859 Train_loss: 0.00020268706430215389\n",
      "Epoch: 27 Iter 879 Train_loss: 0.00022763421293348074\n",
      "Epoch: 27 Iter 899 Train_loss: 0.00031966459937393665\n",
      "Epoch: 27 Iter 919 Train_loss: 0.00022254305076785386\n",
      "Epoch: 27 Iter 939 Train_loss: 0.00025081337662413716\n",
      "Epoch: 27 Iter 959 Train_loss: 0.00024022936122491956\n",
      "Epoch: 27 Iter 979 Train_loss: 0.00023201879230327904\n",
      "Epoch: 27 Iter 999 Train_loss: 0.0002717987517826259\n",
      "Epoch: 27 Iter 1019 Train_loss: 0.00020686288189608604\n",
      "Epoch: 27 Iter 1039 Train_loss: 0.00022899657778907567\n",
      "Epoch: 27 Iter 1059 Train_loss: 0.00023715256247669458\n",
      "[ 27/100]train_loss:0.00023valid_loss:0.00028\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 28 Iter 19 Train_loss: 0.000225382114876993\n",
      "Epoch: 28 Iter 39 Train_loss: 0.00019530490681063384\n",
      "Epoch: 28 Iter 59 Train_loss: 0.0002352492301724851\n",
      "Epoch: 28 Iter 79 Train_loss: 0.00022170762531459332\n",
      "Epoch: 28 Iter 99 Train_loss: 0.0002086250315187499\n",
      "Epoch: 28 Iter 119 Train_loss: 0.00019191317551303655\n",
      "Epoch: 28 Iter 139 Train_loss: 0.00022884116333443671\n",
      "Epoch: 28 Iter 159 Train_loss: 0.0001882841606857255\n",
      "Epoch: 28 Iter 179 Train_loss: 0.0002161676820833236\n",
      "Epoch: 28 Iter 199 Train_loss: 0.0002464517892803997\n",
      "Epoch: 28 Iter 219 Train_loss: 0.0002255146682728082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 Iter 239 Train_loss: 0.00021602526248898357\n",
      "Epoch: 28 Iter 259 Train_loss: 0.0002570634242147207\n",
      "Epoch: 28 Iter 279 Train_loss: 0.00022843664919491857\n",
      "Epoch: 28 Iter 299 Train_loss: 0.00021392881171777844\n",
      "Epoch: 28 Iter 319 Train_loss: 0.00021563553309533745\n",
      "Epoch: 28 Iter 339 Train_loss: 0.00021495818509720266\n",
      "Epoch: 28 Iter 359 Train_loss: 0.00021886757167521864\n",
      "Epoch: 28 Iter 379 Train_loss: 0.00021072196250315756\n",
      "Epoch: 28 Iter 399 Train_loss: 0.00023181294091045856\n",
      "Epoch: 28 Iter 419 Train_loss: 0.00026921724202111363\n",
      "Epoch: 28 Iter 439 Train_loss: 0.00022005710343364626\n",
      "Epoch: 28 Iter 459 Train_loss: 0.0002172423992305994\n",
      "Epoch: 28 Iter 479 Train_loss: 0.00022707060270477086\n",
      "Epoch: 28 Iter 499 Train_loss: 0.00017565068264957517\n",
      "Epoch: 28 Iter 519 Train_loss: 0.00019723156583495438\n",
      "Epoch: 28 Iter 539 Train_loss: 0.0002330800925847143\n",
      "Epoch: 28 Iter 559 Train_loss: 0.00022584959515370429\n",
      "Epoch: 28 Iter 579 Train_loss: 0.00024292999296449125\n",
      "Epoch: 28 Iter 599 Train_loss: 0.0002038103702943772\n",
      "Epoch: 28 Iter 619 Train_loss: 0.00027977206627838314\n",
      "Epoch: 28 Iter 639 Train_loss: 0.0001955180923687294\n",
      "Epoch: 28 Iter 659 Train_loss: 0.00024053198285400867\n",
      "Epoch: 28 Iter 679 Train_loss: 0.00021871173521503806\n",
      "Epoch: 28 Iter 699 Train_loss: 0.00019058611360378563\n",
      "Epoch: 28 Iter 719 Train_loss: 0.0002248199307359755\n",
      "Epoch: 28 Iter 739 Train_loss: 0.0002619884617161006\n",
      "Epoch: 28 Iter 759 Train_loss: 0.00022738109691999853\n",
      "Epoch: 28 Iter 779 Train_loss: 0.00022802363673690706\n",
      "Epoch: 28 Iter 799 Train_loss: 0.0002116592222591862\n",
      "Epoch: 28 Iter 819 Train_loss: 0.0002420296659693122\n",
      "Epoch: 28 Iter 839 Train_loss: 0.00023613288067281246\n",
      "Epoch: 28 Iter 859 Train_loss: 0.0002250682737212628\n",
      "Epoch: 28 Iter 879 Train_loss: 0.00021584166097454727\n",
      "Epoch: 28 Iter 899 Train_loss: 0.0002958503318950534\n",
      "Epoch: 28 Iter 919 Train_loss: 0.00025323053705506027\n",
      "Epoch: 28 Iter 939 Train_loss: 0.00020288843370508403\n",
      "Epoch: 28 Iter 959 Train_loss: 0.00021144913625903428\n",
      "Epoch: 28 Iter 979 Train_loss: 0.00022044790966901928\n",
      "Epoch: 28 Iter 999 Train_loss: 0.00023495240020565689\n",
      "Epoch: 28 Iter 1019 Train_loss: 0.0002162917808163911\n",
      "Epoch: 28 Iter 1039 Train_loss: 0.00021144334459677339\n",
      "Epoch: 28 Iter 1059 Train_loss: 0.00021463099983520806\n",
      "[ 28/100]train_loss:0.00023valid_loss:0.00027\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch: 29 Iter 19 Train_loss: 0.00022952916333451867\n",
      "Epoch: 29 Iter 39 Train_loss: 0.000249288888880983\n",
      "Epoch: 29 Iter 59 Train_loss: 0.0002194996050093323\n",
      "Epoch: 29 Iter 79 Train_loss: 0.00022530568821821362\n",
      "Epoch: 29 Iter 99 Train_loss: 0.00022859562886878848\n",
      "Epoch: 29 Iter 119 Train_loss: 0.00023366099048871547\n",
      "Epoch: 29 Iter 139 Train_loss: 0.00022254329815041274\n",
      "Epoch: 29 Iter 159 Train_loss: 0.00018582827760837972\n",
      "Epoch: 29 Iter 179 Train_loss: 0.00021627265959978104\n",
      "Epoch: 29 Iter 199 Train_loss: 0.00021258022752590477\n",
      "Epoch: 29 Iter 219 Train_loss: 0.00019900029292330146\n",
      "Epoch: 29 Iter 239 Train_loss: 0.00022449257085099816\n",
      "Epoch: 29 Iter 259 Train_loss: 0.00023090701142791659\n",
      "Epoch: 29 Iter 279 Train_loss: 0.00021078516147099435\n",
      "Epoch: 29 Iter 299 Train_loss: 0.0002581991138868034\n",
      "Epoch: 29 Iter 319 Train_loss: 0.00021364426356740296\n",
      "Epoch: 29 Iter 339 Train_loss: 0.00021952675888314843\n",
      "Epoch: 29 Iter 359 Train_loss: 0.0002531949139665812\n",
      "Epoch: 29 Iter 379 Train_loss: 0.00023657096608076245\n",
      "Epoch: 29 Iter 399 Train_loss: 0.00022607709979638457\n",
      "Epoch: 29 Iter 419 Train_loss: 0.0002339447382837534\n",
      "Epoch: 29 Iter 439 Train_loss: 0.0002102855796692893\n",
      "Epoch: 29 Iter 459 Train_loss: 0.00021273088350426406\n",
      "Epoch: 29 Iter 479 Train_loss: 0.00020372544531710446\n",
      "Epoch: 29 Iter 499 Train_loss: 0.00021563035261351615\n",
      "Epoch: 29 Iter 519 Train_loss: 0.00022607001301366836\n",
      "Epoch: 29 Iter 539 Train_loss: 0.00025624484987929463\n",
      "Epoch: 29 Iter 559 Train_loss: 0.00023511522158514708\n",
      "Epoch: 29 Iter 579 Train_loss: 0.00021609332179650664\n",
      "Epoch: 29 Iter 599 Train_loss: 0.00019812476239167154\n",
      "Epoch: 29 Iter 619 Train_loss: 0.0002019718085648492\n",
      "Epoch: 29 Iter 639 Train_loss: 0.00021977585856802762\n",
      "Epoch: 29 Iter 659 Train_loss: 0.00019804874318651855\n",
      "Epoch: 29 Iter 679 Train_loss: 0.00024207441310863942\n",
      "Epoch: 29 Iter 699 Train_loss: 0.00023076111392583698\n",
      "Epoch: 29 Iter 719 Train_loss: 0.00019615120254456997\n",
      "Epoch: 29 Iter 739 Train_loss: 0.00024953967658802867\n",
      "Epoch: 29 Iter 759 Train_loss: 0.0001960507215699181\n",
      "Epoch: 29 Iter 779 Train_loss: 0.0002117477124556899\n",
      "Epoch: 29 Iter 799 Train_loss: 0.00022507109679281712\n",
      "Epoch: 29 Iter 819 Train_loss: 0.00029586482560262084\n",
      "Epoch: 29 Iter 839 Train_loss: 0.00025472600827924907\n",
      "Epoch: 29 Iter 859 Train_loss: 0.00020904278790112585\n",
      "Epoch: 29 Iter 879 Train_loss: 0.00024337846843991429\n",
      "Epoch: 29 Iter 899 Train_loss: 0.0002509885816834867\n",
      "Epoch: 29 Iter 919 Train_loss: 0.00021022396686021239\n",
      "Epoch: 29 Iter 939 Train_loss: 0.0002110406494466588\n",
      "Epoch: 29 Iter 959 Train_loss: 0.0002479873946867883\n",
      "Epoch: 29 Iter 979 Train_loss: 0.00022533380251843482\n",
      "Epoch: 29 Iter 999 Train_loss: 0.00022764038294553757\n",
      "Epoch: 29 Iter 1019 Train_loss: 0.0002172271051676944\n",
      "Epoch: 29 Iter 1039 Train_loss: 0.00021631084382534027\n",
      "Epoch: 29 Iter 1059 Train_loss: 0.00022853277914691716\n",
      "[ 29/100]train_loss:0.00023valid_loss:0.00028\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch: 30 Iter 19 Train_loss: 0.00022197171347215772\n",
      "Epoch: 30 Iter 39 Train_loss: 0.00022962766524869949\n",
      "Epoch: 30 Iter 59 Train_loss: 0.00021580394241027534\n",
      "Epoch: 30 Iter 79 Train_loss: 0.00026720663299784064\n",
      "Epoch: 30 Iter 99 Train_loss: 0.00018903471936937422\n",
      "Epoch: 30 Iter 119 Train_loss: 0.00022518295736517757\n",
      "Epoch: 30 Iter 139 Train_loss: 0.00019806834461633116\n",
      "Epoch: 30 Iter 159 Train_loss: 0.00022696537780575454\n",
      "Epoch: 30 Iter 179 Train_loss: 0.0002442173718009144\n",
      "Epoch: 30 Iter 199 Train_loss: 0.00021103529434185475\n",
      "Epoch: 30 Iter 219 Train_loss: 0.00022312291548587382\n",
      "Epoch: 30 Iter 239 Train_loss: 0.00021899274725001305\n",
      "Epoch: 30 Iter 259 Train_loss: 0.00027106970082968473\n",
      "Epoch: 30 Iter 279 Train_loss: 0.0001949564612004906\n",
      "Epoch: 30 Iter 299 Train_loss: 0.00020397568005137146\n",
      "Epoch: 30 Iter 319 Train_loss: 0.00020272450638003647\n",
      "Epoch: 30 Iter 339 Train_loss: 0.00022488694230560213\n",
      "Epoch: 30 Iter 359 Train_loss: 0.00023286024224944413\n",
      "Epoch: 30 Iter 379 Train_loss: 0.00024973024846985936\n",
      "Epoch: 30 Iter 399 Train_loss: 0.00019448749662842602\n",
      "Epoch: 30 Iter 419 Train_loss: 0.00023061811225488782\n",
      "Epoch: 30 Iter 439 Train_loss: 0.00022993149468675256\n",
      "Epoch: 30 Iter 459 Train_loss: 0.00022109616838861257\n",
      "Epoch: 30 Iter 479 Train_loss: 0.00023034233890939504\n",
      "Epoch: 30 Iter 499 Train_loss: 0.00021021101565565914\n",
      "Epoch: 30 Iter 519 Train_loss: 0.00020335684530436993\n",
      "Epoch: 30 Iter 539 Train_loss: 0.00025296429521404207\n",
      "Epoch: 30 Iter 559 Train_loss: 0.0002142146258847788\n",
      "Epoch: 30 Iter 579 Train_loss: 0.00026768448879010975\n",
      "Epoch: 30 Iter 599 Train_loss: 0.00021687717526219785\n",
      "Epoch: 30 Iter 619 Train_loss: 0.00020409129501786083\n",
      "Epoch: 30 Iter 639 Train_loss: 0.0002170115039916709\n",
      "Epoch: 30 Iter 659 Train_loss: 0.00022163157700560987\n",
      "Epoch: 30 Iter 679 Train_loss: 0.00022954719315748662\n",
      "Epoch: 30 Iter 699 Train_loss: 0.0002338938065804541\n",
      "Epoch: 30 Iter 719 Train_loss: 0.00020571901404764503\n",
      "Epoch: 30 Iter 739 Train_loss: 0.00018734936020337045\n",
      "Epoch: 30 Iter 759 Train_loss: 0.0002553200756665319\n",
      "Epoch: 30 Iter 779 Train_loss: 0.0002204137563239783\n",
      "Epoch: 30 Iter 799 Train_loss: 0.0001963932445505634\n",
      "Epoch: 30 Iter 819 Train_loss: 0.00023608900664839894\n",
      "Epoch: 30 Iter 839 Train_loss: 0.00022928031103219837\n",
      "Epoch: 30 Iter 859 Train_loss: 0.0002206618373747915\n",
      "Epoch: 30 Iter 879 Train_loss: 0.00020959820540156215\n",
      "Epoch: 30 Iter 899 Train_loss: 0.00021987089712638408\n",
      "Epoch: 30 Iter 919 Train_loss: 0.00022075008018873632\n",
      "Epoch: 30 Iter 939 Train_loss: 0.0002626966161187738\n",
      "Epoch: 30 Iter 959 Train_loss: 0.00022083760995883495\n",
      "Epoch: 30 Iter 979 Train_loss: 0.00023373965814244002\n",
      "Epoch: 30 Iter 999 Train_loss: 0.00020435800252016634\n",
      "Epoch: 30 Iter 1019 Train_loss: 0.00021099261357448995\n",
      "Epoch: 30 Iter 1039 Train_loss: 0.0002559697604738176\n",
      "Epoch: 30 Iter 1059 Train_loss: 0.00021224630472715944\n",
      "[ 30/100]train_loss:0.00023valid_loss:0.00026\n",
      "Validation loss decreased (0.000260 --> 0.000257).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 Iter 19 Train_loss: 0.0002524421433918178\n",
      "Epoch: 31 Iter 39 Train_loss: 0.0002608357463032007\n",
      "Epoch: 31 Iter 59 Train_loss: 0.00026335124857723713\n",
      "Epoch: 31 Iter 79 Train_loss: 0.0002112951478920877\n",
      "Epoch: 31 Iter 99 Train_loss: 0.00022372332750819623\n",
      "Epoch: 31 Iter 119 Train_loss: 0.00019262765999883413\n",
      "Epoch: 31 Iter 139 Train_loss: 0.00021833140635862947\n",
      "Epoch: 31 Iter 159 Train_loss: 0.00020804442465305328\n",
      "Epoch: 31 Iter 179 Train_loss: 0.00018834156799130142\n",
      "Epoch: 31 Iter 199 Train_loss: 0.00020998578111175448\n",
      "Epoch: 31 Iter 219 Train_loss: 0.00019007486116606742\n",
      "Epoch: 31 Iter 239 Train_loss: 0.00025634924531914294\n",
      "Epoch: 31 Iter 259 Train_loss: 0.0002318347105756402\n",
      "Epoch: 31 Iter 279 Train_loss: 0.00022060390620026737\n",
      "Epoch: 31 Iter 299 Train_loss: 0.0001893076696433127\n",
      "Epoch: 31 Iter 319 Train_loss: 0.00021911048679612577\n",
      "Epoch: 31 Iter 339 Train_loss: 0.00021533870312850922\n",
      "Epoch: 31 Iter 359 Train_loss: 0.00021556043066084385\n",
      "Epoch: 31 Iter 379 Train_loss: 0.00025590418954379857\n",
      "Epoch: 31 Iter 399 Train_loss: 0.0002932380884885788\n",
      "Epoch: 31 Iter 419 Train_loss: 0.00021297542843967676\n",
      "Epoch: 31 Iter 439 Train_loss: 0.00023705160128884017\n",
      "Epoch: 31 Iter 459 Train_loss: 0.00022185953275766224\n",
      "Epoch: 31 Iter 479 Train_loss: 0.00021295255282893777\n",
      "Epoch: 31 Iter 499 Train_loss: 0.00020684575429186225\n",
      "Epoch: 31 Iter 519 Train_loss: 0.00017885732813738286\n",
      "Epoch: 31 Iter 539 Train_loss: 0.00024366712023038417\n",
      "Epoch: 31 Iter 559 Train_loss: 0.0002083895669784397\n",
      "Epoch: 31 Iter 579 Train_loss: 0.0002544108428992331\n",
      "Epoch: 31 Iter 599 Train_loss: 0.0002610025985632092\n",
      "Epoch: 31 Iter 619 Train_loss: 0.00019708098261617124\n",
      "Epoch: 31 Iter 639 Train_loss: 0.00023483583936467767\n",
      "Epoch: 31 Iter 659 Train_loss: 0.00030621624318882823\n",
      "Epoch: 31 Iter 679 Train_loss: 0.000199483911274001\n",
      "Epoch: 31 Iter 699 Train_loss: 0.00023845180112402886\n",
      "Epoch: 31 Iter 719 Train_loss: 0.00021424084843602031\n",
      "Epoch: 31 Iter 739 Train_loss: 0.00025354474200867116\n",
      "Epoch: 31 Iter 759 Train_loss: 0.0002461134863551706\n",
      "Epoch: 31 Iter 779 Train_loss: 0.0002597368147689849\n",
      "Epoch: 31 Iter 799 Train_loss: 0.00024367666628677398\n",
      "Epoch: 31 Iter 819 Train_loss: 0.000225059746298939\n",
      "Epoch: 31 Iter 839 Train_loss: 0.0002376106713199988\n",
      "Epoch: 31 Iter 859 Train_loss: 0.00022173176694195718\n",
      "Epoch: 31 Iter 879 Train_loss: 0.0002058393001789227\n",
      "Epoch: 31 Iter 899 Train_loss: 0.00020503290579654276\n",
      "Epoch: 31 Iter 919 Train_loss: 0.00022056742454878986\n",
      "Epoch: 31 Iter 939 Train_loss: 0.00025099082267843187\n",
      "Epoch: 31 Iter 959 Train_loss: 0.00021877883409615606\n",
      "Epoch: 31 Iter 979 Train_loss: 0.00018295217887498438\n",
      "Epoch: 31 Iter 999 Train_loss: 0.0002375147450948134\n",
      "Epoch: 31 Iter 1019 Train_loss: 0.00024001220299396664\n",
      "Epoch: 31 Iter 1039 Train_loss: 0.00021063153690192848\n",
      "Epoch: 31 Iter 1059 Train_loss: 0.00024750194279477\n",
      "[ 31/100]train_loss:0.00023valid_loss:0.00026\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 32 Iter 19 Train_loss: 0.0002554258971940726\n",
      "Epoch: 32 Iter 39 Train_loss: 0.0002187434583902359\n",
      "Epoch: 32 Iter 59 Train_loss: 0.0002038453967543319\n",
      "Epoch: 32 Iter 79 Train_loss: 0.00021919111895840615\n",
      "Epoch: 32 Iter 99 Train_loss: 0.00022114586317911744\n",
      "Epoch: 32 Iter 119 Train_loss: 0.0001999010710278526\n",
      "Epoch: 32 Iter 139 Train_loss: 0.00030005144071765244\n",
      "Epoch: 32 Iter 159 Train_loss: 0.0002399373333901167\n",
      "Epoch: 32 Iter 179 Train_loss: 0.0001897113397717476\n",
      "Epoch: 32 Iter 199 Train_loss: 0.00020640729053411633\n",
      "Epoch: 32 Iter 219 Train_loss: 0.000222891234443523\n",
      "Epoch: 32 Iter 239 Train_loss: 0.0002043252025032416\n",
      "Epoch: 32 Iter 259 Train_loss: 0.00019502629584167153\n",
      "Epoch: 32 Iter 279 Train_loss: 0.00021601011394523084\n",
      "Epoch: 32 Iter 299 Train_loss: 0.0002369247522437945\n",
      "Epoch: 32 Iter 319 Train_loss: 0.00023520688409917057\n",
      "Epoch: 32 Iter 339 Train_loss: 0.00020287839288357645\n",
      "Epoch: 32 Iter 359 Train_loss: 0.0002458250382915139\n",
      "Epoch: 32 Iter 379 Train_loss: 0.0002559732529334724\n",
      "Epoch: 32 Iter 399 Train_loss: 0.00028346749604679644\n",
      "Epoch: 32 Iter 419 Train_loss: 0.0002336751640541479\n",
      "Epoch: 32 Iter 439 Train_loss: 0.00021623764769174159\n",
      "Epoch: 32 Iter 459 Train_loss: 0.00022095083841122687\n",
      "Epoch: 32 Iter 479 Train_loss: 0.00020992675854358822\n",
      "Epoch: 32 Iter 499 Train_loss: 0.00020398545893840492\n",
      "Epoch: 32 Iter 519 Train_loss: 0.0002231192629551515\n",
      "Epoch: 32 Iter 539 Train_loss: 0.0001914203749038279\n",
      "Epoch: 32 Iter 559 Train_loss: 0.00021080236183479428\n",
      "Epoch: 32 Iter 579 Train_loss: 0.00020860425138380378\n",
      "Epoch: 32 Iter 599 Train_loss: 0.00021976257266942412\n",
      "Epoch: 32 Iter 619 Train_loss: 0.00023019003856461495\n",
      "Epoch: 32 Iter 639 Train_loss: 0.0002245656360173598\n",
      "Epoch: 32 Iter 659 Train_loss: 0.0002215767017332837\n",
      "Epoch: 32 Iter 679 Train_loss: 0.0002368465211475268\n",
      "Epoch: 32 Iter 699 Train_loss: 0.00023515448265243322\n",
      "Epoch: 32 Iter 719 Train_loss: 0.00022175956110004336\n",
      "Epoch: 32 Iter 739 Train_loss: 0.0001993007172131911\n",
      "Epoch: 32 Iter 759 Train_loss: 0.0001867434475570917\n",
      "Epoch: 32 Iter 779 Train_loss: 0.00020245873020030558\n",
      "Epoch: 32 Iter 799 Train_loss: 0.0002337507321499288\n",
      "Epoch: 32 Iter 819 Train_loss: 0.0002013846969930455\n",
      "Epoch: 32 Iter 839 Train_loss: 0.00021151785040274262\n",
      "Epoch: 32 Iter 859 Train_loss: 0.0002093895891448483\n",
      "Epoch: 32 Iter 879 Train_loss: 0.00027457994292490184\n",
      "Epoch: 32 Iter 899 Train_loss: 0.00024343050608877093\n",
      "Epoch: 32 Iter 919 Train_loss: 0.00023501082614529878\n",
      "Epoch: 32 Iter 939 Train_loss: 0.00023855814652051777\n",
      "Epoch: 32 Iter 959 Train_loss: 0.00019698952382896096\n",
      "Epoch: 32 Iter 979 Train_loss: 0.00024111651873681694\n",
      "Epoch: 32 Iter 999 Train_loss: 0.00020993083307985216\n",
      "Epoch: 32 Iter 1019 Train_loss: 0.00021250382997095585\n",
      "Epoch: 32 Iter 1039 Train_loss: 0.00023525417782366276\n",
      "Epoch: 32 Iter 1059 Train_loss: 0.00026078487280756235\n",
      "[ 32/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 33 Iter 19 Train_loss: 0.00023166353639680892\n",
      "Epoch: 33 Iter 39 Train_loss: 0.0002493740466888994\n",
      "Epoch: 33 Iter 59 Train_loss: 0.00023510547180194408\n",
      "Epoch: 33 Iter 79 Train_loss: 0.000238653679843992\n",
      "Epoch: 33 Iter 99 Train_loss: 0.00023202072770800442\n",
      "Epoch: 33 Iter 119 Train_loss: 0.00024098972789943218\n",
      "Epoch: 33 Iter 139 Train_loss: 0.0002084587758872658\n",
      "Epoch: 33 Iter 159 Train_loss: 0.0002014063356909901\n",
      "Epoch: 33 Iter 179 Train_loss: 0.00020901369862258434\n",
      "Epoch: 33 Iter 199 Train_loss: 0.00022207944130059332\n",
      "Epoch: 33 Iter 219 Train_loss: 0.00026593063375912607\n",
      "Epoch: 33 Iter 239 Train_loss: 0.00022762076696380973\n",
      "Epoch: 33 Iter 259 Train_loss: 0.00019383220933377743\n",
      "Epoch: 33 Iter 279 Train_loss: 0.00021288951393216848\n",
      "Epoch: 33 Iter 299 Train_loss: 0.0002371877053519711\n",
      "Epoch: 33 Iter 319 Train_loss: 0.0002461823751218617\n",
      "Epoch: 33 Iter 339 Train_loss: 0.00020280896569602191\n",
      "Epoch: 33 Iter 359 Train_loss: 0.0002051389601547271\n",
      "Epoch: 33 Iter 379 Train_loss: 0.00020103951101191342\n",
      "Epoch: 33 Iter 399 Train_loss: 0.00018349768652115017\n",
      "Epoch: 33 Iter 419 Train_loss: 0.00023800776398275048\n",
      "Epoch: 33 Iter 439 Train_loss: 0.00022350315703079104\n",
      "Epoch: 33 Iter 459 Train_loss: 0.00020738779858220369\n",
      "Epoch: 33 Iter 479 Train_loss: 0.00025663324049673975\n",
      "Epoch: 33 Iter 499 Train_loss: 0.000200055685127154\n",
      "Epoch: 33 Iter 519 Train_loss: 0.0002598222636152059\n",
      "Epoch: 33 Iter 539 Train_loss: 0.00018567174265626818\n",
      "Epoch: 33 Iter 559 Train_loss: 0.0001879584015114233\n",
      "Epoch: 33 Iter 579 Train_loss: 0.0002066879387712106\n",
      "Epoch: 33 Iter 599 Train_loss: 0.00021771641331724823\n",
      "Epoch: 33 Iter 619 Train_loss: 0.0001930810249177739\n",
      "Epoch: 33 Iter 639 Train_loss: 0.0002595964469946921\n",
      "Epoch: 33 Iter 659 Train_loss: 0.0002428126463200897\n",
      "Epoch: 33 Iter 679 Train_loss: 0.00019763977616094053\n",
      "Epoch: 33 Iter 699 Train_loss: 0.00023497972870245576\n",
      "Epoch: 33 Iter 719 Train_loss: 0.00021328417642507702\n",
      "Epoch: 33 Iter 739 Train_loss: 0.00018575724971015006\n",
      "Epoch: 33 Iter 759 Train_loss: 0.00020146243332419544\n",
      "Epoch: 33 Iter 779 Train_loss: 0.00021130769164301455\n",
      "Epoch: 33 Iter 799 Train_loss: 0.00025654322234913707\n",
      "Epoch: 33 Iter 819 Train_loss: 0.00025941492640413344\n",
      "Epoch: 33 Iter 839 Train_loss: 0.00020797095203306526\n",
      "Epoch: 33 Iter 859 Train_loss: 0.00020766771922353655\n",
      "Epoch: 33 Iter 879 Train_loss: 0.00021510939404834062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 Iter 899 Train_loss: 0.00023083877749741077\n",
      "Epoch: 33 Iter 919 Train_loss: 0.00023272287216968834\n",
      "Epoch: 33 Iter 939 Train_loss: 0.00024007068714126945\n",
      "Epoch: 33 Iter 959 Train_loss: 0.00023097168013919145\n",
      "Epoch: 33 Iter 979 Train_loss: 0.0001832258130889386\n",
      "Epoch: 33 Iter 999 Train_loss: 0.00019823710317723453\n",
      "Epoch: 33 Iter 1019 Train_loss: 0.0002674011921044439\n",
      "Epoch: 33 Iter 1039 Train_loss: 0.00018311056192032993\n",
      "Epoch: 33 Iter 1059 Train_loss: 0.0001985794515348971\n",
      "[ 33/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 34 Iter 19 Train_loss: 0.00022688400349579751\n",
      "Epoch: 34 Iter 39 Train_loss: 0.0002192923566326499\n",
      "Epoch: 34 Iter 59 Train_loss: 0.00019712833454832435\n",
      "Epoch: 34 Iter 79 Train_loss: 0.00023576768580824137\n",
      "Epoch: 34 Iter 99 Train_loss: 0.0002152103988919407\n",
      "Epoch: 34 Iter 119 Train_loss: 0.00024062562442850322\n",
      "Epoch: 34 Iter 139 Train_loss: 0.00022425821225624532\n",
      "Epoch: 34 Iter 159 Train_loss: 0.00022320567222777754\n",
      "Epoch: 34 Iter 179 Train_loss: 0.00021457098773680627\n",
      "Epoch: 34 Iter 199 Train_loss: 0.00018793853814713657\n",
      "Epoch: 34 Iter 219 Train_loss: 0.0002190256054745987\n",
      "Epoch: 34 Iter 239 Train_loss: 0.00022781449661124498\n",
      "Epoch: 34 Iter 259 Train_loss: 0.00023983900609891862\n",
      "Epoch: 34 Iter 279 Train_loss: 0.00020856928313151002\n",
      "Epoch: 34 Iter 299 Train_loss: 0.0002467975136823952\n",
      "Epoch: 34 Iter 319 Train_loss: 0.00022439366148319095\n",
      "Epoch: 34 Iter 339 Train_loss: 0.0002062003914033994\n",
      "Epoch: 34 Iter 359 Train_loss: 0.00020993447105865926\n",
      "Epoch: 34 Iter 379 Train_loss: 0.00017761896015144885\n",
      "Epoch: 34 Iter 399 Train_loss: 0.00018532607646193355\n",
      "Epoch: 34 Iter 419 Train_loss: 0.0001902311050798744\n",
      "Epoch: 34 Iter 439 Train_loss: 0.00025889588869176805\n",
      "Epoch: 34 Iter 459 Train_loss: 0.00021057935373391956\n",
      "Epoch: 34 Iter 479 Train_loss: 0.00020283617777749896\n",
      "Epoch: 34 Iter 499 Train_loss: 0.0002359072823310271\n",
      "Epoch: 34 Iter 519 Train_loss: 0.00024032272631302476\n",
      "Epoch: 34 Iter 539 Train_loss: 0.0002181992313126102\n",
      "Epoch: 34 Iter 559 Train_loss: 0.0002194958651671186\n",
      "Epoch: 34 Iter 579 Train_loss: 0.00019123524543829262\n",
      "Epoch: 34 Iter 599 Train_loss: 0.00020949228201061487\n",
      "Epoch: 34 Iter 619 Train_loss: 0.000200916183530353\n",
      "Epoch: 34 Iter 639 Train_loss: 0.00022859747696202248\n",
      "Epoch: 34 Iter 659 Train_loss: 0.00022083643125370145\n",
      "Epoch: 34 Iter 679 Train_loss: 0.00019822210015263408\n",
      "Epoch: 34 Iter 699 Train_loss: 0.00021374471543822438\n",
      "Epoch: 34 Iter 719 Train_loss: 0.00021929854119662195\n",
      "Epoch: 34 Iter 739 Train_loss: 0.00019489681289996952\n",
      "Epoch: 34 Iter 759 Train_loss: 0.00021352697513066232\n",
      "Epoch: 34 Iter 779 Train_loss: 0.00020594832312781364\n",
      "Epoch: 34 Iter 799 Train_loss: 0.00020687567302957177\n",
      "Epoch: 34 Iter 819 Train_loss: 0.00020708904776256531\n",
      "Epoch: 34 Iter 839 Train_loss: 0.0001952682068804279\n",
      "Epoch: 34 Iter 859 Train_loss: 0.00021571959950961173\n",
      "Epoch: 34 Iter 879 Train_loss: 0.00021814159117639065\n",
      "Epoch: 34 Iter 899 Train_loss: 0.00018521220772527158\n",
      "Epoch: 34 Iter 919 Train_loss: 0.00021760753588750958\n",
      "Epoch: 34 Iter 939 Train_loss: 0.00022871539113111794\n",
      "Epoch: 34 Iter 959 Train_loss: 0.0002643298066686839\n",
      "Epoch: 34 Iter 979 Train_loss: 0.0002583022869657725\n",
      "Epoch: 34 Iter 999 Train_loss: 0.00022010352404322475\n",
      "Epoch: 34 Iter 1019 Train_loss: 0.00019049501861445606\n",
      "Epoch: 34 Iter 1039 Train_loss: 0.00023307694937102497\n",
      "Epoch: 34 Iter 1059 Train_loss: 0.00029489205917343497\n",
      "[ 34/100]train_loss:0.00022valid_loss:0.00028\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch: 35 Iter 19 Train_loss: 0.00024277721240650862\n",
      "Epoch: 35 Iter 39 Train_loss: 0.0001900102070067078\n",
      "Epoch: 35 Iter 59 Train_loss: 0.0002007320144912228\n",
      "Epoch: 35 Iter 79 Train_loss: 0.0002266760857310146\n",
      "Epoch: 35 Iter 99 Train_loss: 0.00019630842143669724\n",
      "Epoch: 35 Iter 119 Train_loss: 0.00020083530398551375\n",
      "Epoch: 35 Iter 139 Train_loss: 0.00021393380302470177\n",
      "Epoch: 35 Iter 159 Train_loss: 0.0001865941158030182\n",
      "Epoch: 35 Iter 179 Train_loss: 0.0002040843537542969\n",
      "Epoch: 35 Iter 199 Train_loss: 0.0001890802086563781\n",
      "Epoch: 35 Iter 219 Train_loss: 0.00023826687538530678\n",
      "Epoch: 35 Iter 239 Train_loss: 0.00021126464707776904\n",
      "Epoch: 35 Iter 259 Train_loss: 0.0002316693280590698\n",
      "Epoch: 35 Iter 279 Train_loss: 0.00022839881421532482\n",
      "Epoch: 35 Iter 299 Train_loss: 0.0002894613135140389\n",
      "Epoch: 35 Iter 319 Train_loss: 0.00022432934201788157\n",
      "Epoch: 35 Iter 339 Train_loss: 0.00023618976410944015\n",
      "Epoch: 35 Iter 359 Train_loss: 0.0002019485255004838\n",
      "Epoch: 35 Iter 379 Train_loss: 0.00018701633962336928\n",
      "Epoch: 35 Iter 399 Train_loss: 0.0001974596962099895\n",
      "Epoch: 35 Iter 419 Train_loss: 0.00020714294805657119\n",
      "Epoch: 35 Iter 439 Train_loss: 0.00030661289929412305\n",
      "Epoch: 35 Iter 459 Train_loss: 0.0002110034693032503\n",
      "Epoch: 35 Iter 479 Train_loss: 0.00021091442613396794\n",
      "Epoch: 35 Iter 499 Train_loss: 0.00018295718473382294\n",
      "Epoch: 35 Iter 519 Train_loss: 0.0002283706417074427\n",
      "Epoch: 35 Iter 539 Train_loss: 0.00022891040134709328\n",
      "Epoch: 35 Iter 559 Train_loss: 0.0002338864142075181\n",
      "Epoch: 35 Iter 579 Train_loss: 0.0002473079366609454\n",
      "Epoch: 35 Iter 599 Train_loss: 0.00021445217134896666\n",
      "Epoch: 35 Iter 619 Train_loss: 0.0002047308225883171\n",
      "Epoch: 35 Iter 639 Train_loss: 0.00023286923533305526\n",
      "Epoch: 35 Iter 659 Train_loss: 0.00029591983184218407\n",
      "Epoch: 35 Iter 679 Train_loss: 0.00023286686337087303\n",
      "Epoch: 35 Iter 699 Train_loss: 0.0002189010992879048\n",
      "Epoch: 35 Iter 719 Train_loss: 0.00019386847270652652\n",
      "Epoch: 35 Iter 739 Train_loss: 0.0002099599951179698\n",
      "Epoch: 35 Iter 759 Train_loss: 0.0001801301841624081\n",
      "Epoch: 35 Iter 779 Train_loss: 0.00020339501497801393\n",
      "Epoch: 35 Iter 799 Train_loss: 0.00022958753106649965\n",
      "Epoch: 35 Iter 819 Train_loss: 0.00021046483016107231\n",
      "Epoch: 35 Iter 839 Train_loss: 0.00022139822249300778\n",
      "Epoch: 35 Iter 859 Train_loss: 0.00022707777679897845\n",
      "Epoch: 35 Iter 879 Train_loss: 0.00026683055330067873\n",
      "Epoch: 35 Iter 899 Train_loss: 0.00031386406044475734\n",
      "Epoch: 35 Iter 919 Train_loss: 0.00022782395535614341\n",
      "Epoch: 35 Iter 939 Train_loss: 0.00021295233455020934\n",
      "Epoch: 35 Iter 959 Train_loss: 0.0002306867972947657\n",
      "Epoch: 35 Iter 979 Train_loss: 0.00023027841234579682\n",
      "Epoch: 35 Iter 999 Train_loss: 0.00021476700203493237\n",
      "Epoch: 35 Iter 1019 Train_loss: 0.0001958032080437988\n",
      "Epoch: 35 Iter 1039 Train_loss: 0.0002420856908429414\n",
      "Epoch: 35 Iter 1059 Train_loss: 0.00020561754354275763\n",
      "[ 35/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch: 36 Iter 19 Train_loss: 0.00020851478620897979\n",
      "Epoch: 36 Iter 39 Train_loss: 0.0002180060400860384\n",
      "Epoch: 36 Iter 59 Train_loss: 0.0002572266384959221\n",
      "Epoch: 36 Iter 79 Train_loss: 0.0002371070731896907\n",
      "Epoch: 36 Iter 99 Train_loss: 0.0001862834469648078\n",
      "Epoch: 36 Iter 119 Train_loss: 0.00020604765450116247\n",
      "Epoch: 36 Iter 139 Train_loss: 0.00020438524370547384\n",
      "Epoch: 36 Iter 159 Train_loss: 0.00023306184448301792\n",
      "Epoch: 36 Iter 179 Train_loss: 0.00020256006973795593\n",
      "Epoch: 36 Iter 199 Train_loss: 0.00020523816056083888\n",
      "Epoch: 36 Iter 219 Train_loss: 0.00019178312504664063\n",
      "Epoch: 36 Iter 239 Train_loss: 0.00019516532483976334\n",
      "Epoch: 36 Iter 259 Train_loss: 0.0002182675525546074\n",
      "Epoch: 36 Iter 279 Train_loss: 0.00021208410908002406\n",
      "Epoch: 36 Iter 299 Train_loss: 0.0002027870068559423\n",
      "Epoch: 36 Iter 319 Train_loss: 0.00022387155331671238\n",
      "Epoch: 36 Iter 339 Train_loss: 0.0002201609459007159\n",
      "Epoch: 36 Iter 359 Train_loss: 0.00022112861915957183\n",
      "Epoch: 36 Iter 379 Train_loss: 0.0002092849463224411\n",
      "Epoch: 36 Iter 399 Train_loss: 0.00019827464711852372\n",
      "Epoch: 36 Iter 419 Train_loss: 0.0001963948889169842\n",
      "Epoch: 36 Iter 439 Train_loss: 0.00021875386300962418\n",
      "Epoch: 36 Iter 459 Train_loss: 0.00019964869716204703\n",
      "Epoch: 36 Iter 479 Train_loss: 0.0002198849688284099\n",
      "Epoch: 36 Iter 499 Train_loss: 0.00019572229939512908\n",
      "Epoch: 36 Iter 519 Train_loss: 0.00024289080465678126\n",
      "Epoch: 36 Iter 539 Train_loss: 0.00018980707682203501\n",
      "Epoch: 36 Iter 559 Train_loss: 0.00021263443341013044\n",
      "Epoch: 36 Iter 579 Train_loss: 0.00023314121062867343\n",
      "Epoch: 36 Iter 599 Train_loss: 0.00020543343271128833\n",
      "Epoch: 36 Iter 619 Train_loss: 0.00019728390907403082\n",
      "Epoch: 36 Iter 639 Train_loss: 0.000239490982494317\n",
      "Epoch: 36 Iter 659 Train_loss: 0.00022829398221801966\n",
      "Epoch: 36 Iter 679 Train_loss: 0.0002174763212678954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 Iter 699 Train_loss: 0.00021109463705215603\n",
      "Epoch: 36 Iter 719 Train_loss: 0.0002557758125476539\n",
      "Epoch: 36 Iter 739 Train_loss: 0.00022953335428610444\n",
      "Epoch: 36 Iter 759 Train_loss: 0.00023241518647409976\n",
      "Epoch: 36 Iter 779 Train_loss: 0.0002076056698570028\n",
      "Epoch: 36 Iter 799 Train_loss: 0.00021385631407611072\n",
      "Epoch: 36 Iter 819 Train_loss: 0.00019188577425666153\n",
      "Epoch: 36 Iter 839 Train_loss: 0.0002591427764855325\n",
      "Epoch: 36 Iter 859 Train_loss: 0.0001931390434037894\n",
      "Epoch: 36 Iter 879 Train_loss: 0.00019711934146471322\n",
      "Epoch: 36 Iter 899 Train_loss: 0.00026093580527231097\n",
      "Epoch: 36 Iter 919 Train_loss: 0.00021437193208839744\n",
      "Epoch: 36 Iter 939 Train_loss: 0.00021620573534164578\n",
      "Epoch: 36 Iter 959 Train_loss: 0.00023451153538189828\n",
      "Epoch: 36 Iter 979 Train_loss: 0.00023265593335963786\n",
      "Epoch: 36 Iter 999 Train_loss: 0.0002534901141189039\n",
      "Epoch: 36 Iter 1019 Train_loss: 0.00020856811897829175\n",
      "Epoch: 36 Iter 1039 Train_loss: 0.00020315793517511338\n",
      "Epoch: 36 Iter 1059 Train_loss: 0.00019839733431581408\n",
      "[ 36/100]train_loss:0.00022valid_loss:0.00027\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch: 37 Iter 19 Train_loss: 0.00019063707441091537\n",
      "Epoch: 37 Iter 39 Train_loss: 0.00020304346980992705\n",
      "Epoch: 37 Iter 59 Train_loss: 0.00019925847300328314\n",
      "Epoch: 37 Iter 79 Train_loss: 0.00020246919302735478\n",
      "Epoch: 37 Iter 99 Train_loss: 0.00020027165010105819\n",
      "Epoch: 37 Iter 119 Train_loss: 0.0002750495041254908\n",
      "Epoch: 37 Iter 139 Train_loss: 0.0002438571973470971\n",
      "Epoch: 37 Iter 159 Train_loss: 0.00022780930157750845\n",
      "Epoch: 37 Iter 179 Train_loss: 0.00023178780975285918\n",
      "Epoch: 37 Iter 199 Train_loss: 0.0002315608726348728\n",
      "Epoch: 37 Iter 219 Train_loss: 0.00021370504691731185\n",
      "Epoch: 37 Iter 239 Train_loss: 0.00023601151769980788\n",
      "Epoch: 37 Iter 259 Train_loss: 0.00021142351033631712\n",
      "Epoch: 37 Iter 279 Train_loss: 0.00022193099721334875\n",
      "Epoch: 37 Iter 299 Train_loss: 0.00019060581689700484\n",
      "Epoch: 37 Iter 319 Train_loss: 0.00021496685803867877\n",
      "Epoch: 37 Iter 339 Train_loss: 0.00021819359972141683\n",
      "Epoch: 37 Iter 359 Train_loss: 0.00025401703896932304\n",
      "Epoch: 37 Iter 379 Train_loss: 0.00020575210510287434\n",
      "Epoch: 37 Iter 399 Train_loss: 0.00022615598572883755\n",
      "Epoch: 37 Iter 419 Train_loss: 0.00023257934662979096\n",
      "Epoch: 37 Iter 439 Train_loss: 0.00023885141126811504\n",
      "Epoch: 37 Iter 459 Train_loss: 0.0002010638127103448\n",
      "Epoch: 37 Iter 479 Train_loss: 0.00021996075520291924\n",
      "Epoch: 37 Iter 499 Train_loss: 0.00020927029254380614\n",
      "Epoch: 37 Iter 519 Train_loss: 0.00023227503697853535\n",
      "Epoch: 37 Iter 539 Train_loss: 0.00020361202768981457\n",
      "Epoch: 37 Iter 559 Train_loss: 0.00021550888777710497\n",
      "Epoch: 37 Iter 579 Train_loss: 0.0002067120949504897\n",
      "Epoch: 37 Iter 599 Train_loss: 0.00019953917944803834\n",
      "Epoch: 37 Iter 619 Train_loss: 0.00017821797518990934\n",
      "Epoch: 37 Iter 639 Train_loss: 0.00022080370399635285\n",
      "Epoch: 37 Iter 659 Train_loss: 0.00021233930601738393\n",
      "Epoch: 37 Iter 679 Train_loss: 0.00020405944087542593\n",
      "Epoch: 37 Iter 699 Train_loss: 0.00021670327987521887\n",
      "Epoch: 37 Iter 719 Train_loss: 0.00020135918748565018\n",
      "Epoch: 37 Iter 739 Train_loss: 0.00023307427181862295\n",
      "Epoch: 37 Iter 759 Train_loss: 0.00018434652884025127\n",
      "Epoch: 37 Iter 779 Train_loss: 0.00019386009080335498\n",
      "Epoch: 37 Iter 799 Train_loss: 0.00019904768851120025\n",
      "Epoch: 37 Iter 819 Train_loss: 0.0001957553904503584\n",
      "Epoch: 37 Iter 839 Train_loss: 0.00018148140225093812\n",
      "Epoch: 37 Iter 859 Train_loss: 0.00020852420129813254\n",
      "Epoch: 37 Iter 879 Train_loss: 0.00021367445879150182\n",
      "Epoch: 37 Iter 899 Train_loss: 0.00022385249030776322\n",
      "Epoch: 37 Iter 919 Train_loss: 0.0002058542158920318\n",
      "Epoch: 37 Iter 939 Train_loss: 0.00023069410235621035\n",
      "Epoch: 37 Iter 959 Train_loss: 0.0002152140805264935\n",
      "Epoch: 37 Iter 979 Train_loss: 0.00020570328342728317\n",
      "Epoch: 37 Iter 999 Train_loss: 0.00019424461061134934\n",
      "Epoch: 37 Iter 1019 Train_loss: 0.00022685984731651843\n",
      "Epoch: 37 Iter 1039 Train_loss: 0.000217226188397035\n",
      "Epoch: 37 Iter 1059 Train_loss: 0.0002825056144502014\n",
      "[ 37/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch: 38 Iter 19 Train_loss: 0.00020043444237671793\n",
      "Epoch: 38 Iter 39 Train_loss: 0.00019525123934727162\n",
      "Epoch: 38 Iter 59 Train_loss: 0.00022614090994466096\n",
      "Epoch: 38 Iter 79 Train_loss: 0.00017676591232884675\n",
      "Epoch: 38 Iter 99 Train_loss: 0.00022021621407475322\n",
      "Epoch: 38 Iter 119 Train_loss: 0.00021106572239659727\n",
      "Epoch: 38 Iter 139 Train_loss: 0.0002122140140272677\n",
      "Epoch: 38 Iter 159 Train_loss: 0.00021465418103616685\n",
      "Epoch: 38 Iter 179 Train_loss: 0.0002026164293056354\n",
      "Epoch: 38 Iter 199 Train_loss: 0.0002688187814783305\n",
      "Epoch: 38 Iter 219 Train_loss: 0.00019126008555758744\n",
      "Epoch: 38 Iter 239 Train_loss: 0.0001919260830618441\n",
      "Epoch: 38 Iter 259 Train_loss: 0.00022058348986320198\n",
      "Epoch: 38 Iter 279 Train_loss: 0.0002392241731286049\n",
      "Epoch: 38 Iter 299 Train_loss: 0.00024216444580815732\n",
      "Epoch: 38 Iter 319 Train_loss: 0.00018614073633216321\n",
      "Epoch: 38 Iter 339 Train_loss: 0.00022167194401845336\n",
      "Epoch: 38 Iter 359 Train_loss: 0.0002544659364502877\n",
      "Epoch: 38 Iter 379 Train_loss: 0.0002341562503715977\n",
      "Epoch: 38 Iter 399 Train_loss: 0.00018559160525910556\n",
      "Epoch: 38 Iter 419 Train_loss: 0.00021392338385339826\n",
      "Epoch: 38 Iter 439 Train_loss: 0.00021594922873191535\n",
      "Epoch: 38 Iter 459 Train_loss: 0.00024099083384498954\n",
      "Epoch: 38 Iter 479 Train_loss: 0.00023261649766936898\n",
      "Epoch: 38 Iter 499 Train_loss: 0.00020431354641914368\n",
      "Epoch: 38 Iter 519 Train_loss: 0.00019904338114429265\n",
      "Epoch: 38 Iter 539 Train_loss: 0.00021793275664094836\n",
      "Epoch: 38 Iter 559 Train_loss: 0.00022731124772690237\n",
      "Epoch: 38 Iter 579 Train_loss: 0.00018058890418615192\n",
      "Epoch: 38 Iter 599 Train_loss: 0.00021312279568519443\n",
      "Epoch: 38 Iter 619 Train_loss: 0.0002657987060956657\n",
      "Epoch: 38 Iter 639 Train_loss: 0.00020439000218175352\n",
      "Epoch: 38 Iter 659 Train_loss: 0.0001898025075206533\n",
      "Epoch: 38 Iter 679 Train_loss: 0.00024525137268938124\n",
      "Epoch: 38 Iter 699 Train_loss: 0.0002090917550958693\n",
      "Epoch: 38 Iter 719 Train_loss: 0.0002115585666615516\n",
      "Epoch: 38 Iter 739 Train_loss: 0.0001959779765456915\n",
      "Epoch: 38 Iter 759 Train_loss: 0.00022317109687719494\n",
      "Epoch: 38 Iter 779 Train_loss: 0.00022694290964864194\n",
      "Epoch: 38 Iter 799 Train_loss: 0.0002099639386869967\n",
      "Epoch: 38 Iter 819 Train_loss: 0.00018195348093286157\n",
      "Epoch: 38 Iter 839 Train_loss: 0.0002538992266636342\n",
      "Epoch: 38 Iter 859 Train_loss: 0.0002415062626823783\n",
      "Epoch: 38 Iter 879 Train_loss: 0.00024366100842598826\n",
      "Epoch: 38 Iter 899 Train_loss: 0.00018397379608359188\n",
      "Epoch: 38 Iter 919 Train_loss: 0.0002082616265397519\n",
      "Epoch: 38 Iter 939 Train_loss: 0.00021921085135545582\n",
      "Epoch: 38 Iter 959 Train_loss: 0.0002072429924737662\n",
      "Epoch: 38 Iter 979 Train_loss: 0.0002127054613083601\n",
      "Epoch: 38 Iter 999 Train_loss: 0.00022733033983968198\n",
      "Epoch: 38 Iter 1019 Train_loss: 0.0002216114808106795\n",
      "Epoch: 38 Iter 1039 Train_loss: 0.00025331511278636754\n",
      "Epoch: 38 Iter 1059 Train_loss: 0.00027305385447107255\n",
      "[ 38/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch: 39 Iter 19 Train_loss: 0.00027262221556156874\n",
      "Epoch: 39 Iter 39 Train_loss: 0.00021246740652713925\n",
      "Epoch: 39 Iter 59 Train_loss: 0.0002510910271666944\n",
      "Epoch: 39 Iter 79 Train_loss: 0.0002326856047147885\n",
      "Epoch: 39 Iter 99 Train_loss: 0.0002471021143719554\n",
      "Epoch: 39 Iter 119 Train_loss: 0.00019271559722255915\n",
      "Epoch: 39 Iter 139 Train_loss: 0.00021744905097875744\n",
      "Epoch: 39 Iter 159 Train_loss: 0.00018200832710135728\n",
      "Epoch: 39 Iter 179 Train_loss: 0.00018668945995159447\n",
      "Epoch: 39 Iter 199 Train_loss: 0.00019973407324869186\n",
      "Epoch: 39 Iter 219 Train_loss: 0.00020266759383957833\n",
      "Epoch: 39 Iter 239 Train_loss: 0.00019067403627559543\n",
      "Epoch: 39 Iter 259 Train_loss: 0.00022682968119625002\n",
      "Epoch: 39 Iter 279 Train_loss: 0.00018498551798984408\n",
      "Epoch: 39 Iter 299 Train_loss: 0.00021338537044357508\n",
      "Epoch: 39 Iter 319 Train_loss: 0.0002258716122014448\n",
      "Epoch: 39 Iter 339 Train_loss: 0.00017669767839834094\n",
      "Epoch: 39 Iter 359 Train_loss: 0.00020698581647593528\n",
      "Epoch: 39 Iter 379 Train_loss: 0.0002263408969156444\n",
      "Epoch: 39 Iter 399 Train_loss: 0.00023024092661216855\n",
      "Epoch: 39 Iter 419 Train_loss: 0.00023169157793745399\n",
      "Epoch: 39 Iter 439 Train_loss: 0.0002534259983804077\n",
      "Epoch: 39 Iter 459 Train_loss: 0.00019413510744925588\n",
      "Epoch: 39 Iter 479 Train_loss: 0.00022079559857957065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 Iter 499 Train_loss: 0.00021980841120239347\n",
      "Epoch: 39 Iter 519 Train_loss: 0.00021722869132645428\n",
      "Epoch: 39 Iter 539 Train_loss: 0.00021125160856172442\n",
      "Epoch: 39 Iter 559 Train_loss: 0.00022665323922410607\n",
      "Epoch: 39 Iter 579 Train_loss: 0.00023497562506236136\n",
      "Epoch: 39 Iter 599 Train_loss: 0.00023422454250976443\n",
      "Epoch: 39 Iter 619 Train_loss: 0.00023072099429555237\n",
      "Epoch: 39 Iter 639 Train_loss: 0.00020966217562090605\n",
      "Epoch: 39 Iter 659 Train_loss: 0.00020288009545765817\n",
      "Epoch: 39 Iter 679 Train_loss: 0.00025350399664603174\n",
      "Epoch: 39 Iter 699 Train_loss: 0.0002229020174127072\n",
      "Epoch: 39 Iter 719 Train_loss: 0.00019015680300071836\n",
      "Epoch: 39 Iter 739 Train_loss: 0.00018975100829266012\n",
      "Epoch: 39 Iter 759 Train_loss: 0.0002050451294053346\n",
      "Epoch: 39 Iter 779 Train_loss: 0.0002187734644394368\n",
      "Epoch: 39 Iter 799 Train_loss: 0.00022781602456234396\n",
      "Epoch: 39 Iter 819 Train_loss: 0.0001838603348005563\n",
      "Epoch: 39 Iter 839 Train_loss: 0.00021827338787261397\n",
      "Epoch: 39 Iter 859 Train_loss: 0.00022179563529789448\n",
      "Epoch: 39 Iter 879 Train_loss: 0.00020992658392060548\n",
      "Epoch: 39 Iter 899 Train_loss: 0.0002181485906476155\n",
      "Epoch: 39 Iter 919 Train_loss: 0.00022061531490180641\n",
      "Epoch: 39 Iter 939 Train_loss: 0.00022739671112503856\n",
      "Epoch: 39 Iter 959 Train_loss: 0.00018357617955189198\n",
      "Epoch: 39 Iter 979 Train_loss: 0.0001898732443805784\n",
      "Epoch: 39 Iter 999 Train_loss: 0.0002428680454613641\n",
      "Epoch: 39 Iter 1019 Train_loss: 0.00020539840625133365\n",
      "Epoch: 39 Iter 1039 Train_loss: 0.00021281829685904086\n",
      "Epoch: 39 Iter 1059 Train_loss: 0.0002926939050666988\n",
      "[ 39/100]train_loss:0.00022valid_loss:0.00027\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch: 40 Iter 19 Train_loss: 0.00022231752518564463\n",
      "Epoch: 40 Iter 39 Train_loss: 0.00022211034956853837\n",
      "Epoch: 40 Iter 59 Train_loss: 0.0002123141021002084\n",
      "Epoch: 40 Iter 79 Train_loss: 0.0002565390313975513\n",
      "Epoch: 40 Iter 99 Train_loss: 0.00021526627824641764\n",
      "Epoch: 40 Iter 119 Train_loss: 0.00018618075409904122\n",
      "Epoch: 40 Iter 139 Train_loss: 0.00022477773018181324\n",
      "Epoch: 40 Iter 159 Train_loss: 0.0002257107407785952\n",
      "Epoch: 40 Iter 179 Train_loss: 0.00022460171021521091\n",
      "Epoch: 40 Iter 199 Train_loss: 0.0002325488458154723\n",
      "Epoch: 40 Iter 219 Train_loss: 0.0002302436769241467\n",
      "Epoch: 40 Iter 239 Train_loss: 0.00019347398483660072\n",
      "Epoch: 40 Iter 259 Train_loss: 0.00023773136490490288\n",
      "Epoch: 40 Iter 279 Train_loss: 0.00021081100567243993\n",
      "Epoch: 40 Iter 299 Train_loss: 0.00017663709877524525\n",
      "Epoch: 40 Iter 319 Train_loss: 0.0002072752540698275\n",
      "Epoch: 40 Iter 339 Train_loss: 0.0001979049266083166\n",
      "Epoch: 40 Iter 359 Train_loss: 0.00022648337471764535\n",
      "Epoch: 40 Iter 379 Train_loss: 0.0002587532508186996\n",
      "Epoch: 40 Iter 399 Train_loss: 0.00019855810387525707\n",
      "Epoch: 40 Iter 419 Train_loss: 0.00018084813200403005\n",
      "Epoch: 40 Iter 439 Train_loss: 0.00020949938334524632\n",
      "Epoch: 40 Iter 459 Train_loss: 0.00019815319683402777\n",
      "Epoch: 40 Iter 479 Train_loss: 0.00020866413251496851\n",
      "Epoch: 40 Iter 499 Train_loss: 0.00018876172543969005\n",
      "Epoch: 40 Iter 519 Train_loss: 0.00022796027769800276\n",
      "Epoch: 40 Iter 539 Train_loss: 0.0002261272311443463\n",
      "Epoch: 40 Iter 559 Train_loss: 0.0002489598991815001\n",
      "Epoch: 40 Iter 579 Train_loss: 0.0002341255167266354\n",
      "Epoch: 40 Iter 599 Train_loss: 0.0002633523545227945\n",
      "Epoch: 40 Iter 619 Train_loss: 0.0002141192089766264\n",
      "Epoch: 40 Iter 639 Train_loss: 0.00021792383631691337\n",
      "Epoch: 40 Iter 659 Train_loss: 0.0002008126029977575\n",
      "Epoch: 40 Iter 679 Train_loss: 0.0001948029239429161\n",
      "Epoch: 40 Iter 699 Train_loss: 0.0002180848823627457\n",
      "Epoch: 40 Iter 719 Train_loss: 0.00022825768974144012\n",
      "Epoch: 40 Iter 739 Train_loss: 0.0002200406015617773\n",
      "Epoch: 40 Iter 759 Train_loss: 0.00022720367996953428\n",
      "Epoch: 40 Iter 779 Train_loss: 0.0002264194772578776\n",
      "Epoch: 40 Iter 799 Train_loss: 0.0002132981171598658\n",
      "Epoch: 40 Iter 819 Train_loss: 0.00024381261027883738\n",
      "Epoch: 40 Iter 839 Train_loss: 0.00024519755970686674\n",
      "Epoch: 40 Iter 859 Train_loss: 0.00020975714141968638\n",
      "Epoch: 40 Iter 879 Train_loss: 0.0001910805149236694\n",
      "Epoch: 40 Iter 899 Train_loss: 0.0002793272433336824\n",
      "Epoch: 40 Iter 919 Train_loss: 0.00021429438493214548\n",
      "Epoch: 40 Iter 939 Train_loss: 0.00027718563796952367\n",
      "Epoch: 40 Iter 959 Train_loss: 0.00022045958030503243\n",
      "Epoch: 40 Iter 979 Train_loss: 0.00021363113773986697\n",
      "Epoch: 40 Iter 999 Train_loss: 0.0001991688768612221\n",
      "Epoch: 40 Iter 1019 Train_loss: 0.0002168295904994011\n",
      "Epoch: 40 Iter 1039 Train_loss: 0.00019869461539201438\n",
      "Epoch: 40 Iter 1059 Train_loss: 0.0001956887572305277\n",
      "[ 40/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch: 41 Iter 19 Train_loss: 0.00019226125732529908\n",
      "Epoch: 41 Iter 39 Train_loss: 0.00021842190471943468\n",
      "Epoch: 41 Iter 59 Train_loss: 0.00018749039736576378\n",
      "Epoch: 41 Iter 79 Train_loss: 0.00024247719557024539\n",
      "Epoch: 41 Iter 99 Train_loss: 0.00020848882559221238\n",
      "Epoch: 41 Iter 119 Train_loss: 0.00022212817566469312\n",
      "Epoch: 41 Iter 139 Train_loss: 0.00021569666569121182\n",
      "Epoch: 41 Iter 159 Train_loss: 0.00022150448057800531\n",
      "Epoch: 41 Iter 179 Train_loss: 0.0001975038758246228\n",
      "Epoch: 41 Iter 199 Train_loss: 0.00020605768077075481\n",
      "Epoch: 41 Iter 219 Train_loss: 0.00023788149701431394\n",
      "Epoch: 41 Iter 239 Train_loss: 0.00018624078074935824\n",
      "Epoch: 41 Iter 259 Train_loss: 0.00020487335859797895\n",
      "Epoch: 41 Iter 279 Train_loss: 0.0002260408509755507\n",
      "Epoch: 41 Iter 299 Train_loss: 0.00020349465194158256\n",
      "Epoch: 41 Iter 319 Train_loss: 0.00020383542869240046\n",
      "Epoch: 41 Iter 339 Train_loss: 0.00024890259373933077\n",
      "Epoch: 41 Iter 359 Train_loss: 0.00019021004845853895\n",
      "Epoch: 41 Iter 379 Train_loss: 0.00024413013306912035\n",
      "Epoch: 41 Iter 399 Train_loss: 0.00020783286890946329\n",
      "Epoch: 41 Iter 419 Train_loss: 0.00019051917479373515\n",
      "Epoch: 41 Iter 439 Train_loss: 0.00022764669847674668\n",
      "Epoch: 41 Iter 459 Train_loss: 0.00019850782700814307\n",
      "Epoch: 41 Iter 479 Train_loss: 0.0002023043780354783\n",
      "Epoch: 41 Iter 499 Train_loss: 0.00018375985382590443\n",
      "Epoch: 41 Iter 519 Train_loss: 0.00021305835980456322\n",
      "Epoch: 41 Iter 539 Train_loss: 0.0001946768898051232\n",
      "Epoch: 41 Iter 559 Train_loss: 0.0001820683537516743\n",
      "Epoch: 41 Iter 579 Train_loss: 0.00023004335525911301\n",
      "Epoch: 41 Iter 599 Train_loss: 0.00023741810582578182\n",
      "Epoch: 41 Iter 619 Train_loss: 0.00021073051902931184\n",
      "Epoch: 41 Iter 639 Train_loss: 0.00021508921054191887\n",
      "Epoch: 41 Iter 659 Train_loss: 0.00025323693989776075\n",
      "Epoch: 41 Iter 679 Train_loss: 0.00021351853501982987\n",
      "Epoch: 41 Iter 699 Train_loss: 0.0002477859961800277\n",
      "Epoch: 41 Iter 719 Train_loss: 0.0002261779736727476\n",
      "Epoch: 41 Iter 739 Train_loss: 0.00019973622693214566\n",
      "Epoch: 41 Iter 759 Train_loss: 0.00019850705575663596\n",
      "Epoch: 41 Iter 779 Train_loss: 0.000188402394996956\n",
      "Epoch: 41 Iter 799 Train_loss: 0.0002175646077375859\n",
      "Epoch: 41 Iter 819 Train_loss: 0.00019388683722354472\n",
      "Epoch: 41 Iter 839 Train_loss: 0.00020097411470487714\n",
      "Epoch: 41 Iter 859 Train_loss: 0.0002244214410893619\n",
      "Epoch: 41 Iter 879 Train_loss: 0.00019302955479361117\n",
      "Epoch: 41 Iter 899 Train_loss: 0.00024093252432066947\n",
      "Epoch: 41 Iter 919 Train_loss: 0.00020981329726055264\n",
      "Epoch: 41 Iter 939 Train_loss: 0.00020147758186794817\n",
      "Epoch: 41 Iter 959 Train_loss: 0.00020597114053089172\n",
      "Epoch: 41 Iter 979 Train_loss: 0.0001969961595023051\n",
      "Epoch: 41 Iter 999 Train_loss: 0.0001996335486182943\n",
      "Epoch: 41 Iter 1019 Train_loss: 0.0001989269076148048\n",
      "Epoch: 41 Iter 1039 Train_loss: 0.00022552897280547768\n",
      "Epoch: 41 Iter 1059 Train_loss: 0.00019629261805675924\n",
      "[ 41/100]train_loss:0.00022valid_loss:0.00027\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch: 42 Iter 19 Train_loss: 0.0001744315231917426\n",
      "Epoch: 42 Iter 39 Train_loss: 0.00021241708600427955\n",
      "Epoch: 42 Iter 59 Train_loss: 0.00019623817934188992\n",
      "Epoch: 42 Iter 79 Train_loss: 0.00020812070579268038\n",
      "Epoch: 42 Iter 99 Train_loss: 0.00020039793162140995\n",
      "Epoch: 42 Iter 119 Train_loss: 0.00019789559883065522\n",
      "Epoch: 42 Iter 139 Train_loss: 0.00025978285702876747\n",
      "Epoch: 42 Iter 159 Train_loss: 0.00019330835493747145\n",
      "Epoch: 42 Iter 179 Train_loss: 0.00019667876767925918\n",
      "Epoch: 42 Iter 199 Train_loss: 0.00021779829694423825\n",
      "Epoch: 42 Iter 219 Train_loss: 0.0002128836786141619\n",
      "Epoch: 42 Iter 239 Train_loss: 0.0001968990545719862\n",
      "Epoch: 42 Iter 259 Train_loss: 0.0002220759924966842\n",
      "Epoch: 42 Iter 279 Train_loss: 0.0001864301011664793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 Iter 299 Train_loss: 0.00019568245625123382\n",
      "Epoch: 42 Iter 319 Train_loss: 0.0002093182411044836\n",
      "Epoch: 42 Iter 339 Train_loss: 0.00019620981765910983\n",
      "Epoch: 42 Iter 359 Train_loss: 0.00019780204456765205\n",
      "Epoch: 42 Iter 379 Train_loss: 0.0001870434934971854\n",
      "Epoch: 42 Iter 399 Train_loss: 0.0001955677435034886\n",
      "Epoch: 42 Iter 419 Train_loss: 0.0002232183760497719\n",
      "Epoch: 42 Iter 439 Train_loss: 0.00024503516033291817\n",
      "Epoch: 42 Iter 459 Train_loss: 0.00023542443523183465\n",
      "Epoch: 42 Iter 479 Train_loss: 0.00021761484094895422\n",
      "Epoch: 42 Iter 499 Train_loss: 0.00020551387569867074\n",
      "Epoch: 42 Iter 519 Train_loss: 0.00024481030413880944\n",
      "Epoch: 42 Iter 539 Train_loss: 0.0002321862557437271\n",
      "Epoch: 42 Iter 559 Train_loss: 0.00023616956605110317\n",
      "Epoch: 42 Iter 579 Train_loss: 0.00020686772768385708\n",
      "Epoch: 42 Iter 599 Train_loss: 0.00018915199325419962\n",
      "Epoch: 42 Iter 619 Train_loss: 0.00022943671501707286\n",
      "Epoch: 42 Iter 639 Train_loss: 0.00022530554269906133\n",
      "Epoch: 42 Iter 659 Train_loss: 0.00026395238819532096\n",
      "Epoch: 42 Iter 679 Train_loss: 0.00019775699183810502\n",
      "Epoch: 42 Iter 699 Train_loss: 0.00027934793615713716\n",
      "Epoch: 42 Iter 719 Train_loss: 0.00020089029567316175\n",
      "Epoch: 42 Iter 739 Train_loss: 0.000217683264054358\n",
      "Epoch: 42 Iter 759 Train_loss: 0.00019660769612528384\n",
      "Epoch: 42 Iter 779 Train_loss: 0.00019787059864029288\n",
      "Epoch: 42 Iter 799 Train_loss: 0.00021451912471093237\n",
      "Epoch: 42 Iter 819 Train_loss: 0.00019324262393638492\n",
      "Epoch: 42 Iter 839 Train_loss: 0.00020121880515944213\n",
      "Epoch: 42 Iter 859 Train_loss: 0.00020213598327245563\n",
      "Epoch: 42 Iter 879 Train_loss: 0.0002513455110602081\n",
      "Epoch: 42 Iter 899 Train_loss: 0.0002291162236360833\n",
      "Epoch: 42 Iter 919 Train_loss: 0.0002032224292634055\n",
      "Epoch: 42 Iter 939 Train_loss: 0.0002101104037137702\n",
      "Epoch: 42 Iter 959 Train_loss: 0.0002513648651074618\n",
      "Epoch: 42 Iter 979 Train_loss: 0.00020496666547842324\n",
      "Epoch: 42 Iter 999 Train_loss: 0.00022930015984456986\n",
      "Epoch: 42 Iter 1019 Train_loss: 0.00023733692069072276\n",
      "Epoch: 42 Iter 1039 Train_loss: 0.00021762419783044606\n",
      "Epoch: 42 Iter 1059 Train_loss: 0.0002071719354717061\n",
      "[ 42/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch: 43 Iter 19 Train_loss: 0.00019748690829146653\n",
      "Epoch: 43 Iter 39 Train_loss: 0.00019950639398302883\n",
      "Epoch: 43 Iter 59 Train_loss: 0.0002045412256848067\n",
      "Epoch: 43 Iter 79 Train_loss: 0.0002565638569649309\n",
      "Epoch: 43 Iter 99 Train_loss: 0.00020194391254335642\n",
      "Epoch: 43 Iter 119 Train_loss: 0.0002267868840135634\n",
      "Epoch: 43 Iter 139 Train_loss: 0.0002435908536426723\n",
      "Epoch: 43 Iter 159 Train_loss: 0.00021505447512026876\n",
      "Epoch: 43 Iter 179 Train_loss: 0.00021541077876463532\n",
      "Epoch: 43 Iter 199 Train_loss: 0.00018476173863746226\n",
      "Epoch: 43 Iter 219 Train_loss: 0.00020353055151645094\n",
      "Epoch: 43 Iter 239 Train_loss: 0.00026822712970897555\n",
      "Epoch: 43 Iter 259 Train_loss: 0.00020673788094427437\n",
      "Epoch: 43 Iter 279 Train_loss: 0.00021385951549746096\n",
      "Epoch: 43 Iter 299 Train_loss: 0.00021561856556218117\n",
      "Epoch: 43 Iter 319 Train_loss: 0.00027607858646661043\n",
      "Epoch: 43 Iter 339 Train_loss: 0.00020230055088177323\n",
      "Epoch: 43 Iter 359 Train_loss: 0.0002036446239799261\n",
      "Epoch: 43 Iter 379 Train_loss: 0.00019549441640265286\n",
      "Epoch: 43 Iter 399 Train_loss: 0.0002107448090100661\n",
      "Epoch: 43 Iter 419 Train_loss: 0.0002159437135560438\n",
      "Epoch: 43 Iter 439 Train_loss: 0.0002320829516975209\n",
      "Epoch: 43 Iter 459 Train_loss: 0.0002339150378247723\n",
      "Epoch: 43 Iter 479 Train_loss: 0.00017165068129543215\n",
      "Epoch: 43 Iter 499 Train_loss: 0.00021787478181067854\n",
      "Epoch: 43 Iter 519 Train_loss: 0.00020219056750647724\n",
      "Epoch: 43 Iter 539 Train_loss: 0.00022316700778901577\n",
      "Epoch: 43 Iter 559 Train_loss: 0.00022226104920264333\n",
      "Epoch: 43 Iter 579 Train_loss: 0.00023925016284920275\n",
      "Epoch: 43 Iter 599 Train_loss: 0.00021688567358069122\n",
      "Epoch: 43 Iter 619 Train_loss: 0.00021997054864186794\n",
      "Epoch: 43 Iter 639 Train_loss: 0.00020614791719708592\n",
      "Epoch: 43 Iter 659 Train_loss: 0.00019314195378683507\n",
      "Epoch: 43 Iter 679 Train_loss: 0.00018356155487708747\n",
      "Epoch: 43 Iter 699 Train_loss: 0.00022600553347729146\n",
      "Epoch: 43 Iter 719 Train_loss: 0.00021676975302398205\n",
      "Epoch: 43 Iter 739 Train_loss: 0.00020741195476148278\n",
      "Epoch: 43 Iter 759 Train_loss: 0.00020577882241923362\n",
      "Epoch: 43 Iter 779 Train_loss: 0.00020129918993916363\n",
      "Epoch: 43 Iter 799 Train_loss: 0.00022794546384830028\n",
      "Epoch: 43 Iter 819 Train_loss: 0.00019127590348944068\n",
      "Epoch: 43 Iter 839 Train_loss: 0.00021002981520723552\n",
      "Epoch: 43 Iter 859 Train_loss: 0.00019886696827597916\n",
      "Epoch: 43 Iter 879 Train_loss: 0.00022062472999095917\n",
      "Epoch: 43 Iter 899 Train_loss: 0.00026814150623977184\n",
      "Epoch: 43 Iter 919 Train_loss: 0.00023621899890713394\n",
      "Epoch: 43 Iter 939 Train_loss: 0.00019236374646425247\n",
      "Epoch: 43 Iter 959 Train_loss: 0.00021139437740202993\n",
      "Epoch: 43 Iter 979 Train_loss: 0.0002453966299071908\n",
      "Epoch: 43 Iter 999 Train_loss: 0.00027721759397536516\n",
      "Epoch: 43 Iter 1019 Train_loss: 0.00018276226182933897\n",
      "Epoch: 43 Iter 1039 Train_loss: 0.00020302033226471394\n",
      "Epoch: 43 Iter 1059 Train_loss: 0.00019878961029462516\n",
      "[ 43/100]train_loss:0.00021valid_loss:0.00027\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch: 44 Iter 19 Train_loss: 0.00019459970644675195\n",
      "Epoch: 44 Iter 39 Train_loss: 0.0002201165334554389\n",
      "Epoch: 44 Iter 59 Train_loss: 0.00021005255985073745\n",
      "Epoch: 44 Iter 79 Train_loss: 0.00018238197662867606\n",
      "Epoch: 44 Iter 99 Train_loss: 0.00022556947078555822\n",
      "Epoch: 44 Iter 119 Train_loss: 0.00022900568728800863\n",
      "Epoch: 44 Iter 139 Train_loss: 0.0001730236690491438\n",
      "Epoch: 44 Iter 159 Train_loss: 0.00018928332428913563\n",
      "Epoch: 44 Iter 179 Train_loss: 0.0001961758389370516\n",
      "Epoch: 44 Iter 199 Train_loss: 0.00021467229817062616\n",
      "Epoch: 44 Iter 219 Train_loss: 0.00023595403763465583\n",
      "Epoch: 44 Iter 239 Train_loss: 0.0002503368305042386\n",
      "Epoch: 44 Iter 259 Train_loss: 0.00020027738355565816\n",
      "Epoch: 44 Iter 279 Train_loss: 0.00020493168267421424\n",
      "Epoch: 44 Iter 299 Train_loss: 0.00021021856809966266\n",
      "Epoch: 44 Iter 319 Train_loss: 0.0002080517151625827\n",
      "Epoch: 44 Iter 339 Train_loss: 0.00020469898299779743\n",
      "Epoch: 44 Iter 359 Train_loss: 0.0002093458897434175\n",
      "Epoch: 44 Iter 379 Train_loss: 0.0001890619023470208\n",
      "Epoch: 44 Iter 399 Train_loss: 0.00017300363106187433\n",
      "Epoch: 44 Iter 419 Train_loss: 0.00020713784033432603\n",
      "Epoch: 44 Iter 439 Train_loss: 0.0001981903042178601\n",
      "Epoch: 44 Iter 459 Train_loss: 0.00024153552658390254\n",
      "Epoch: 44 Iter 479 Train_loss: 0.000197541419765912\n",
      "Epoch: 44 Iter 499 Train_loss: 0.00018655063468031585\n",
      "Epoch: 44 Iter 519 Train_loss: 0.00019325596804264933\n",
      "Epoch: 44 Iter 539 Train_loss: 0.00019802695896942168\n",
      "Epoch: 44 Iter 559 Train_loss: 0.00021777223446406424\n",
      "Epoch: 44 Iter 579 Train_loss: 0.00020333741849754006\n",
      "Epoch: 44 Iter 599 Train_loss: 0.00019865731883328408\n",
      "Epoch: 44 Iter 619 Train_loss: 0.00020706388750113547\n",
      "Epoch: 44 Iter 639 Train_loss: 0.00018821776029653847\n",
      "Epoch: 44 Iter 659 Train_loss: 0.0002057778328889981\n",
      "Epoch: 44 Iter 679 Train_loss: 0.00020999742264393717\n",
      "Epoch: 44 Iter 699 Train_loss: 0.00019698261166922748\n",
      "Epoch: 44 Iter 719 Train_loss: 0.00022908889513928443\n",
      "Epoch: 44 Iter 739 Train_loss: 0.0002570229407865554\n",
      "Epoch: 44 Iter 759 Train_loss: 0.00020776718156412244\n",
      "Epoch: 44 Iter 779 Train_loss: 0.0001875305752037093\n",
      "Epoch: 44 Iter 799 Train_loss: 0.00019247634918428957\n",
      "Epoch: 44 Iter 819 Train_loss: 0.0002459253591950983\n",
      "Epoch: 44 Iter 839 Train_loss: 0.00021364456915762275\n",
      "Epoch: 44 Iter 859 Train_loss: 0.00020481445244513452\n",
      "Epoch: 44 Iter 879 Train_loss: 0.00032039792858995497\n",
      "Epoch: 44 Iter 899 Train_loss: 0.00020487277652136981\n",
      "Epoch: 44 Iter 919 Train_loss: 0.00019809388322755694\n",
      "Epoch: 44 Iter 939 Train_loss: 0.00024558030418120325\n",
      "Epoch: 44 Iter 959 Train_loss: 0.00021478856797330081\n",
      "Epoch: 44 Iter 979 Train_loss: 0.00024371917243115604\n",
      "Epoch: 44 Iter 999 Train_loss: 0.00020057101210113615\n",
      "Epoch: 44 Iter 1019 Train_loss: 0.0002592506934888661\n",
      "Epoch: 44 Iter 1039 Train_loss: 0.000247646908974275\n",
      "Epoch: 44 Iter 1059 Train_loss: 0.000177991678356193\n",
      "[ 44/100]train_loss:0.00022valid_loss:0.00026\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch: 45 Iter 19 Train_loss: 0.0001809063833206892\n",
      "Epoch: 45 Iter 39 Train_loss: 0.0002068896865239367\n",
      "Epoch: 45 Iter 59 Train_loss: 0.0001904603559523821\n",
      "Epoch: 45 Iter 79 Train_loss: 0.0002196627319790423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 Iter 99 Train_loss: 0.0001933085877681151\n",
      "Epoch: 45 Iter 119 Train_loss: 0.00020072066399734467\n",
      "Epoch: 45 Iter 139 Train_loss: 0.00020690738165285438\n",
      "Epoch: 45 Iter 159 Train_loss: 0.00018212928262073547\n",
      "Epoch: 45 Iter 179 Train_loss: 0.0002355904143769294\n",
      "Epoch: 45 Iter 199 Train_loss: 0.0002014859055634588\n",
      "Epoch: 45 Iter 219 Train_loss: 0.0001841666962718591\n",
      "Epoch: 45 Iter 239 Train_loss: 0.000217903740121983\n",
      "Epoch: 45 Iter 259 Train_loss: 0.00023182693985290825\n",
      "Epoch: 45 Iter 279 Train_loss: 0.00023403592058457434\n",
      "Epoch: 45 Iter 299 Train_loss: 0.00020804363884963095\n",
      "Epoch: 45 Iter 319 Train_loss: 0.00017127017781604081\n",
      "Epoch: 45 Iter 339 Train_loss: 0.0001969789300346747\n",
      "Epoch: 45 Iter 359 Train_loss: 0.00023225067707244307\n",
      "Epoch: 45 Iter 379 Train_loss: 0.00019010910182259977\n",
      "Epoch: 45 Iter 399 Train_loss: 0.00020097427477594465\n",
      "Epoch: 45 Iter 419 Train_loss: 0.0002023398847086355\n",
      "Epoch: 45 Iter 439 Train_loss: 0.00020162021974101663\n",
      "Epoch: 45 Iter 459 Train_loss: 0.00019318786507938057\n",
      "Epoch: 45 Iter 479 Train_loss: 0.00019460813200566918\n",
      "Epoch: 45 Iter 499 Train_loss: 0.00025032926350831985\n",
      "Epoch: 45 Iter 519 Train_loss: 0.0002627238573040813\n",
      "Epoch: 45 Iter 539 Train_loss: 0.0001895284076454118\n",
      "Epoch: 45 Iter 559 Train_loss: 0.00022540471400134265\n",
      "Epoch: 45 Iter 579 Train_loss: 0.0002213044062955305\n",
      "Epoch: 45 Iter 599 Train_loss: 0.00018866192840505391\n",
      "Epoch: 45 Iter 619 Train_loss: 0.0002048853348242119\n",
      "Epoch: 45 Iter 639 Train_loss: 0.00022362112940754741\n",
      "Epoch: 45 Iter 659 Train_loss: 0.00020102773851249367\n",
      "Epoch: 45 Iter 679 Train_loss: 0.00020038537331856787\n",
      "Epoch: 45 Iter 699 Train_loss: 0.00024547846987843513\n",
      "Epoch: 45 Iter 719 Train_loss: 0.0001879054179880768\n",
      "Epoch: 45 Iter 739 Train_loss: 0.00023141193378251046\n",
      "Epoch: 45 Iter 759 Train_loss: 0.0002043959975708276\n",
      "Epoch: 45 Iter 779 Train_loss: 0.00022445227659773082\n",
      "Epoch: 45 Iter 799 Train_loss: 0.00022007551160641015\n",
      "Epoch: 45 Iter 819 Train_loss: 0.0002126050239894539\n",
      "Epoch: 45 Iter 839 Train_loss: 0.00022055736917536706\n",
      "Epoch: 45 Iter 859 Train_loss: 0.00022892432752996683\n",
      "Epoch: 45 Iter 879 Train_loss: 0.00021295931946951896\n",
      "Epoch: 45 Iter 899 Train_loss: 0.00024057379050645977\n",
      "Epoch: 45 Iter 919 Train_loss: 0.0002169938525184989\n",
      "Epoch: 45 Iter 939 Train_loss: 0.00020228943321853876\n",
      "Epoch: 45 Iter 959 Train_loss: 0.0002506389864720404\n",
      "Epoch: 45 Iter 979 Train_loss: 0.00022932460706215352\n",
      "Epoch: 45 Iter 999 Train_loss: 0.00019876380974892527\n",
      "Epoch: 45 Iter 1019 Train_loss: 0.00022652142797596753\n",
      "Epoch: 45 Iter 1039 Train_loss: 0.0001939896319527179\n",
      "Epoch: 45 Iter 1059 Train_loss: 0.00021593979909084737\n",
      "[ 45/100]train_loss:0.00021valid_loss:0.00026\n",
      "Validation loss decreased (0.000257 --> 0.000256).  Saving model ...\n",
      "Epoch: 46 Iter 19 Train_loss: 0.00022720923880115151\n",
      "Epoch: 46 Iter 39 Train_loss: 0.0002087780594592914\n",
      "Epoch: 46 Iter 59 Train_loss: 0.00021131327957846224\n",
      "Epoch: 46 Iter 79 Train_loss: 0.00019351678201928735\n",
      "Epoch: 46 Iter 99 Train_loss: 0.0002025291760219261\n",
      "Epoch: 46 Iter 119 Train_loss: 0.00024340262461919338\n",
      "Epoch: 46 Iter 139 Train_loss: 0.00021352287149056792\n",
      "Epoch: 46 Iter 159 Train_loss: 0.00019541550136636943\n",
      "Epoch: 46 Iter 179 Train_loss: 0.00020954638603143394\n",
      "Epoch: 46 Iter 199 Train_loss: 0.00023011461598798633\n",
      "Epoch: 46 Iter 219 Train_loss: 0.00020856970513705164\n",
      "Epoch: 46 Iter 239 Train_loss: 0.00020742863125633448\n",
      "Epoch: 46 Iter 259 Train_loss: 0.00020544113067444414\n",
      "Epoch: 46 Iter 279 Train_loss: 0.0001854689617175609\n",
      "Epoch: 46 Iter 299 Train_loss: 0.00020361397764645517\n",
      "Epoch: 46 Iter 319 Train_loss: 0.00020140879496466368\n",
      "Epoch: 46 Iter 339 Train_loss: 0.0002006244903896004\n",
      "Epoch: 46 Iter 359 Train_loss: 0.0002207717188866809\n",
      "Epoch: 46 Iter 379 Train_loss: 0.00025142455706372857\n",
      "Epoch: 46 Iter 399 Train_loss: 0.0002830924349837005\n",
      "Epoch: 46 Iter 419 Train_loss: 0.0001823355269152671\n",
      "Epoch: 46 Iter 439 Train_loss: 0.0002345390967093408\n",
      "Epoch: 46 Iter 459 Train_loss: 0.00020725584181491286\n",
      "Epoch: 46 Iter 479 Train_loss: 0.00018951624224428087\n",
      "Epoch: 46 Iter 499 Train_loss: 0.00021974170522298664\n",
      "Epoch: 46 Iter 519 Train_loss: 0.00022793174139223993\n",
      "Epoch: 46 Iter 539 Train_loss: 0.0002155621477868408\n",
      "Epoch: 46 Iter 559 Train_loss: 0.00028855339041911066\n",
      "Epoch: 46 Iter 579 Train_loss: 0.00022405580966733396\n",
      "Epoch: 46 Iter 599 Train_loss: 0.00025012277183122933\n",
      "Epoch: 46 Iter 619 Train_loss: 0.00019596148922573775\n",
      "Epoch: 46 Iter 639 Train_loss: 0.00021122767066117376\n",
      "Epoch: 46 Iter 659 Train_loss: 0.00021187493985053152\n",
      "Epoch: 46 Iter 679 Train_loss: 0.0001914509921334684\n",
      "Epoch: 46 Iter 699 Train_loss: 0.00025752256624400616\n",
      "Epoch: 46 Iter 719 Train_loss: 0.00020934033091180027\n",
      "Epoch: 46 Iter 739 Train_loss: 0.00020411743025761098\n",
      "Epoch: 46 Iter 759 Train_loss: 0.0002273019781569019\n",
      "Epoch: 46 Iter 779 Train_loss: 0.00021298721549101174\n",
      "Epoch: 46 Iter 799 Train_loss: 0.00019042498024646193\n",
      "Epoch: 46 Iter 819 Train_loss: 0.00022483784414362162\n",
      "Epoch: 46 Iter 839 Train_loss: 0.0002122898877132684\n",
      "Epoch: 46 Iter 859 Train_loss: 0.0002099583944072947\n",
      "Epoch: 46 Iter 879 Train_loss: 0.0002269782271469012\n",
      "Epoch: 46 Iter 899 Train_loss: 0.00020337286696303636\n",
      "Epoch: 46 Iter 919 Train_loss: 0.00020372655126266181\n",
      "Epoch: 46 Iter 939 Train_loss: 0.00021622460917569697\n",
      "Epoch: 46 Iter 959 Train_loss: 0.00020441458036657423\n",
      "Epoch: 46 Iter 979 Train_loss: 0.00021902610023971647\n",
      "Epoch: 46 Iter 999 Train_loss: 0.00023125740699470043\n",
      "Epoch: 46 Iter 1019 Train_loss: 0.00023013637110125273\n",
      "Epoch: 46 Iter 1039 Train_loss: 0.00023236649576574564\n",
      "Epoch: 46 Iter 1059 Train_loss: 0.0001984246919164434\n",
      "[ 46/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 47 Iter 19 Train_loss: 0.0001942836825037375\n",
      "Epoch: 47 Iter 39 Train_loss: 0.00022663701383862644\n",
      "Epoch: 47 Iter 59 Train_loss: 0.00021065353939775378\n",
      "Epoch: 47 Iter 79 Train_loss: 0.00019882059132214636\n",
      "Epoch: 47 Iter 99 Train_loss: 0.000204005409614183\n",
      "Epoch: 47 Iter 119 Train_loss: 0.00020712254627142102\n",
      "Epoch: 47 Iter 139 Train_loss: 0.00022748422634322196\n",
      "Epoch: 47 Iter 159 Train_loss: 0.0002140391879947856\n",
      "Epoch: 47 Iter 179 Train_loss: 0.00020165192836429924\n",
      "Epoch: 47 Iter 199 Train_loss: 0.000185214783414267\n",
      "Epoch: 47 Iter 219 Train_loss: 0.0002510871272534132\n",
      "Epoch: 47 Iter 239 Train_loss: 0.00021054262469988316\n",
      "Epoch: 47 Iter 259 Train_loss: 0.00020901154493913054\n",
      "Epoch: 47 Iter 279 Train_loss: 0.00019611790776252747\n",
      "Epoch: 47 Iter 299 Train_loss: 0.00021986932551953942\n",
      "Epoch: 47 Iter 319 Train_loss: 0.00024134093837346882\n",
      "Epoch: 47 Iter 339 Train_loss: 0.00018326273129787296\n",
      "Epoch: 47 Iter 359 Train_loss: 0.00018509732035454363\n",
      "Epoch: 47 Iter 379 Train_loss: 0.0002062107960227877\n",
      "Epoch: 47 Iter 399 Train_loss: 0.0002483816060703248\n",
      "Epoch: 47 Iter 419 Train_loss: 0.00019129429711028934\n",
      "Epoch: 47 Iter 439 Train_loss: 0.00019139450159855187\n",
      "Epoch: 47 Iter 459 Train_loss: 0.00018974492559209466\n",
      "Epoch: 47 Iter 479 Train_loss: 0.0001809323439374566\n",
      "Epoch: 47 Iter 499 Train_loss: 0.00020413233141880482\n",
      "Epoch: 47 Iter 519 Train_loss: 0.00024450503406114876\n",
      "Epoch: 47 Iter 539 Train_loss: 0.0002796106564346701\n",
      "Epoch: 47 Iter 559 Train_loss: 0.00019504020747262985\n",
      "Epoch: 47 Iter 579 Train_loss: 0.00018573271518107504\n",
      "Epoch: 47 Iter 599 Train_loss: 0.00021096413547638804\n",
      "Epoch: 47 Iter 619 Train_loss: 0.00021878306870348752\n",
      "Epoch: 47 Iter 639 Train_loss: 0.00022884040663484484\n",
      "Epoch: 47 Iter 659 Train_loss: 0.00020711463002953678\n",
      "Epoch: 47 Iter 679 Train_loss: 0.00023416012118104845\n",
      "Epoch: 47 Iter 699 Train_loss: 0.00019768389756791294\n",
      "Epoch: 47 Iter 719 Train_loss: 0.00021508841018658131\n",
      "Epoch: 47 Iter 739 Train_loss: 0.00022364525648299605\n",
      "Epoch: 47 Iter 759 Train_loss: 0.00022571621229872108\n",
      "Epoch: 47 Iter 779 Train_loss: 0.00019337267440278083\n",
      "Epoch: 47 Iter 799 Train_loss: 0.0002975536626763642\n",
      "Epoch: 47 Iter 819 Train_loss: 0.0001875063608167693\n",
      "Epoch: 47 Iter 839 Train_loss: 0.0001797830336727202\n",
      "Epoch: 47 Iter 859 Train_loss: 0.0001909063576022163\n",
      "Epoch: 47 Iter 879 Train_loss: 0.00021357212972361594\n",
      "Epoch: 47 Iter 899 Train_loss: 0.00019628123845905066\n",
      "Epoch: 47 Iter 919 Train_loss: 0.0002122320292983204\n",
      "Epoch: 47 Iter 939 Train_loss: 0.00022014332353137434\n",
      "Epoch: 47 Iter 959 Train_loss: 0.00021087245841044933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 Iter 979 Train_loss: 0.00023381758364848793\n",
      "Epoch: 47 Iter 999 Train_loss: 0.00023094927018973976\n",
      "Epoch: 47 Iter 1019 Train_loss: 0.00023112387862056494\n",
      "Epoch: 47 Iter 1039 Train_loss: 0.00019821495516225696\n",
      "Epoch: 47 Iter 1059 Train_loss: 0.0002088230539811775\n",
      "[ 47/100]train_loss:0.00021valid_loss:0.00027\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 48 Iter 19 Train_loss: 0.00024275502073578537\n",
      "Epoch: 48 Iter 39 Train_loss: 0.0002046144218184054\n",
      "Epoch: 48 Iter 59 Train_loss: 0.0002144377212971449\n",
      "Epoch: 48 Iter 79 Train_loss: 0.00025440313038416207\n",
      "Epoch: 48 Iter 99 Train_loss: 0.00024349337036255747\n",
      "Epoch: 48 Iter 119 Train_loss: 0.00023821412469260395\n",
      "Epoch: 48 Iter 139 Train_loss: 0.00022278916731011122\n",
      "Epoch: 48 Iter 159 Train_loss: 0.00022306233586277813\n",
      "Epoch: 48 Iter 179 Train_loss: 0.00019784258620347828\n",
      "Epoch: 48 Iter 199 Train_loss: 0.00019233586499467492\n",
      "Epoch: 48 Iter 219 Train_loss: 0.0002114021044690162\n",
      "Epoch: 48 Iter 239 Train_loss: 0.00018052005907520652\n",
      "Epoch: 48 Iter 259 Train_loss: 0.00021394061332102865\n",
      "Epoch: 48 Iter 279 Train_loss: 0.0002207565848948434\n",
      "Epoch: 48 Iter 299 Train_loss: 0.0002173516113543883\n",
      "Epoch: 48 Iter 319 Train_loss: 0.00019646892906166613\n",
      "Epoch: 48 Iter 339 Train_loss: 0.00021889939671382308\n",
      "Epoch: 48 Iter 359 Train_loss: 0.00019093268201686442\n",
      "Epoch: 48 Iter 379 Train_loss: 0.00020783192303497344\n",
      "Epoch: 48 Iter 399 Train_loss: 0.0001975328486878425\n",
      "Epoch: 48 Iter 419 Train_loss: 0.0002129022468579933\n",
      "Epoch: 48 Iter 439 Train_loss: 0.00018818618264049292\n",
      "Epoch: 48 Iter 459 Train_loss: 0.00019692610658239573\n",
      "Epoch: 48 Iter 479 Train_loss: 0.0002417764044366777\n",
      "Epoch: 48 Iter 499 Train_loss: 0.00021092381211929023\n",
      "Epoch: 48 Iter 519 Train_loss: 0.0001847628882387653\n",
      "Epoch: 48 Iter 539 Train_loss: 0.00021862830908503383\n",
      "Epoch: 48 Iter 559 Train_loss: 0.00027652940480038524\n",
      "Epoch: 48 Iter 579 Train_loss: 0.00018887288752011955\n",
      "Epoch: 48 Iter 599 Train_loss: 0.00020762199710588902\n",
      "Epoch: 48 Iter 619 Train_loss: 0.00025026427465490997\n",
      "Epoch: 48 Iter 639 Train_loss: 0.00020485695858951658\n",
      "Epoch: 48 Iter 659 Train_loss: 0.00020933005725964904\n",
      "Epoch: 48 Iter 679 Train_loss: 0.00021109131921548396\n",
      "Epoch: 48 Iter 699 Train_loss: 0.00017733465938363224\n",
      "Epoch: 48 Iter 719 Train_loss: 0.00019390943634789437\n",
      "Epoch: 48 Iter 739 Train_loss: 0.00020672110258601606\n",
      "Epoch: 48 Iter 759 Train_loss: 0.00018680139328353107\n",
      "Epoch: 48 Iter 779 Train_loss: 0.00023789530678186566\n",
      "Epoch: 48 Iter 799 Train_loss: 0.00025610835291445255\n",
      "Epoch: 48 Iter 819 Train_loss: 0.0001964723487617448\n",
      "Epoch: 48 Iter 839 Train_loss: 0.00018836323579307646\n",
      "Epoch: 48 Iter 859 Train_loss: 0.00021701080549973994\n",
      "Epoch: 48 Iter 879 Train_loss: 0.00018047753837890923\n",
      "Epoch: 48 Iter 899 Train_loss: 0.00019252703350502998\n",
      "Epoch: 48 Iter 919 Train_loss: 0.0002196039422415197\n",
      "Epoch: 48 Iter 939 Train_loss: 0.00020109143224544823\n",
      "Epoch: 48 Iter 959 Train_loss: 0.00020000750373583287\n",
      "Epoch: 48 Iter 979 Train_loss: 0.00019806956697721034\n",
      "Epoch: 48 Iter 999 Train_loss: 0.00019191141473129392\n",
      "Epoch: 48 Iter 1019 Train_loss: 0.00022316073591355234\n",
      "Epoch: 48 Iter 1039 Train_loss: 0.00021806532458867878\n",
      "Epoch: 48 Iter 1059 Train_loss: 0.0002394293696852401\n",
      "[ 48/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 49 Iter 19 Train_loss: 0.00022002971672918648\n",
      "Epoch: 49 Iter 39 Train_loss: 0.00023228581994771957\n",
      "Epoch: 49 Iter 59 Train_loss: 0.00020508111629169434\n",
      "Epoch: 49 Iter 79 Train_loss: 0.00019462780619505793\n",
      "Epoch: 49 Iter 99 Train_loss: 0.00022606791753787547\n",
      "Epoch: 49 Iter 119 Train_loss: 0.00020092917839065194\n",
      "Epoch: 49 Iter 139 Train_loss: 0.00024980309535749257\n",
      "Epoch: 49 Iter 159 Train_loss: 0.00017621490405872464\n",
      "Epoch: 49 Iter 179 Train_loss: 0.00020699910237453878\n",
      "Epoch: 49 Iter 199 Train_loss: 0.00020028254948556423\n",
      "Epoch: 49 Iter 219 Train_loss: 0.00017056340584531426\n",
      "Epoch: 49 Iter 239 Train_loss: 0.00019504364172462374\n",
      "Epoch: 49 Iter 259 Train_loss: 0.00019041626364924014\n",
      "Epoch: 49 Iter 279 Train_loss: 0.00021089898655191064\n",
      "Epoch: 49 Iter 299 Train_loss: 0.0001996047212742269\n",
      "Epoch: 49 Iter 319 Train_loss: 0.00021716019546147436\n",
      "Epoch: 49 Iter 339 Train_loss: 0.00022857410658616573\n",
      "Epoch: 49 Iter 359 Train_loss: 0.00023188329942058772\n",
      "Epoch: 49 Iter 379 Train_loss: 0.0001887315884232521\n",
      "Epoch: 49 Iter 399 Train_loss: 0.00020900857634842396\n",
      "Epoch: 49 Iter 419 Train_loss: 0.00022878710296936333\n",
      "Epoch: 49 Iter 439 Train_loss: 0.00020354936714284122\n",
      "Epoch: 49 Iter 459 Train_loss: 0.0001950410078279674\n",
      "Epoch: 49 Iter 479 Train_loss: 0.00019110557332169265\n",
      "Epoch: 49 Iter 499 Train_loss: 0.00021370648755691946\n",
      "Epoch: 49 Iter 519 Train_loss: 0.0002000195236178115\n",
      "Epoch: 49 Iter 539 Train_loss: 0.00020705183851532638\n",
      "Epoch: 49 Iter 559 Train_loss: 0.00018322706455364823\n",
      "Epoch: 49 Iter 579 Train_loss: 0.00023453481844626367\n",
      "Epoch: 49 Iter 599 Train_loss: 0.00018372159684076905\n",
      "Epoch: 49 Iter 619 Train_loss: 0.0001673074730206281\n",
      "Epoch: 49 Iter 639 Train_loss: 0.00022380442533176392\n",
      "Epoch: 49 Iter 659 Train_loss: 0.00019128384883515537\n",
      "Epoch: 49 Iter 679 Train_loss: 0.00020105269504711032\n",
      "Epoch: 49 Iter 699 Train_loss: 0.00022026282385922968\n",
      "Epoch: 49 Iter 719 Train_loss: 0.000207272736588493\n",
      "Epoch: 49 Iter 739 Train_loss: 0.0001915294269565493\n",
      "Epoch: 49 Iter 759 Train_loss: 0.0001992875331779942\n",
      "Epoch: 49 Iter 779 Train_loss: 0.00019723494187928736\n",
      "Epoch: 49 Iter 799 Train_loss: 0.0002136904076905921\n",
      "Epoch: 49 Iter 819 Train_loss: 0.00021065736655145884\n",
      "Epoch: 49 Iter 839 Train_loss: 0.00020695512648671865\n",
      "Epoch: 49 Iter 859 Train_loss: 0.00021032510267104954\n",
      "Epoch: 49 Iter 879 Train_loss: 0.0002102887083310634\n",
      "Epoch: 49 Iter 899 Train_loss: 0.00021695448958780617\n",
      "Epoch: 49 Iter 919 Train_loss: 0.0002314241573913023\n",
      "Epoch: 49 Iter 939 Train_loss: 0.00021536462008953094\n",
      "Epoch: 49 Iter 959 Train_loss: 0.00019529643759597093\n",
      "Epoch: 49 Iter 979 Train_loss: 0.000254782207775861\n",
      "Epoch: 49 Iter 999 Train_loss: 0.0002126736508216709\n",
      "Epoch: 49 Iter 1019 Train_loss: 0.00019762723241001368\n",
      "Epoch: 49 Iter 1039 Train_loss: 0.0002402511890977621\n",
      "Epoch: 49 Iter 1059 Train_loss: 0.0002096455282298848\n",
      "[ 49/100]train_loss:0.00021valid_loss:0.00025\n",
      "Validation loss decreased (0.000256 --> 0.000253).  Saving model ...\n",
      "Epoch: 50 Iter 19 Train_loss: 0.0002066555607598275\n",
      "Epoch: 50 Iter 39 Train_loss: 0.00018449347408022732\n",
      "Epoch: 50 Iter 59 Train_loss: 0.0001865874946815893\n",
      "Epoch: 50 Iter 79 Train_loss: 0.00019170073210261762\n",
      "Epoch: 50 Iter 99 Train_loss: 0.00020591422799043357\n",
      "Epoch: 50 Iter 119 Train_loss: 0.00028570048743858933\n",
      "Epoch: 50 Iter 139 Train_loss: 0.00024144905910361558\n",
      "Epoch: 50 Iter 159 Train_loss: 0.0002558151609264314\n",
      "Epoch: 50 Iter 179 Train_loss: 0.0002062935527646914\n",
      "Epoch: 50 Iter 199 Train_loss: 0.00024470232892781496\n",
      "Epoch: 50 Iter 219 Train_loss: 0.0002790310245472938\n",
      "Epoch: 50 Iter 239 Train_loss: 0.0002079007390420884\n",
      "Epoch: 50 Iter 259 Train_loss: 0.00021327899594325572\n",
      "Epoch: 50 Iter 279 Train_loss: 0.00020068777666892856\n",
      "Epoch: 50 Iter 299 Train_loss: 0.00020327761012595147\n",
      "Epoch: 50 Iter 319 Train_loss: 0.0002106554456986487\n",
      "Epoch: 50 Iter 339 Train_loss: 0.00025310119963251054\n",
      "Epoch: 50 Iter 359 Train_loss: 0.0002239846799056977\n",
      "Epoch: 50 Iter 379 Train_loss: 0.00020699985907413065\n",
      "Epoch: 50 Iter 399 Train_loss: 0.00020041600510012358\n",
      "Epoch: 50 Iter 419 Train_loss: 0.00020479373051784933\n",
      "Epoch: 50 Iter 439 Train_loss: 0.0001810029789339751\n",
      "Epoch: 50 Iter 459 Train_loss: 0.00020817594486288726\n",
      "Epoch: 50 Iter 479 Train_loss: 0.00020315719302743673\n",
      "Epoch: 50 Iter 499 Train_loss: 0.00020231933740433306\n",
      "Epoch: 50 Iter 519 Train_loss: 0.00021802903211209923\n",
      "Epoch: 50 Iter 539 Train_loss: 0.00022132389131002128\n",
      "Epoch: 50 Iter 559 Train_loss: 0.00024169882817659527\n",
      "Epoch: 50 Iter 579 Train_loss: 0.0001992133620660752\n",
      "Epoch: 50 Iter 599 Train_loss: 0.00019369361689314246\n",
      "Epoch: 50 Iter 619 Train_loss: 0.0002269423275720328\n",
      "Epoch: 50 Iter 639 Train_loss: 0.00020823015074711293\n",
      "Epoch: 50 Iter 659 Train_loss: 0.0002041631960310042\n",
      "Epoch: 50 Iter 679 Train_loss: 0.00018427951727062464\n",
      "Epoch: 50 Iter 699 Train_loss: 0.00022113470186013728\n",
      "Epoch: 50 Iter 719 Train_loss: 0.00023942074039950967\n",
      "Epoch: 50 Iter 739 Train_loss: 0.0001889564300654456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Iter 759 Train_loss: 0.00023517492809332907\n",
      "Epoch: 50 Iter 779 Train_loss: 0.00022385604097507894\n",
      "Epoch: 50 Iter 799 Train_loss: 0.00024590775137767196\n",
      "Epoch: 50 Iter 819 Train_loss: 0.00023984727158676833\n",
      "Epoch: 50 Iter 839 Train_loss: 0.00022914286819286644\n",
      "Epoch: 50 Iter 859 Train_loss: 0.00019758837879635394\n",
      "Epoch: 50 Iter 879 Train_loss: 0.0002168109203921631\n",
      "Epoch: 50 Iter 899 Train_loss: 0.0002565380127634853\n",
      "Epoch: 50 Iter 919 Train_loss: 0.0001809855893952772\n",
      "Epoch: 50 Iter 939 Train_loss: 0.00018898236157838255\n",
      "Epoch: 50 Iter 959 Train_loss: 0.00022598389477934688\n",
      "Epoch: 50 Iter 979 Train_loss: 0.00022110537975095212\n",
      "Epoch: 50 Iter 999 Train_loss: 0.00024084099277388304\n",
      "Epoch: 50 Iter 1019 Train_loss: 0.00025709473993629217\n",
      "Epoch: 50 Iter 1039 Train_loss: 0.0002439961099298671\n",
      "Epoch: 50 Iter 1059 Train_loss: 0.00020492463954724371\n",
      "[ 50/100]train_loss:0.00021valid_loss:0.00027\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 51 Iter 19 Train_loss: 0.0002574615937191993\n",
      "Epoch: 51 Iter 39 Train_loss: 0.00018640609050635248\n",
      "Epoch: 51 Iter 59 Train_loss: 0.00021677518088836223\n",
      "Epoch: 51 Iter 79 Train_loss: 0.00023451932065654546\n",
      "Epoch: 51 Iter 99 Train_loss: 0.0002010607422562316\n",
      "Epoch: 51 Iter 119 Train_loss: 0.00019046930538024753\n",
      "Epoch: 51 Iter 139 Train_loss: 0.00019203861302230507\n",
      "Epoch: 51 Iter 159 Train_loss: 0.00019552103185560554\n",
      "Epoch: 51 Iter 179 Train_loss: 0.00021858887339476496\n",
      "Epoch: 51 Iter 199 Train_loss: 0.00021900820138398558\n",
      "Epoch: 51 Iter 219 Train_loss: 0.0001992114557651803\n",
      "Epoch: 51 Iter 239 Train_loss: 0.00018593360437080264\n",
      "Epoch: 51 Iter 259 Train_loss: 0.00021890344214625657\n",
      "Epoch: 51 Iter 279 Train_loss: 0.00020095410582143813\n",
      "Epoch: 51 Iter 299 Train_loss: 0.00023656118719372898\n",
      "Epoch: 51 Iter 319 Train_loss: 0.00021895203099120408\n",
      "Epoch: 51 Iter 339 Train_loss: 0.00020488107111304998\n",
      "Epoch: 51 Iter 359 Train_loss: 0.00021674529125448316\n",
      "Epoch: 51 Iter 379 Train_loss: 0.00018324106349609792\n",
      "Epoch: 51 Iter 399 Train_loss: 0.00024036195827648044\n",
      "Epoch: 51 Iter 419 Train_loss: 0.00022076877939980477\n",
      "Epoch: 51 Iter 439 Train_loss: 0.00024344920529983938\n",
      "Epoch: 51 Iter 459 Train_loss: 0.0001983543625101447\n",
      "Epoch: 51 Iter 479 Train_loss: 0.00018525440827943385\n",
      "Epoch: 51 Iter 499 Train_loss: 0.00021090725203976035\n",
      "Epoch: 51 Iter 519 Train_loss: 0.00023094935750123113\n",
      "Epoch: 51 Iter 539 Train_loss: 0.00020718247105833143\n",
      "Epoch: 51 Iter 559 Train_loss: 0.00019662377599161118\n",
      "Epoch: 51 Iter 579 Train_loss: 0.00022846089268568903\n",
      "Epoch: 51 Iter 599 Train_loss: 0.00018765839922707528\n",
      "Epoch: 51 Iter 619 Train_loss: 0.00023593984951730818\n",
      "Epoch: 51 Iter 639 Train_loss: 0.00022740839631296694\n",
      "Epoch: 51 Iter 659 Train_loss: 0.00019867453374899924\n",
      "Epoch: 51 Iter 679 Train_loss: 0.000274381076451391\n",
      "Epoch: 51 Iter 699 Train_loss: 0.00023256863642018288\n",
      "Epoch: 51 Iter 719 Train_loss: 0.0001840985205490142\n",
      "Epoch: 51 Iter 739 Train_loss: 0.00018901489966083318\n",
      "Epoch: 51 Iter 759 Train_loss: 0.00021910261420998722\n",
      "Epoch: 51 Iter 779 Train_loss: 0.0002376184129389003\n",
      "Epoch: 51 Iter 799 Train_loss: 0.00021370186004787683\n",
      "Epoch: 51 Iter 819 Train_loss: 0.00021496399131137878\n",
      "Epoch: 51 Iter 839 Train_loss: 0.0001956939959200099\n",
      "Epoch: 51 Iter 859 Train_loss: 0.0002169779036194086\n",
      "Epoch: 51 Iter 879 Train_loss: 0.0002385407278779894\n",
      "Epoch: 51 Iter 899 Train_loss: 0.000217985303606838\n",
      "Epoch: 51 Iter 919 Train_loss: 0.00025363927124999464\n",
      "Epoch: 51 Iter 939 Train_loss: 0.0002195194101659581\n",
      "Epoch: 51 Iter 959 Train_loss: 0.00021235663734842092\n",
      "Epoch: 51 Iter 979 Train_loss: 0.00029295714921317995\n",
      "Epoch: 51 Iter 999 Train_loss: 0.00022303052537608892\n",
      "Epoch: 51 Iter 1019 Train_loss: 0.00025775920948944986\n",
      "Epoch: 51 Iter 1039 Train_loss: 0.00020797165052499622\n",
      "Epoch: 51 Iter 1059 Train_loss: 0.00026441807858645916\n",
      "[ 51/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 52 Iter 19 Train_loss: 0.00020216933626215905\n",
      "Epoch: 52 Iter 39 Train_loss: 0.00017875287448987365\n",
      "Epoch: 52 Iter 59 Train_loss: 0.00019648633315227926\n",
      "Epoch: 52 Iter 79 Train_loss: 0.00018756325880531222\n",
      "Epoch: 52 Iter 99 Train_loss: 0.00031263750861398876\n",
      "Epoch: 52 Iter 119 Train_loss: 0.00023955077631399035\n",
      "Epoch: 52 Iter 139 Train_loss: 0.00018967874348163605\n",
      "Epoch: 52 Iter 159 Train_loss: 0.00021258443302940577\n",
      "Epoch: 52 Iter 179 Train_loss: 0.00019626021094154567\n",
      "Epoch: 52 Iter 199 Train_loss: 0.000209435194847174\n",
      "Epoch: 52 Iter 219 Train_loss: 0.00019261433044448495\n",
      "Epoch: 52 Iter 239 Train_loss: 0.0002279054169775918\n",
      "Epoch: 52 Iter 259 Train_loss: 0.0002155932888854295\n",
      "Epoch: 52 Iter 279 Train_loss: 0.00023738766321912408\n",
      "Epoch: 52 Iter 299 Train_loss: 0.00020394906459841877\n",
      "Epoch: 52 Iter 319 Train_loss: 0.00022769336646888405\n",
      "Epoch: 52 Iter 339 Train_loss: 0.00018369313329458237\n",
      "Epoch: 52 Iter 359 Train_loss: 0.00023798497568350285\n",
      "Epoch: 52 Iter 379 Train_loss: 0.0001908730046125129\n",
      "Epoch: 52 Iter 399 Train_loss: 0.0002424339618301019\n",
      "Epoch: 52 Iter 419 Train_loss: 0.00021372690389398485\n",
      "Epoch: 52 Iter 439 Train_loss: 0.00027453008806332946\n",
      "Epoch: 52 Iter 459 Train_loss: 0.00020383033552207053\n",
      "Epoch: 52 Iter 479 Train_loss: 0.0002004597772611305\n",
      "Epoch: 52 Iter 499 Train_loss: 0.00021258550987113267\n",
      "Epoch: 52 Iter 519 Train_loss: 0.00020153692457824945\n",
      "Epoch: 52 Iter 539 Train_loss: 0.0002662315673660487\n",
      "Epoch: 52 Iter 559 Train_loss: 0.00018931656086351722\n",
      "Epoch: 52 Iter 579 Train_loss: 0.00021625995577778667\n",
      "Epoch: 52 Iter 599 Train_loss: 0.00021200453920755535\n",
      "Epoch: 52 Iter 619 Train_loss: 0.0002233537525171414\n",
      "Epoch: 52 Iter 639 Train_loss: 0.00017829191347118467\n",
      "Epoch: 52 Iter 659 Train_loss: 0.0002079858968500048\n",
      "Epoch: 52 Iter 679 Train_loss: 0.00019404271733947098\n",
      "Epoch: 52 Iter 699 Train_loss: 0.00018057654961012304\n",
      "Epoch: 52 Iter 719 Train_loss: 0.00019882664491888136\n",
      "Epoch: 52 Iter 739 Train_loss: 0.00023326929658651352\n",
      "Epoch: 52 Iter 759 Train_loss: 0.00020025440608151257\n",
      "Epoch: 52 Iter 779 Train_loss: 0.0002112525253323838\n",
      "Epoch: 52 Iter 799 Train_loss: 0.0001804686471587047\n",
      "Epoch: 52 Iter 819 Train_loss: 0.00022499519400298595\n",
      "Epoch: 52 Iter 839 Train_loss: 0.00021832628408446908\n",
      "Epoch: 52 Iter 859 Train_loss: 0.0002055747900158167\n",
      "Epoch: 52 Iter 879 Train_loss: 0.0001897331967484206\n",
      "Epoch: 52 Iter 899 Train_loss: 0.00023364860680885613\n",
      "Epoch: 52 Iter 919 Train_loss: 0.0001856308663263917\n",
      "Epoch: 52 Iter 939 Train_loss: 0.00021989349625073373\n",
      "Epoch: 52 Iter 959 Train_loss: 0.00021366923465393484\n",
      "Epoch: 52 Iter 979 Train_loss: 0.00021209307305980474\n",
      "Epoch: 52 Iter 999 Train_loss: 0.00019974981842096895\n",
      "Epoch: 52 Iter 1019 Train_loss: 0.00027614255668595433\n",
      "Epoch: 52 Iter 1039 Train_loss: 0.00021465391910169274\n",
      "Epoch: 52 Iter 1059 Train_loss: 0.00021331400785129517\n",
      "[ 52/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 53 Iter 19 Train_loss: 0.0001963799149962142\n",
      "Epoch: 53 Iter 39 Train_loss: 0.0002054473734460771\n",
      "Epoch: 53 Iter 59 Train_loss: 0.00023871097073424608\n",
      "Epoch: 53 Iter 79 Train_loss: 0.00019903828797396272\n",
      "Epoch: 53 Iter 99 Train_loss: 0.00019511340360622853\n",
      "Epoch: 53 Iter 119 Train_loss: 0.00019661734404508024\n",
      "Epoch: 53 Iter 139 Train_loss: 0.00019372969109099358\n",
      "Epoch: 53 Iter 159 Train_loss: 0.0002621379098854959\n",
      "Epoch: 53 Iter 179 Train_loss: 0.00018371990881860256\n",
      "Epoch: 53 Iter 199 Train_loss: 0.00018916284898295999\n",
      "Epoch: 53 Iter 219 Train_loss: 0.00020995487284380943\n",
      "Epoch: 53 Iter 239 Train_loss: 0.00019226560834795237\n",
      "Epoch: 53 Iter 259 Train_loss: 0.00018929144425783306\n",
      "Epoch: 53 Iter 279 Train_loss: 0.00019933268777094781\n",
      "Epoch: 53 Iter 299 Train_loss: 0.00018095664563588798\n",
      "Epoch: 53 Iter 319 Train_loss: 0.0001817667653085664\n",
      "Epoch: 53 Iter 339 Train_loss: 0.00022218342928681523\n",
      "Epoch: 53 Iter 359 Train_loss: 0.00021449818450491875\n",
      "Epoch: 53 Iter 379 Train_loss: 0.00020631136430893093\n",
      "Epoch: 53 Iter 399 Train_loss: 0.0002544283343013376\n",
      "Epoch: 53 Iter 419 Train_loss: 0.00019951772992499173\n",
      "Epoch: 53 Iter 439 Train_loss: 0.00021186545200180262\n",
      "Epoch: 53 Iter 459 Train_loss: 0.00020343292271718383\n",
      "Epoch: 53 Iter 479 Train_loss: 0.00020913711341563612\n",
      "Epoch: 53 Iter 499 Train_loss: 0.00019301111751701683\n",
      "Epoch: 53 Iter 519 Train_loss: 0.00026281713508069515\n",
      "Epoch: 53 Iter 539 Train_loss: 0.00024004421720746905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 Iter 559 Train_loss: 0.00022729324700776488\n",
      "Epoch: 53 Iter 579 Train_loss: 0.00019569596042856574\n",
      "Epoch: 53 Iter 599 Train_loss: 0.0001850477565312758\n",
      "Epoch: 53 Iter 619 Train_loss: 0.00030392795451916754\n",
      "Epoch: 53 Iter 639 Train_loss: 0.00021584430942311883\n",
      "Epoch: 53 Iter 659 Train_loss: 0.0001973901380551979\n",
      "Epoch: 53 Iter 679 Train_loss: 0.00020702779875136912\n",
      "Epoch: 53 Iter 699 Train_loss: 0.00018743694818113\n",
      "Epoch: 53 Iter 719 Train_loss: 0.00016709604824427515\n",
      "Epoch: 53 Iter 739 Train_loss: 0.00020099099492654204\n",
      "Epoch: 53 Iter 759 Train_loss: 0.00019291641365271062\n",
      "Epoch: 53 Iter 779 Train_loss: 0.00020062638213858008\n",
      "Epoch: 53 Iter 799 Train_loss: 0.0002146325568901375\n",
      "Epoch: 53 Iter 819 Train_loss: 0.00022669137979391962\n",
      "Epoch: 53 Iter 839 Train_loss: 0.00022315415844786912\n",
      "Epoch: 53 Iter 859 Train_loss: 0.00019549955322872847\n",
      "Epoch: 53 Iter 879 Train_loss: 0.00020446637063287199\n",
      "Epoch: 53 Iter 899 Train_loss: 0.00018692424055188894\n",
      "Epoch: 53 Iter 919 Train_loss: 0.00022710507619194686\n",
      "Epoch: 53 Iter 939 Train_loss: 0.00020815181778743863\n",
      "Epoch: 53 Iter 959 Train_loss: 0.0002109224151354283\n",
      "Epoch: 53 Iter 979 Train_loss: 0.00019049408729188144\n",
      "Epoch: 53 Iter 999 Train_loss: 0.0002421385288471356\n",
      "Epoch: 53 Iter 1019 Train_loss: 0.0001835302828112617\n",
      "Epoch: 53 Iter 1039 Train_loss: 0.0002033279015449807\n",
      "Epoch: 53 Iter 1059 Train_loss: 0.0001889043633127585\n",
      "[ 53/100]train_loss:0.00021valid_loss:0.00025\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch: 54 Iter 19 Train_loss: 0.0002068893372779712\n",
      "Epoch: 54 Iter 39 Train_loss: 0.00021439403644762933\n",
      "Epoch: 54 Iter 59 Train_loss: 0.00019509934645611793\n",
      "Epoch: 54 Iter 79 Train_loss: 0.00018849869957193732\n",
      "Epoch: 54 Iter 99 Train_loss: 0.00019012716074939817\n",
      "Epoch: 54 Iter 119 Train_loss: 0.00021340898820199072\n",
      "Epoch: 54 Iter 139 Train_loss: 0.00023392241564579308\n",
      "Epoch: 54 Iter 159 Train_loss: 0.0002437866642139852\n",
      "Epoch: 54 Iter 179 Train_loss: 0.0002090118796331808\n",
      "Epoch: 54 Iter 199 Train_loss: 0.00018896916299127042\n",
      "Epoch: 54 Iter 219 Train_loss: 0.00018299365183338523\n",
      "Epoch: 54 Iter 239 Train_loss: 0.00024287021369673312\n",
      "Epoch: 54 Iter 259 Train_loss: 0.0001950928708538413\n",
      "Epoch: 54 Iter 279 Train_loss: 0.00020362519717309624\n",
      "Epoch: 54 Iter 299 Train_loss: 0.00020879168005194515\n",
      "Epoch: 54 Iter 319 Train_loss: 0.00020542502170428634\n",
      "Epoch: 54 Iter 339 Train_loss: 0.0002098085096804425\n",
      "Epoch: 54 Iter 359 Train_loss: 0.00020375098392833024\n",
      "Epoch: 54 Iter 379 Train_loss: 0.00020061424584127963\n",
      "Epoch: 54 Iter 399 Train_loss: 0.00020052111358381808\n",
      "Epoch: 54 Iter 419 Train_loss: 0.00018355391512159258\n",
      "Epoch: 54 Iter 439 Train_loss: 0.00018841674318537116\n",
      "Epoch: 54 Iter 459 Train_loss: 0.00021849005133844912\n",
      "Epoch: 54 Iter 479 Train_loss: 0.0001926214899867773\n",
      "Epoch: 54 Iter 499 Train_loss: 0.00020207965280860662\n",
      "Epoch: 54 Iter 519 Train_loss: 0.00020962035341653973\n",
      "Epoch: 54 Iter 539 Train_loss: 0.00018506745982449502\n",
      "Epoch: 54 Iter 559 Train_loss: 0.00020339632465038449\n",
      "Epoch: 54 Iter 579 Train_loss: 0.00020976943778805435\n",
      "Epoch: 54 Iter 599 Train_loss: 0.00020228135690558702\n",
      "Epoch: 54 Iter 619 Train_loss: 0.00018490619549993426\n",
      "Epoch: 54 Iter 639 Train_loss: 0.00020503310952335596\n",
      "Epoch: 54 Iter 659 Train_loss: 0.0002096879470627755\n",
      "Epoch: 54 Iter 679 Train_loss: 0.00018749164883047342\n",
      "Epoch: 54 Iter 699 Train_loss: 0.00018961502064485103\n",
      "Epoch: 54 Iter 719 Train_loss: 0.00018581404583528638\n",
      "Epoch: 54 Iter 739 Train_loss: 0.00020948602468706667\n",
      "Epoch: 54 Iter 759 Train_loss: 0.00016579720249865204\n",
      "Epoch: 54 Iter 779 Train_loss: 0.00023988462635315955\n",
      "Epoch: 54 Iter 799 Train_loss: 0.00021794653730466962\n",
      "Epoch: 54 Iter 819 Train_loss: 0.0002002594992518425\n",
      "Epoch: 54 Iter 839 Train_loss: 0.00022512811119668186\n",
      "Epoch: 54 Iter 859 Train_loss: 0.00022769582574255764\n",
      "Epoch: 54 Iter 879 Train_loss: 0.00018977104627992958\n",
      "Epoch: 54 Iter 899 Train_loss: 0.00022794518736191094\n",
      "Epoch: 54 Iter 919 Train_loss: 0.0002215215063188225\n",
      "Epoch: 54 Iter 939 Train_loss: 0.00020663008035626262\n",
      "Epoch: 54 Iter 959 Train_loss: 0.00021560030290856957\n",
      "Epoch: 54 Iter 979 Train_loss: 0.00022464593348558992\n",
      "Epoch: 54 Iter 999 Train_loss: 0.00025966763496398926\n",
      "Epoch: 54 Iter 1019 Train_loss: 0.0002306546230101958\n",
      "Epoch: 54 Iter 1039 Train_loss: 0.00021013779041823\n",
      "Epoch: 54 Iter 1059 Train_loss: 0.0001914310414576903\n",
      "[ 54/100]train_loss:0.00021valid_loss:0.00025\n",
      "Validation loss decreased (0.000253 --> 0.000249).  Saving model ...\n",
      "Epoch: 55 Iter 19 Train_loss: 0.00018322697724215686\n",
      "Epoch: 55 Iter 39 Train_loss: 0.00020261324243620038\n",
      "Epoch: 55 Iter 59 Train_loss: 0.0002139434654964134\n",
      "Epoch: 55 Iter 79 Train_loss: 0.00020090573525521904\n",
      "Epoch: 55 Iter 99 Train_loss: 0.00018450563948135823\n",
      "Epoch: 55 Iter 119 Train_loss: 0.00020418461645022035\n",
      "Epoch: 55 Iter 139 Train_loss: 0.00019895585137419403\n",
      "Epoch: 55 Iter 159 Train_loss: 0.00021002994617447257\n",
      "Epoch: 55 Iter 179 Train_loss: 0.00024176412262022495\n",
      "Epoch: 55 Iter 199 Train_loss: 0.00019844234338961542\n",
      "Epoch: 55 Iter 219 Train_loss: 0.00020002094970550388\n",
      "Epoch: 55 Iter 239 Train_loss: 0.00019585370318964124\n",
      "Epoch: 55 Iter 259 Train_loss: 0.00019413804693613201\n",
      "Epoch: 55 Iter 279 Train_loss: 0.0002389816945651546\n",
      "Epoch: 55 Iter 299 Train_loss: 0.0001440078194718808\n",
      "Epoch: 55 Iter 319 Train_loss: 0.00022511875431519002\n",
      "Epoch: 55 Iter 339 Train_loss: 0.00021636299788951874\n",
      "Epoch: 55 Iter 359 Train_loss: 0.00022010279644746333\n",
      "Epoch: 55 Iter 379 Train_loss: 0.00019549441640265286\n",
      "Epoch: 55 Iter 399 Train_loss: 0.00018861060380004346\n",
      "Epoch: 55 Iter 419 Train_loss: 0.0001740799198159948\n",
      "Epoch: 55 Iter 439 Train_loss: 0.00018227772670798004\n",
      "Epoch: 55 Iter 459 Train_loss: 0.00021336821373552084\n",
      "Epoch: 55 Iter 479 Train_loss: 0.00022768689086660743\n",
      "Epoch: 55 Iter 499 Train_loss: 0.00020143341680523008\n",
      "Epoch: 55 Iter 519 Train_loss: 0.00018313413602299988\n",
      "Epoch: 55 Iter 539 Train_loss: 0.0002603672328405082\n",
      "Epoch: 55 Iter 559 Train_loss: 0.00021428537729661912\n",
      "Epoch: 55 Iter 579 Train_loss: 0.0002040060207946226\n",
      "Epoch: 55 Iter 599 Train_loss: 0.00020365229283925146\n",
      "Epoch: 55 Iter 619 Train_loss: 0.00019545506802387536\n",
      "Epoch: 55 Iter 639 Train_loss: 0.00023422738013323396\n",
      "Epoch: 55 Iter 659 Train_loss: 0.00023376793251372874\n",
      "Epoch: 55 Iter 679 Train_loss: 0.0002147294580936432\n",
      "Epoch: 55 Iter 699 Train_loss: 0.00020354933803901076\n",
      "Epoch: 55 Iter 719 Train_loss: 0.0001938420464284718\n",
      "Epoch: 55 Iter 739 Train_loss: 0.0002455351350363344\n",
      "Epoch: 55 Iter 759 Train_loss: 0.00022001775505486876\n",
      "Epoch: 55 Iter 779 Train_loss: 0.00020331336418166757\n",
      "Epoch: 55 Iter 799 Train_loss: 0.00020735627913381904\n",
      "Epoch: 55 Iter 819 Train_loss: 0.0002127576881321147\n",
      "Epoch: 55 Iter 839 Train_loss: 0.00021839464898221195\n",
      "Epoch: 55 Iter 859 Train_loss: 0.00021224492229521275\n",
      "Epoch: 55 Iter 879 Train_loss: 0.00021028026822023094\n",
      "Epoch: 55 Iter 899 Train_loss: 0.0002155830297851935\n",
      "Epoch: 55 Iter 919 Train_loss: 0.0001967159623745829\n",
      "Epoch: 55 Iter 939 Train_loss: 0.00018450245261192322\n",
      "Epoch: 55 Iter 959 Train_loss: 0.00020370338461361825\n",
      "Epoch: 55 Iter 979 Train_loss: 0.00022547411208506674\n",
      "Epoch: 55 Iter 999 Train_loss: 0.0002507212630007416\n",
      "Epoch: 55 Iter 1019 Train_loss: 0.00020339555339887738\n",
      "Epoch: 55 Iter 1039 Train_loss: 0.00018092559184879065\n",
      "Epoch: 55 Iter 1059 Train_loss: 0.00021083024330437183\n",
      "[ 55/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch: 56 Iter 19 Train_loss: 0.000205411619390361\n",
      "Epoch: 56 Iter 39 Train_loss: 0.00022909404651727527\n",
      "Epoch: 56 Iter 59 Train_loss: 0.00020023366960231215\n",
      "Epoch: 56 Iter 79 Train_loss: 0.00018360838294029236\n",
      "Epoch: 56 Iter 99 Train_loss: 0.00019172040629200637\n",
      "Epoch: 56 Iter 119 Train_loss: 0.00017828399722930044\n",
      "Epoch: 56 Iter 139 Train_loss: 0.000201573726371862\n",
      "Epoch: 56 Iter 159 Train_loss: 0.00020568440959323198\n",
      "Epoch: 56 Iter 179 Train_loss: 0.0002070941700367257\n",
      "Epoch: 56 Iter 199 Train_loss: 0.00019588472787290812\n",
      "Epoch: 56 Iter 219 Train_loss: 0.00022359899594448507\n",
      "Epoch: 56 Iter 239 Train_loss: 0.00018686677503865212\n",
      "Epoch: 56 Iter 259 Train_loss: 0.0001887412799987942\n",
      "Epoch: 56 Iter 279 Train_loss: 0.00022521623759530485\n",
      "Epoch: 56 Iter 299 Train_loss: 0.0002782134688459337\n",
      "Epoch: 56 Iter 319 Train_loss: 0.00019893402350135148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Iter 339 Train_loss: 0.00020108380704186857\n",
      "Epoch: 56 Iter 359 Train_loss: 0.00017856310296338052\n",
      "Epoch: 56 Iter 379 Train_loss: 0.0001975570630747825\n",
      "Epoch: 56 Iter 399 Train_loss: 0.000174490109202452\n",
      "Epoch: 56 Iter 419 Train_loss: 0.0002060009428532794\n",
      "Epoch: 56 Iter 439 Train_loss: 0.00021869741613045335\n",
      "Epoch: 56 Iter 459 Train_loss: 0.000254596903687343\n",
      "Epoch: 56 Iter 479 Train_loss: 0.00019578676437959075\n",
      "Epoch: 56 Iter 499 Train_loss: 0.0001938423520186916\n",
      "Epoch: 56 Iter 519 Train_loss: 0.00018823833670467138\n",
      "Epoch: 56 Iter 539 Train_loss: 0.00020288863743189722\n",
      "Epoch: 56 Iter 559 Train_loss: 0.00018772983457893133\n",
      "Epoch: 56 Iter 579 Train_loss: 0.0002042504056589678\n",
      "Epoch: 56 Iter 599 Train_loss: 0.00023211205552797765\n",
      "Epoch: 56 Iter 619 Train_loss: 0.00021138036390766501\n",
      "Epoch: 56 Iter 639 Train_loss: 0.00019086642714682966\n",
      "Epoch: 56 Iter 659 Train_loss: 0.00022804732725489885\n",
      "Epoch: 56 Iter 679 Train_loss: 0.00019660610996652395\n",
      "Epoch: 56 Iter 699 Train_loss: 0.0002040475665125996\n",
      "Epoch: 56 Iter 719 Train_loss: 0.00020063066040165722\n",
      "Epoch: 56 Iter 739 Train_loss: 0.00022661566617898643\n",
      "Epoch: 56 Iter 759 Train_loss: 0.0002903725835494697\n",
      "Epoch: 56 Iter 779 Train_loss: 0.00019711673667188734\n",
      "Epoch: 56 Iter 799 Train_loss: 0.0002124498423654586\n",
      "Epoch: 56 Iter 819 Train_loss: 0.00023874513863120228\n",
      "Epoch: 56 Iter 839 Train_loss: 0.00022656006331089884\n",
      "Epoch: 56 Iter 859 Train_loss: 0.00019888280075974762\n",
      "Epoch: 56 Iter 879 Train_loss: 0.0001994057820411399\n",
      "Epoch: 56 Iter 899 Train_loss: 0.00024638950708322227\n",
      "Epoch: 56 Iter 919 Train_loss: 0.00019903408247046173\n",
      "Epoch: 56 Iter 939 Train_loss: 0.00024389922327827662\n",
      "Epoch: 56 Iter 959 Train_loss: 0.00019714070367626846\n",
      "Epoch: 56 Iter 979 Train_loss: 0.00022034603171050549\n",
      "Epoch: 56 Iter 999 Train_loss: 0.0001915160391945392\n",
      "Epoch: 56 Iter 1019 Train_loss: 0.00021277104679029435\n",
      "Epoch: 56 Iter 1039 Train_loss: 0.00018716123304329813\n",
      "Epoch: 56 Iter 1059 Train_loss: 0.0002686559164430946\n",
      "[ 56/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch: 57 Iter 19 Train_loss: 0.00019911832350771874\n",
      "Epoch: 57 Iter 39 Train_loss: 0.0002195105771534145\n",
      "Epoch: 57 Iter 59 Train_loss: 0.00023531328770332038\n",
      "Epoch: 57 Iter 79 Train_loss: 0.00021535276027861983\n",
      "Epoch: 57 Iter 99 Train_loss: 0.00020612168009392917\n",
      "Epoch: 57 Iter 119 Train_loss: 0.00016662896086927503\n",
      "Epoch: 57 Iter 139 Train_loss: 0.00020298277377150953\n",
      "Epoch: 57 Iter 159 Train_loss: 0.00017667470092419535\n",
      "Epoch: 57 Iter 179 Train_loss: 0.00024621179909445345\n",
      "Epoch: 57 Iter 199 Train_loss: 0.00019794743275269866\n",
      "Epoch: 57 Iter 219 Train_loss: 0.0001937609922606498\n",
      "Epoch: 57 Iter 239 Train_loss: 0.00023037634673528373\n",
      "Epoch: 57 Iter 259 Train_loss: 0.00021336766076274216\n",
      "Epoch: 57 Iter 279 Train_loss: 0.0001875402667792514\n",
      "Epoch: 57 Iter 299 Train_loss: 0.0001800895552150905\n",
      "Epoch: 57 Iter 319 Train_loss: 0.00021325408306438476\n",
      "Epoch: 57 Iter 339 Train_loss: 0.0002229206293122843\n",
      "Epoch: 57 Iter 359 Train_loss: 0.00021565800125245005\n",
      "Epoch: 57 Iter 379 Train_loss: 0.00022481333871837705\n",
      "Epoch: 57 Iter 399 Train_loss: 0.00019461118790786713\n",
      "Epoch: 57 Iter 419 Train_loss: 0.00022171765158418566\n",
      "Epoch: 57 Iter 439 Train_loss: 0.00020635304099414498\n",
      "Epoch: 57 Iter 459 Train_loss: 0.0001860476186266169\n",
      "Epoch: 57 Iter 479 Train_loss: 0.0002244358038296923\n",
      "Epoch: 57 Iter 499 Train_loss: 0.0001949472789419815\n",
      "Epoch: 57 Iter 519 Train_loss: 0.00020326496451161802\n",
      "Epoch: 57 Iter 539 Train_loss: 0.00018158377497456968\n",
      "Epoch: 57 Iter 559 Train_loss: 0.00022615953639615327\n",
      "Epoch: 57 Iter 579 Train_loss: 0.00021508878853637725\n",
      "Epoch: 57 Iter 599 Train_loss: 0.00017701461911201477\n",
      "Epoch: 57 Iter 619 Train_loss: 0.0001973430480575189\n",
      "Epoch: 57 Iter 639 Train_loss: 0.00020316797599662095\n",
      "Epoch: 57 Iter 659 Train_loss: 0.00019716809038072824\n",
      "Epoch: 57 Iter 679 Train_loss: 0.00023882565437816083\n",
      "Epoch: 57 Iter 699 Train_loss: 0.0001938886707648635\n",
      "Epoch: 57 Iter 719 Train_loss: 0.00023238718858920038\n",
      "Epoch: 57 Iter 739 Train_loss: 0.0001966904674191028\n",
      "Epoch: 57 Iter 759 Train_loss: 0.00018932925013359636\n",
      "Epoch: 57 Iter 779 Train_loss: 0.00020458230574149638\n",
      "Epoch: 57 Iter 799 Train_loss: 0.00022840489691589028\n",
      "Epoch: 57 Iter 819 Train_loss: 0.00021091593953315169\n",
      "Epoch: 57 Iter 839 Train_loss: 0.0002433991030557081\n",
      "Epoch: 57 Iter 859 Train_loss: 0.00022866945073474199\n",
      "Epoch: 57 Iter 879 Train_loss: 0.00019151826563756913\n",
      "Epoch: 57 Iter 899 Train_loss: 0.0001963652903214097\n",
      "Epoch: 57 Iter 919 Train_loss: 0.00021852787176612765\n",
      "Epoch: 57 Iter 939 Train_loss: 0.00023581553250551224\n",
      "Epoch: 57 Iter 959 Train_loss: 0.00020204165775794536\n",
      "Epoch: 57 Iter 979 Train_loss: 0.0002337750484002754\n",
      "Epoch: 57 Iter 999 Train_loss: 0.0002147136110579595\n",
      "Epoch: 57 Iter 1019 Train_loss: 0.00018769178132060915\n",
      "Epoch: 57 Iter 1039 Train_loss: 0.00018626984092406929\n",
      "Epoch: 57 Iter 1059 Train_loss: 0.0001948877179529518\n",
      "[ 57/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch: 58 Iter 19 Train_loss: 0.00019833924307022244\n",
      "Epoch: 58 Iter 39 Train_loss: 0.00017922717961482704\n",
      "Epoch: 58 Iter 59 Train_loss: 0.00021890868083573878\n",
      "Epoch: 58 Iter 79 Train_loss: 0.0002357667253818363\n",
      "Epoch: 58 Iter 99 Train_loss: 0.00022166932467371225\n",
      "Epoch: 58 Iter 119 Train_loss: 0.0002179222647100687\n",
      "Epoch: 58 Iter 139 Train_loss: 0.00019547979172784835\n",
      "Epoch: 58 Iter 159 Train_loss: 0.00018971094687003642\n",
      "Epoch: 58 Iter 179 Train_loss: 0.00018900245777331293\n",
      "Epoch: 58 Iter 199 Train_loss: 0.00019198593508917838\n",
      "Epoch: 58 Iter 219 Train_loss: 0.0001848082320066169\n",
      "Epoch: 58 Iter 239 Train_loss: 0.00019265641458332539\n",
      "Epoch: 58 Iter 259 Train_loss: 0.00019047003297600895\n",
      "Epoch: 58 Iter 279 Train_loss: 0.0002381611557211727\n",
      "Epoch: 58 Iter 299 Train_loss: 0.00018388220632914454\n",
      "Epoch: 58 Iter 319 Train_loss: 0.00025203422410413623\n",
      "Epoch: 58 Iter 339 Train_loss: 0.00024349428713321686\n",
      "Epoch: 58 Iter 359 Train_loss: 0.00019727014296222478\n",
      "Epoch: 58 Iter 379 Train_loss: 0.00018010941857937723\n",
      "Epoch: 58 Iter 399 Train_loss: 0.00022535388416144997\n",
      "Epoch: 58 Iter 419 Train_loss: 0.0001991050667129457\n",
      "Epoch: 58 Iter 439 Train_loss: 0.00020784972002729774\n",
      "Epoch: 58 Iter 459 Train_loss: 0.00022831490787211806\n",
      "Epoch: 58 Iter 479 Train_loss: 0.00020495538774412125\n",
      "Epoch: 58 Iter 499 Train_loss: 0.00021029129857197404\n",
      "Epoch: 58 Iter 519 Train_loss: 0.00021831091726198792\n",
      "Epoch: 58 Iter 539 Train_loss: 0.0002534021914470941\n",
      "Epoch: 58 Iter 559 Train_loss: 0.00018679907952900976\n",
      "Epoch: 58 Iter 579 Train_loss: 0.000176900444785133\n",
      "Epoch: 58 Iter 599 Train_loss: 0.00018370631732977927\n",
      "Epoch: 58 Iter 619 Train_loss: 0.00020782437059096992\n",
      "Epoch: 58 Iter 639 Train_loss: 0.00019806706404779106\n",
      "Epoch: 58 Iter 659 Train_loss: 0.0001769516384229064\n",
      "Epoch: 58 Iter 679 Train_loss: 0.000203632764169015\n",
      "Epoch: 58 Iter 699 Train_loss: 0.00020383240189403296\n",
      "Epoch: 58 Iter 719 Train_loss: 0.0001941673253895715\n",
      "Epoch: 58 Iter 739 Train_loss: 0.00017961183039005846\n",
      "Epoch: 58 Iter 759 Train_loss: 0.00024909593048505485\n",
      "Epoch: 58 Iter 779 Train_loss: 0.00024193058197852224\n",
      "Epoch: 58 Iter 799 Train_loss: 0.00018965305935125798\n",
      "Epoch: 58 Iter 819 Train_loss: 0.00018977561558131129\n",
      "Epoch: 58 Iter 839 Train_loss: 0.00020412822777871042\n",
      "Epoch: 58 Iter 859 Train_loss: 0.00027441460406407714\n",
      "Epoch: 58 Iter 879 Train_loss: 0.0002208119840361178\n",
      "Epoch: 58 Iter 899 Train_loss: 0.00022016077127773315\n",
      "Epoch: 58 Iter 919 Train_loss: 0.0002119457785738632\n",
      "Epoch: 58 Iter 939 Train_loss: 0.00020583053992595524\n",
      "Epoch: 58 Iter 959 Train_loss: 0.000309507769998163\n",
      "Epoch: 58 Iter 979 Train_loss: 0.0002156259724870324\n",
      "Epoch: 58 Iter 999 Train_loss: 0.00022551187430508435\n",
      "Epoch: 58 Iter 1019 Train_loss: 0.0002566949697211385\n",
      "Epoch: 58 Iter 1039 Train_loss: 0.0002474895736668259\n",
      "Epoch: 58 Iter 1059 Train_loss: 0.00017984097939915955\n",
      "[ 58/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch: 59 Iter 19 Train_loss: 0.00019961316138505936\n",
      "Epoch: 59 Iter 39 Train_loss: 0.00017319359176326543\n",
      "Epoch: 59 Iter 59 Train_loss: 0.0002098987315548584\n",
      "Epoch: 59 Iter 79 Train_loss: 0.00018768689187709242\n",
      "Epoch: 59 Iter 99 Train_loss: 0.00020652951207011938\n",
      "Epoch: 59 Iter 119 Train_loss: 0.00019289666670374572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 Iter 139 Train_loss: 0.00019413464178796858\n",
      "Epoch: 59 Iter 159 Train_loss: 0.0002733738801907748\n",
      "Epoch: 59 Iter 179 Train_loss: 0.00018267749692313373\n",
      "Epoch: 59 Iter 199 Train_loss: 0.00022593268658965826\n",
      "Epoch: 59 Iter 219 Train_loss: 0.00019680762488860637\n",
      "Epoch: 59 Iter 239 Train_loss: 0.00020763551583513618\n",
      "Epoch: 59 Iter 259 Train_loss: 0.0002803968091029674\n",
      "Epoch: 59 Iter 279 Train_loss: 0.000199948059162125\n",
      "Epoch: 59 Iter 299 Train_loss: 0.00021012756042182446\n",
      "Epoch: 59 Iter 319 Train_loss: 0.00019639015954453498\n",
      "Epoch: 59 Iter 339 Train_loss: 0.00020826059335377067\n",
      "Epoch: 59 Iter 359 Train_loss: 0.0002115898096235469\n",
      "Epoch: 59 Iter 379 Train_loss: 0.0002113762457156554\n",
      "Epoch: 59 Iter 399 Train_loss: 0.00020985963055863976\n",
      "Epoch: 59 Iter 419 Train_loss: 0.0002070404152618721\n",
      "Epoch: 59 Iter 439 Train_loss: 0.00020293588750064373\n",
      "Epoch: 59 Iter 459 Train_loss: 0.0001962047681445256\n",
      "Epoch: 59 Iter 479 Train_loss: 0.00020660275185946375\n",
      "Epoch: 59 Iter 499 Train_loss: 0.00022133950551506132\n",
      "Epoch: 59 Iter 519 Train_loss: 0.00018161407206207514\n",
      "Epoch: 59 Iter 539 Train_loss: 0.0002159300202038139\n",
      "Epoch: 59 Iter 559 Train_loss: 0.00019574409816414118\n",
      "Epoch: 59 Iter 579 Train_loss: 0.0002063386345980689\n",
      "Epoch: 59 Iter 599 Train_loss: 0.00022836000425741076\n",
      "Epoch: 59 Iter 619 Train_loss: 0.0002889208553824574\n",
      "Epoch: 59 Iter 639 Train_loss: 0.00031449197558686137\n",
      "Epoch: 59 Iter 659 Train_loss: 0.0001902544463519007\n",
      "Epoch: 59 Iter 679 Train_loss: 0.00019404418708290905\n",
      "Epoch: 59 Iter 699 Train_loss: 0.00021942754392512143\n",
      "Epoch: 59 Iter 719 Train_loss: 0.00023344677174463868\n",
      "Epoch: 59 Iter 739 Train_loss: 0.00022234173957258463\n",
      "Epoch: 59 Iter 759 Train_loss: 0.00022802475723437965\n",
      "Epoch: 59 Iter 779 Train_loss: 0.0002082392165903002\n",
      "Epoch: 59 Iter 799 Train_loss: 0.00021068273053970188\n",
      "Epoch: 59 Iter 819 Train_loss: 0.00022183633700478822\n",
      "Epoch: 59 Iter 839 Train_loss: 0.00019708549370989203\n",
      "Epoch: 59 Iter 859 Train_loss: 0.00019367225468158722\n",
      "Epoch: 59 Iter 879 Train_loss: 0.000236352818319574\n",
      "Epoch: 59 Iter 899 Train_loss: 0.00024549252702854574\n",
      "Epoch: 59 Iter 919 Train_loss: 0.00018601055489853024\n",
      "Epoch: 59 Iter 939 Train_loss: 0.00017463955737184733\n",
      "Epoch: 59 Iter 959 Train_loss: 0.00023774508736096323\n",
      "Epoch: 59 Iter 979 Train_loss: 0.00019344889733474702\n",
      "Epoch: 59 Iter 999 Train_loss: 0.00020491165923886\n",
      "Epoch: 59 Iter 1019 Train_loss: 0.00020448023860808462\n",
      "Epoch: 59 Iter 1039 Train_loss: 0.00018224361701868474\n",
      "Epoch: 59 Iter 1059 Train_loss: 0.00022477013408206403\n",
      "[ 59/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch: 60 Iter 19 Train_loss: 0.00025902563356794417\n",
      "Epoch: 60 Iter 39 Train_loss: 0.00017258376465179026\n",
      "Epoch: 60 Iter 59 Train_loss: 0.00023550183686893433\n",
      "Epoch: 60 Iter 79 Train_loss: 0.00021809147438034415\n",
      "Epoch: 60 Iter 99 Train_loss: 0.0001913302839966491\n",
      "Epoch: 60 Iter 119 Train_loss: 0.00019605689158197492\n",
      "Epoch: 60 Iter 139 Train_loss: 0.00020599692652467638\n",
      "Epoch: 60 Iter 159 Train_loss: 0.00021221875795163214\n",
      "Epoch: 60 Iter 179 Train_loss: 0.00021713448222726583\n",
      "Epoch: 60 Iter 199 Train_loss: 0.00018849968910217285\n",
      "Epoch: 60 Iter 219 Train_loss: 0.0002214951382484287\n",
      "Epoch: 60 Iter 239 Train_loss: 0.00021151418332010508\n",
      "Epoch: 60 Iter 259 Train_loss: 0.0002105187450069934\n",
      "Epoch: 60 Iter 279 Train_loss: 0.00021926555200479925\n",
      "Epoch: 60 Iter 299 Train_loss: 0.00022987453849054873\n",
      "Epoch: 60 Iter 319 Train_loss: 0.00018378187087364495\n",
      "Epoch: 60 Iter 339 Train_loss: 0.0001990618766285479\n",
      "Epoch: 60 Iter 359 Train_loss: 0.00017182888404931873\n",
      "Epoch: 60 Iter 379 Train_loss: 0.00020190156647004187\n",
      "Epoch: 60 Iter 399 Train_loss: 0.00028384881443344057\n",
      "Epoch: 60 Iter 419 Train_loss: 0.0002164076140616089\n",
      "Epoch: 60 Iter 439 Train_loss: 0.0002027664304478094\n",
      "Epoch: 60 Iter 459 Train_loss: 0.00022088053810875863\n",
      "Epoch: 60 Iter 479 Train_loss: 0.0002009328018175438\n",
      "Epoch: 60 Iter 499 Train_loss: 0.00020340883929748088\n",
      "Epoch: 60 Iter 519 Train_loss: 0.00022737064864486456\n",
      "Epoch: 60 Iter 539 Train_loss: 0.00022688617173116654\n",
      "Epoch: 60 Iter 559 Train_loss: 0.00022761939908377826\n",
      "Epoch: 60 Iter 579 Train_loss: 0.0002281773486174643\n",
      "Epoch: 60 Iter 599 Train_loss: 0.0001890659477794543\n",
      "Epoch: 60 Iter 619 Train_loss: 0.00021281925728544593\n",
      "Epoch: 60 Iter 639 Train_loss: 0.00021890091011300683\n",
      "Epoch: 60 Iter 659 Train_loss: 0.00020501822291407734\n",
      "Epoch: 60 Iter 679 Train_loss: 0.00018590579566080123\n",
      "Epoch: 60 Iter 699 Train_loss: 0.0002448585582897067\n",
      "Epoch: 60 Iter 719 Train_loss: 0.00021742550597991794\n",
      "Epoch: 60 Iter 739 Train_loss: 0.00019240246911067516\n",
      "Epoch: 60 Iter 759 Train_loss: 0.000193745392607525\n",
      "Epoch: 60 Iter 779 Train_loss: 0.00019321811851114035\n",
      "Epoch: 60 Iter 799 Train_loss: 0.00019019660248886794\n",
      "Epoch: 60 Iter 819 Train_loss: 0.00023223900643642992\n",
      "Epoch: 60 Iter 839 Train_loss: 0.00018431049829814583\n",
      "Epoch: 60 Iter 859 Train_loss: 0.00022275549417827278\n",
      "Epoch: 60 Iter 879 Train_loss: 0.0002115490788128227\n",
      "Epoch: 60 Iter 899 Train_loss: 0.0002189989754697308\n",
      "Epoch: 60 Iter 919 Train_loss: 0.00018898912821896374\n",
      "Epoch: 60 Iter 939 Train_loss: 0.0001905534154502675\n",
      "Epoch: 60 Iter 959 Train_loss: 0.00016716613026801497\n",
      "Epoch: 60 Iter 979 Train_loss: 0.00022880654432810843\n",
      "Epoch: 60 Iter 999 Train_loss: 0.00023326931113842875\n",
      "Epoch: 60 Iter 1019 Train_loss: 0.00018049567006528378\n",
      "Epoch: 60 Iter 1039 Train_loss: 0.00023475628404412419\n",
      "Epoch: 60 Iter 1059 Train_loss: 0.0002489113248884678\n",
      "[ 60/100]train_loss:0.00021valid_loss:0.00025\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch: 61 Iter 19 Train_loss: 0.00018987050862051547\n",
      "Epoch: 61 Iter 39 Train_loss: 0.0002156563277821988\n",
      "Epoch: 61 Iter 59 Train_loss: 0.00019448131206445396\n",
      "Epoch: 61 Iter 79 Train_loss: 0.00018247401749249548\n",
      "Epoch: 61 Iter 99 Train_loss: 0.00018915807595476508\n",
      "Epoch: 61 Iter 119 Train_loss: 0.0002297328319400549\n",
      "Epoch: 61 Iter 139 Train_loss: 0.0001854119764175266\n",
      "Epoch: 61 Iter 159 Train_loss: 0.000194230888155289\n",
      "Epoch: 61 Iter 179 Train_loss: 0.00019552180310711265\n",
      "Epoch: 61 Iter 199 Train_loss: 0.0001756150886649266\n",
      "Epoch: 61 Iter 219 Train_loss: 0.00017058236699085683\n",
      "Epoch: 61 Iter 239 Train_loss: 0.0001976901403395459\n",
      "Epoch: 61 Iter 259 Train_loss: 0.00020619973656721413\n",
      "Epoch: 61 Iter 279 Train_loss: 0.00027749003493227065\n",
      "Epoch: 61 Iter 299 Train_loss: 0.0002607211354188621\n",
      "Epoch: 61 Iter 319 Train_loss: 0.0002074083749903366\n",
      "Epoch: 61 Iter 339 Train_loss: 0.00017444705008529127\n",
      "Epoch: 61 Iter 359 Train_loss: 0.00020864659745711833\n",
      "Epoch: 61 Iter 379 Train_loss: 0.00019079720368608832\n",
      "Epoch: 61 Iter 399 Train_loss: 0.00020002186647616327\n",
      "Epoch: 61 Iter 419 Train_loss: 0.00021777459187433124\n",
      "Epoch: 61 Iter 439 Train_loss: 0.00023335473088081926\n",
      "Epoch: 61 Iter 459 Train_loss: 0.0002132849913323298\n",
      "Epoch: 61 Iter 479 Train_loss: 0.0001887816470116377\n",
      "Epoch: 61 Iter 499 Train_loss: 0.00029278892907314\n",
      "Epoch: 61 Iter 519 Train_loss: 0.00020092794147785753\n",
      "Epoch: 61 Iter 539 Train_loss: 0.00023441182565875351\n",
      "Epoch: 61 Iter 559 Train_loss: 0.0002007222210522741\n",
      "Epoch: 61 Iter 579 Train_loss: 0.0002164261823054403\n",
      "Epoch: 61 Iter 599 Train_loss: 0.00024257281620521098\n",
      "Epoch: 61 Iter 619 Train_loss: 0.00021583827037829906\n",
      "Epoch: 61 Iter 639 Train_loss: 0.00020645941549446434\n",
      "Epoch: 61 Iter 659 Train_loss: 0.0001890391722554341\n",
      "Epoch: 61 Iter 679 Train_loss: 0.00023985521693248302\n",
      "Epoch: 61 Iter 699 Train_loss: 0.0002413140027783811\n",
      "Epoch: 61 Iter 719 Train_loss: 0.0002186309138778597\n",
      "Epoch: 61 Iter 739 Train_loss: 0.00020380386558827013\n",
      "Epoch: 61 Iter 759 Train_loss: 0.00023541905102320015\n",
      "Epoch: 61 Iter 779 Train_loss: 0.0001601366966497153\n",
      "Epoch: 61 Iter 799 Train_loss: 0.0002100211859215051\n",
      "Epoch: 61 Iter 819 Train_loss: 0.00019744127348531038\n",
      "Epoch: 61 Iter 839 Train_loss: 0.00020709542150143534\n",
      "Epoch: 61 Iter 859 Train_loss: 0.00020885384583380073\n",
      "Epoch: 61 Iter 879 Train_loss: 0.00021275952167343348\n",
      "Epoch: 61 Iter 899 Train_loss: 0.00020689464872702956\n",
      "Epoch: 61 Iter 919 Train_loss: 0.00024314268375746906\n",
      "Epoch: 61 Iter 939 Train_loss: 0.00024440669221803546\n",
      "Epoch: 61 Iter 959 Train_loss: 0.00021899890271015465\n",
      "Epoch: 61 Iter 979 Train_loss: 0.00019161314412485808\n",
      "Epoch: 61 Iter 999 Train_loss: 0.0001898879127111286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 Iter 1019 Train_loss: 0.00023325413349084556\n",
      "Epoch: 61 Iter 1039 Train_loss: 0.0001881939679151401\n",
      "Epoch: 61 Iter 1059 Train_loss: 0.00020272680558264256\n",
      "[ 61/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch: 62 Iter 19 Train_loss: 0.00018555005954112858\n",
      "Epoch: 62 Iter 39 Train_loss: 0.0001725019101286307\n",
      "Epoch: 62 Iter 59 Train_loss: 0.00017870184092316777\n",
      "Epoch: 62 Iter 79 Train_loss: 0.00026661509764380753\n",
      "Epoch: 62 Iter 99 Train_loss: 0.00019664915453176945\n",
      "Epoch: 62 Iter 119 Train_loss: 0.00026831470313481987\n",
      "Epoch: 62 Iter 139 Train_loss: 0.00019600565428845584\n",
      "Epoch: 62 Iter 159 Train_loss: 0.00016882047930266708\n",
      "Epoch: 62 Iter 179 Train_loss: 0.00018311748863197863\n",
      "Epoch: 62 Iter 199 Train_loss: 0.00020008475985378027\n",
      "Epoch: 62 Iter 219 Train_loss: 0.0001783736515790224\n",
      "Epoch: 62 Iter 239 Train_loss: 0.0002076321979984641\n",
      "Epoch: 62 Iter 259 Train_loss: 0.00018260657088831067\n",
      "Epoch: 62 Iter 279 Train_loss: 0.00019089749548584223\n",
      "Epoch: 62 Iter 299 Train_loss: 0.00019122767844237387\n",
      "Epoch: 62 Iter 319 Train_loss: 0.00018833598005585372\n",
      "Epoch: 62 Iter 339 Train_loss: 0.0002484637952875346\n",
      "Epoch: 62 Iter 359 Train_loss: 0.00018430819909553975\n",
      "Epoch: 62 Iter 379 Train_loss: 0.00017247367941308767\n",
      "Epoch: 62 Iter 399 Train_loss: 0.00018756375357042998\n",
      "Epoch: 62 Iter 419 Train_loss: 0.00020230811787769198\n",
      "Epoch: 62 Iter 439 Train_loss: 0.00022134567552711815\n",
      "Epoch: 62 Iter 459 Train_loss: 0.00019069261907134205\n",
      "Epoch: 62 Iter 479 Train_loss: 0.00019719862029887736\n",
      "Epoch: 62 Iter 499 Train_loss: 0.00019747715850826353\n",
      "Epoch: 62 Iter 519 Train_loss: 0.00022289602202363312\n",
      "Epoch: 62 Iter 539 Train_loss: 0.00017966574523597956\n",
      "Epoch: 62 Iter 559 Train_loss: 0.0001745470508467406\n",
      "Epoch: 62 Iter 579 Train_loss: 0.00020477897487580776\n",
      "Epoch: 62 Iter 599 Train_loss: 0.000206152064492926\n",
      "Epoch: 62 Iter 619 Train_loss: 0.0002045556320808828\n",
      "Epoch: 62 Iter 639 Train_loss: 0.00021544058108702302\n",
      "Epoch: 62 Iter 659 Train_loss: 0.0001995927159441635\n",
      "Epoch: 62 Iter 679 Train_loss: 0.00023444971884600818\n",
      "Epoch: 62 Iter 699 Train_loss: 0.00019862409681081772\n",
      "Epoch: 62 Iter 719 Train_loss: 0.00019585156405810267\n",
      "Epoch: 62 Iter 739 Train_loss: 0.00019848205556627363\n",
      "Epoch: 62 Iter 759 Train_loss: 0.0001951745362021029\n",
      "Epoch: 62 Iter 779 Train_loss: 0.00019338198762852699\n",
      "Epoch: 62 Iter 799 Train_loss: 0.0001918100897455588\n",
      "Epoch: 62 Iter 819 Train_loss: 0.00017001695232465863\n",
      "Epoch: 62 Iter 839 Train_loss: 0.00020731317636091262\n",
      "Epoch: 62 Iter 859 Train_loss: 0.000203041490749456\n",
      "Epoch: 62 Iter 879 Train_loss: 0.00026795975281856954\n",
      "Epoch: 62 Iter 899 Train_loss: 0.00022677228844258934\n",
      "Epoch: 62 Iter 919 Train_loss: 0.00020295691501814872\n",
      "Epoch: 62 Iter 939 Train_loss: 0.0002157294366043061\n",
      "Epoch: 62 Iter 959 Train_loss: 0.00018763825937639922\n",
      "Epoch: 62 Iter 979 Train_loss: 0.00019979808712378144\n",
      "Epoch: 62 Iter 999 Train_loss: 0.00018633170111570507\n",
      "Epoch: 62 Iter 1019 Train_loss: 0.00019198459631297737\n",
      "Epoch: 62 Iter 1039 Train_loss: 0.00022219585662242025\n",
      "Epoch: 62 Iter 1059 Train_loss: 0.00020431900338735431\n",
      "[ 62/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch: 63 Iter 19 Train_loss: 0.00018493650713935494\n",
      "Epoch: 63 Iter 39 Train_loss: 0.0002205928321927786\n",
      "Epoch: 63 Iter 59 Train_loss: 0.00018689654825720936\n",
      "Epoch: 63 Iter 79 Train_loss: 0.00023568671895191073\n",
      "Epoch: 63 Iter 99 Train_loss: 0.00017384139937348664\n",
      "Epoch: 63 Iter 119 Train_loss: 0.00020169701019767672\n",
      "Epoch: 63 Iter 139 Train_loss: 0.00018019482376985252\n",
      "Epoch: 63 Iter 159 Train_loss: 0.00022432506375480443\n",
      "Epoch: 63 Iter 179 Train_loss: 0.0001957439089892432\n",
      "Epoch: 63 Iter 199 Train_loss: 0.00019223256094846874\n",
      "Epoch: 63 Iter 219 Train_loss: 0.0002608943323139101\n",
      "Epoch: 63 Iter 239 Train_loss: 0.00020191346993669868\n",
      "Epoch: 63 Iter 259 Train_loss: 0.00020502806000877172\n",
      "Epoch: 63 Iter 279 Train_loss: 0.00019876241276506335\n",
      "Epoch: 63 Iter 299 Train_loss: 0.00019510350830387324\n",
      "Epoch: 63 Iter 319 Train_loss: 0.00018731359159573913\n",
      "Epoch: 63 Iter 339 Train_loss: 0.00018669472774490714\n",
      "Epoch: 63 Iter 359 Train_loss: 0.00020067511650267988\n",
      "Epoch: 63 Iter 379 Train_loss: 0.00020881292584817857\n",
      "Epoch: 63 Iter 399 Train_loss: 0.00016985983529593796\n",
      "Epoch: 63 Iter 419 Train_loss: 0.00020162943110335618\n",
      "Epoch: 63 Iter 439 Train_loss: 0.00020257796859368682\n",
      "Epoch: 63 Iter 459 Train_loss: 0.00021216453751549125\n",
      "Epoch: 63 Iter 479 Train_loss: 0.00017734122229740024\n",
      "Epoch: 63 Iter 499 Train_loss: 0.0001956777850864455\n",
      "Epoch: 63 Iter 519 Train_loss: 0.0002097045653499663\n",
      "Epoch: 63 Iter 539 Train_loss: 0.00019050197442993522\n",
      "Epoch: 63 Iter 559 Train_loss: 0.00024271041911561042\n",
      "Epoch: 63 Iter 579 Train_loss: 0.00019209421589039266\n",
      "Epoch: 63 Iter 599 Train_loss: 0.0002074457734124735\n",
      "Epoch: 63 Iter 619 Train_loss: 0.00022416777210310102\n",
      "Epoch: 63 Iter 639 Train_loss: 0.00020064853015355766\n",
      "Epoch: 63 Iter 659 Train_loss: 0.00022066777455620468\n",
      "Epoch: 63 Iter 679 Train_loss: 0.00022230311878956854\n",
      "Epoch: 63 Iter 699 Train_loss: 0.00022379160509444773\n",
      "Epoch: 63 Iter 719 Train_loss: 0.00023823481751605868\n",
      "Epoch: 63 Iter 739 Train_loss: 0.00018576017464511096\n",
      "Epoch: 63 Iter 759 Train_loss: 0.00021092049428261817\n",
      "Epoch: 63 Iter 779 Train_loss: 0.00020326461526565254\n",
      "Epoch: 63 Iter 799 Train_loss: 0.00021898647537454963\n",
      "Epoch: 63 Iter 819 Train_loss: 0.0001959908113349229\n",
      "Epoch: 63 Iter 839 Train_loss: 0.0001727666094666347\n",
      "Epoch: 63 Iter 859 Train_loss: 0.00025468828971497715\n",
      "Epoch: 63 Iter 879 Train_loss: 0.00017172413936350495\n",
      "Epoch: 63 Iter 899 Train_loss: 0.00018547833315096796\n",
      "Epoch: 63 Iter 919 Train_loss: 0.00020985622541047633\n",
      "Epoch: 63 Iter 939 Train_loss: 0.00023578024411108345\n",
      "Epoch: 63 Iter 959 Train_loss: 0.0001862371718743816\n",
      "Epoch: 63 Iter 979 Train_loss: 0.00021937450219411403\n",
      "Epoch: 63 Iter 999 Train_loss: 0.00016286609752569348\n",
      "Epoch: 63 Iter 1019 Train_loss: 0.00018933939281851053\n",
      "Epoch: 63 Iter 1039 Train_loss: 0.00021278494386933744\n",
      "Epoch: 63 Iter 1059 Train_loss: 0.00019742308359127492\n",
      "[ 63/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch: 64 Iter 19 Train_loss: 0.00019616560894064605\n",
      "Epoch: 64 Iter 39 Train_loss: 0.00018669175915420055\n",
      "Epoch: 64 Iter 59 Train_loss: 0.00017946973093785346\n",
      "Epoch: 64 Iter 79 Train_loss: 0.00016973786114249378\n",
      "Epoch: 64 Iter 99 Train_loss: 0.00019474777218420058\n",
      "Epoch: 64 Iter 119 Train_loss: 0.00019069657719228417\n",
      "Epoch: 64 Iter 139 Train_loss: 0.00017626548651605844\n",
      "Epoch: 64 Iter 159 Train_loss: 0.00019311983487568796\n",
      "Epoch: 64 Iter 179 Train_loss: 0.00019280130800325423\n",
      "Epoch: 64 Iter 199 Train_loss: 0.00018678195192478597\n",
      "Epoch: 64 Iter 219 Train_loss: 0.00018603542412165552\n",
      "Epoch: 64 Iter 239 Train_loss: 0.00020275158749427646\n",
      "Epoch: 64 Iter 259 Train_loss: 0.00023428267741110176\n",
      "Epoch: 64 Iter 279 Train_loss: 0.00022895008441992104\n",
      "Epoch: 64 Iter 299 Train_loss: 0.00020520070393104106\n",
      "Epoch: 64 Iter 319 Train_loss: 0.00020191930525470525\n",
      "Epoch: 64 Iter 339 Train_loss: 0.0001850381522672251\n",
      "Epoch: 64 Iter 359 Train_loss: 0.0002602959575597197\n",
      "Epoch: 64 Iter 379 Train_loss: 0.0002064532454824075\n",
      "Epoch: 64 Iter 399 Train_loss: 0.00023044171393848956\n",
      "Epoch: 64 Iter 419 Train_loss: 0.00018823682330548763\n",
      "Epoch: 64 Iter 439 Train_loss: 0.0001821625919546932\n",
      "Epoch: 64 Iter 459 Train_loss: 0.00020302455232013017\n",
      "Epoch: 64 Iter 479 Train_loss: 0.00018602752243168652\n",
      "Epoch: 64 Iter 499 Train_loss: 0.00022315813112072647\n",
      "Epoch: 64 Iter 519 Train_loss: 0.0002489539620000869\n",
      "Epoch: 64 Iter 539 Train_loss: 0.00024464880698360503\n",
      "Epoch: 64 Iter 559 Train_loss: 0.00020320859039202332\n",
      "Epoch: 64 Iter 579 Train_loss: 0.00019988046551588923\n",
      "Epoch: 64 Iter 599 Train_loss: 0.00019280097330920398\n",
      "Epoch: 64 Iter 619 Train_loss: 0.0001816143631003797\n",
      "Epoch: 64 Iter 639 Train_loss: 0.00016979433712549508\n",
      "Epoch: 64 Iter 659 Train_loss: 0.0002376641205046326\n",
      "Epoch: 64 Iter 679 Train_loss: 0.00018330848251935095\n",
      "Epoch: 64 Iter 699 Train_loss: 0.0002215188433183357\n",
      "Epoch: 64 Iter 719 Train_loss: 0.0002610158990137279\n",
      "Epoch: 64 Iter 739 Train_loss: 0.00022120107314549387\n",
      "Epoch: 64 Iter 759 Train_loss: 0.00022149417782202363\n",
      "Epoch: 64 Iter 779 Train_loss: 0.00020878046052530408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 Iter 799 Train_loss: 0.0001951272424776107\n",
      "Epoch: 64 Iter 819 Train_loss: 0.00019364897161722183\n",
      "Epoch: 64 Iter 839 Train_loss: 0.00021751470922026783\n",
      "Epoch: 64 Iter 859 Train_loss: 0.00017611256043892354\n",
      "Epoch: 64 Iter 879 Train_loss: 0.0002520170819479972\n",
      "Epoch: 64 Iter 899 Train_loss: 0.00017991960339713842\n",
      "Epoch: 64 Iter 919 Train_loss: 0.00018064292089547962\n",
      "Epoch: 64 Iter 939 Train_loss: 0.00020559504628181458\n",
      "Epoch: 64 Iter 959 Train_loss: 0.00018673572049010545\n",
      "Epoch: 64 Iter 979 Train_loss: 0.000212027138331905\n",
      "Epoch: 64 Iter 999 Train_loss: 0.00027494484675116837\n",
      "Epoch: 64 Iter 1019 Train_loss: 0.0002063006832031533\n",
      "Epoch: 64 Iter 1039 Train_loss: 0.00022049380640964955\n",
      "Epoch: 64 Iter 1059 Train_loss: 0.00020160280109848827\n",
      "[ 64/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch: 65 Iter 19 Train_loss: 0.00019501919450704008\n",
      "Epoch: 65 Iter 39 Train_loss: 0.00023162188881542534\n",
      "Epoch: 65 Iter 59 Train_loss: 0.00020276090072002262\n",
      "Epoch: 65 Iter 79 Train_loss: 0.00020730368851218373\n",
      "Epoch: 65 Iter 99 Train_loss: 0.00018814945360645652\n",
      "Epoch: 65 Iter 119 Train_loss: 0.00018202139472123235\n",
      "Epoch: 65 Iter 139 Train_loss: 0.00019233640341553837\n",
      "Epoch: 65 Iter 159 Train_loss: 0.00018953101243823767\n",
      "Epoch: 65 Iter 179 Train_loss: 0.00019980010983999819\n",
      "Epoch: 65 Iter 199 Train_loss: 0.00019420064927544445\n",
      "Epoch: 65 Iter 219 Train_loss: 0.0001909944403450936\n",
      "Epoch: 65 Iter 239 Train_loss: 0.00021676503820344806\n",
      "Epoch: 65 Iter 259 Train_loss: 0.0001878249750006944\n",
      "Epoch: 65 Iter 279 Train_loss: 0.00019570680160541087\n",
      "Epoch: 65 Iter 299 Train_loss: 0.00025116297183558345\n",
      "Epoch: 65 Iter 319 Train_loss: 0.00024266765103675425\n",
      "Epoch: 65 Iter 339 Train_loss: 0.00019706740567926317\n",
      "Epoch: 65 Iter 359 Train_loss: 0.00021685630781576037\n",
      "Epoch: 65 Iter 379 Train_loss: 0.0001990537712117657\n",
      "Epoch: 65 Iter 399 Train_loss: 0.0001782850013114512\n",
      "Epoch: 65 Iter 419 Train_loss: 0.00019755674293264747\n",
      "Epoch: 65 Iter 439 Train_loss: 0.0002037115627899766\n",
      "Epoch: 65 Iter 459 Train_loss: 0.0001927270059240982\n",
      "Epoch: 65 Iter 479 Train_loss: 0.00018003313743975013\n",
      "Epoch: 65 Iter 499 Train_loss: 0.00020476670761127025\n",
      "Epoch: 65 Iter 519 Train_loss: 0.00017997072427533567\n",
      "Epoch: 65 Iter 539 Train_loss: 0.00020088962628506124\n",
      "Epoch: 65 Iter 559 Train_loss: 0.00020841136574745178\n",
      "Epoch: 65 Iter 579 Train_loss: 0.00023062217223923653\n",
      "Epoch: 65 Iter 599 Train_loss: 0.0002104500454152003\n",
      "Epoch: 65 Iter 619 Train_loss: 0.00022600434022024274\n",
      "Epoch: 65 Iter 639 Train_loss: 0.0001989221345866099\n",
      "Epoch: 65 Iter 659 Train_loss: 0.00024260336067527533\n",
      "Epoch: 65 Iter 679 Train_loss: 0.00018989286036230624\n",
      "Epoch: 65 Iter 699 Train_loss: 0.00020107030286453664\n",
      "Epoch: 65 Iter 719 Train_loss: 0.0002784325333777815\n",
      "Epoch: 65 Iter 739 Train_loss: 0.00021793910127598792\n",
      "Epoch: 65 Iter 759 Train_loss: 0.00021633453434333205\n",
      "Epoch: 65 Iter 779 Train_loss: 0.000213437553611584\n",
      "Epoch: 65 Iter 799 Train_loss: 0.0001995527563849464\n",
      "Epoch: 65 Iter 819 Train_loss: 0.00019447869271971285\n",
      "Epoch: 65 Iter 839 Train_loss: 0.00019134128524456173\n",
      "Epoch: 65 Iter 859 Train_loss: 0.00021666043903678656\n",
      "Epoch: 65 Iter 879 Train_loss: 0.00021818354434799403\n",
      "Epoch: 65 Iter 899 Train_loss: 0.00023159885313361883\n",
      "Epoch: 65 Iter 919 Train_loss: 0.00018605652439873666\n",
      "Epoch: 65 Iter 939 Train_loss: 0.00022572209127247334\n",
      "Epoch: 65 Iter 959 Train_loss: 0.00020179347484372556\n",
      "Epoch: 65 Iter 979 Train_loss: 0.0002182479074690491\n",
      "Epoch: 65 Iter 999 Train_loss: 0.00022753160737920552\n",
      "Epoch: 65 Iter 1019 Train_loss: 0.0002206345379818231\n",
      "Epoch: 65 Iter 1039 Train_loss: 0.00022672823979519308\n",
      "Epoch: 65 Iter 1059 Train_loss: 0.00020353024592623115\n",
      "[ 65/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch: 66 Iter 19 Train_loss: 0.0002573564706835896\n",
      "Epoch: 66 Iter 39 Train_loss: 0.0002536879328545183\n",
      "Epoch: 66 Iter 59 Train_loss: 0.00018254335736855865\n",
      "Epoch: 66 Iter 79 Train_loss: 0.00019441131735220551\n",
      "Epoch: 66 Iter 99 Train_loss: 0.00018556292343419045\n",
      "Epoch: 66 Iter 119 Train_loss: 0.0001867462560767308\n",
      "Epoch: 66 Iter 139 Train_loss: 0.0001815866125980392\n",
      "Epoch: 66 Iter 159 Train_loss: 0.00021128043590579182\n",
      "Epoch: 66 Iter 179 Train_loss: 0.0002030287723755464\n",
      "Epoch: 66 Iter 199 Train_loss: 0.00017092852795030922\n",
      "Epoch: 66 Iter 219 Train_loss: 0.00020710687385872006\n",
      "Epoch: 66 Iter 239 Train_loss: 0.00022818210709374398\n",
      "Epoch: 66 Iter 259 Train_loss: 0.0001906958787003532\n",
      "Epoch: 66 Iter 279 Train_loss: 0.0002205363562097773\n",
      "Epoch: 66 Iter 299 Train_loss: 0.00019055315351579338\n",
      "Epoch: 66 Iter 319 Train_loss: 0.00019883387722074986\n",
      "Epoch: 66 Iter 339 Train_loss: 0.00018506923515815288\n",
      "Epoch: 66 Iter 359 Train_loss: 0.00022312341025099158\n",
      "Epoch: 66 Iter 379 Train_loss: 0.00017558058607392013\n",
      "Epoch: 66 Iter 399 Train_loss: 0.0001798563462216407\n",
      "Epoch: 66 Iter 419 Train_loss: 0.0002451977925375104\n",
      "Epoch: 66 Iter 439 Train_loss: 0.0001784242340363562\n",
      "Epoch: 66 Iter 459 Train_loss: 0.00021195955923758447\n",
      "Epoch: 66 Iter 479 Train_loss: 0.00018769773305393755\n",
      "Epoch: 66 Iter 499 Train_loss: 0.00019772464293055236\n",
      "Epoch: 66 Iter 519 Train_loss: 0.00019025171059183776\n",
      "Epoch: 66 Iter 539 Train_loss: 0.00019809578952845186\n",
      "Epoch: 66 Iter 559 Train_loss: 0.00017716431466396898\n",
      "Epoch: 66 Iter 579 Train_loss: 0.00021179467148613185\n",
      "Epoch: 66 Iter 599 Train_loss: 0.000193411746295169\n",
      "Epoch: 66 Iter 619 Train_loss: 0.00020056484208907932\n",
      "Epoch: 66 Iter 639 Train_loss: 0.00023233459796756506\n",
      "Epoch: 66 Iter 659 Train_loss: 0.000187516154255718\n",
      "Epoch: 66 Iter 679 Train_loss: 0.00022138073109090328\n",
      "Epoch: 66 Iter 699 Train_loss: 0.00021052385272923857\n",
      "Epoch: 66 Iter 719 Train_loss: 0.00020573748042806983\n",
      "Epoch: 66 Iter 739 Train_loss: 0.00021281803492456675\n",
      "Epoch: 66 Iter 759 Train_loss: 0.0001875825837487355\n",
      "Epoch: 66 Iter 779 Train_loss: 0.00018977237050421536\n",
      "Epoch: 66 Iter 799 Train_loss: 0.00021410538465715945\n",
      "Epoch: 66 Iter 819 Train_loss: 0.00018303263641428202\n",
      "Epoch: 66 Iter 839 Train_loss: 0.00020987799507565796\n",
      "Epoch: 66 Iter 859 Train_loss: 0.0002063906576950103\n",
      "Epoch: 66 Iter 879 Train_loss: 0.00023845450778026134\n",
      "Epoch: 66 Iter 899 Train_loss: 0.00021125953935552388\n",
      "Epoch: 66 Iter 919 Train_loss: 0.00019283805158920586\n",
      "Epoch: 66 Iter 939 Train_loss: 0.00019538648484740406\n",
      "Epoch: 66 Iter 959 Train_loss: 0.00018832676869351417\n",
      "Epoch: 66 Iter 979 Train_loss: 0.00020911800675094128\n",
      "Epoch: 66 Iter 999 Train_loss: 0.00019712973153218627\n",
      "Epoch: 66 Iter 1019 Train_loss: 0.000214244588278234\n",
      "Epoch: 66 Iter 1039 Train_loss: 0.0001940690417541191\n",
      "Epoch: 66 Iter 1059 Train_loss: 0.00021039004786871374\n",
      "[ 66/100]train_loss:0.00021valid_loss:0.00026\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch: 67 Iter 19 Train_loss: 0.0001743952016113326\n",
      "Epoch: 67 Iter 39 Train_loss: 0.0002011876495089382\n",
      "Epoch: 67 Iter 59 Train_loss: 0.0001914926542667672\n",
      "Epoch: 67 Iter 79 Train_loss: 0.00021078583085909486\n",
      "Epoch: 67 Iter 99 Train_loss: 0.00019243216956965625\n",
      "Epoch: 67 Iter 119 Train_loss: 0.00022258485842030495\n",
      "Epoch: 67 Iter 139 Train_loss: 0.00019137669005431235\n",
      "Epoch: 67 Iter 159 Train_loss: 0.00022531575814355165\n",
      "Epoch: 67 Iter 179 Train_loss: 0.00019981799414381385\n",
      "Epoch: 67 Iter 199 Train_loss: 0.0001898729387903586\n",
      "Epoch: 67 Iter 219 Train_loss: 0.0001894720335258171\n",
      "Epoch: 67 Iter 239 Train_loss: 0.00020867491548415273\n",
      "Epoch: 67 Iter 259 Train_loss: 0.00019394993432797492\n",
      "Epoch: 67 Iter 279 Train_loss: 0.00020175582903902978\n",
      "Epoch: 67 Iter 299 Train_loss: 0.00022162191453389823\n",
      "Epoch: 67 Iter 319 Train_loss: 0.00020838802447542548\n",
      "Epoch: 67 Iter 339 Train_loss: 0.000178347181645222\n",
      "Epoch: 67 Iter 359 Train_loss: 0.00020454205514397472\n",
      "Epoch: 67 Iter 379 Train_loss: 0.0001890431303763762\n",
      "Epoch: 67 Iter 399 Train_loss: 0.00017631225637160242\n",
      "Epoch: 67 Iter 419 Train_loss: 0.00018226182146463543\n",
      "Epoch: 67 Iter 439 Train_loss: 0.00021779189410153776\n",
      "Epoch: 67 Iter 459 Train_loss: 0.0002444406854920089\n",
      "Epoch: 67 Iter 479 Train_loss: 0.00017806598043534905\n",
      "Epoch: 67 Iter 499 Train_loss: 0.00018978801381308585\n",
      "Epoch: 67 Iter 519 Train_loss: 0.00018351798644289374\n",
      "Epoch: 67 Iter 539 Train_loss: 0.0002063796273432672\n",
      "Epoch: 67 Iter 559 Train_loss: 0.00024694748572073877\n",
      "Epoch: 67 Iter 579 Train_loss: 0.0002791070146486163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 Iter 599 Train_loss: 0.00019768709898926318\n",
      "Epoch: 67 Iter 619 Train_loss: 0.0001825909421313554\n",
      "Epoch: 67 Iter 639 Train_loss: 0.00023028493160381913\n",
      "Epoch: 67 Iter 659 Train_loss: 0.00024386937730014324\n",
      "Epoch: 67 Iter 679 Train_loss: 0.00020637143461499363\n",
      "Epoch: 67 Iter 699 Train_loss: 0.00024408023455180228\n",
      "Epoch: 67 Iter 719 Train_loss: 0.0002325513050891459\n",
      "Epoch: 67 Iter 739 Train_loss: 0.000205847347388044\n",
      "Epoch: 67 Iter 759 Train_loss: 0.0002164314646506682\n",
      "Epoch: 67 Iter 779 Train_loss: 0.00019289407646283507\n",
      "Epoch: 67 Iter 799 Train_loss: 0.00018748649745248258\n",
      "Epoch: 67 Iter 819 Train_loss: 0.00019262633577454835\n",
      "Epoch: 67 Iter 839 Train_loss: 0.00017212118837051094\n",
      "Epoch: 67 Iter 859 Train_loss: 0.00019388335931580514\n",
      "Epoch: 67 Iter 879 Train_loss: 0.00024716302868910134\n",
      "Epoch: 67 Iter 899 Train_loss: 0.0002109974157065153\n",
      "Epoch: 67 Iter 919 Train_loss: 0.00022160736261866987\n",
      "Epoch: 67 Iter 939 Train_loss: 0.00016169740410987288\n",
      "Epoch: 67 Iter 959 Train_loss: 0.00021745204867329448\n",
      "Epoch: 67 Iter 979 Train_loss: 0.00021702655067201704\n",
      "Epoch: 67 Iter 999 Train_loss: 0.00020129801123403013\n",
      "Epoch: 67 Iter 1019 Train_loss: 0.00022519516642205417\n",
      "Epoch: 67 Iter 1039 Train_loss: 0.00018328068836126477\n",
      "Epoch: 67 Iter 1059 Train_loss: 0.00020196275727357715\n",
      "[ 67/100]train_loss:0.00020valid_loss:0.00026\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch: 68 Iter 19 Train_loss: 0.000179370996193029\n",
      "Epoch: 68 Iter 39 Train_loss: 0.00018949454533867538\n",
      "Epoch: 68 Iter 59 Train_loss: 0.00020817495533265173\n",
      "Epoch: 68 Iter 79 Train_loss: 0.00020238680008333176\n",
      "Epoch: 68 Iter 99 Train_loss: 0.00018060779257211834\n",
      "Epoch: 68 Iter 119 Train_loss: 0.0001951479644048959\n",
      "Epoch: 68 Iter 139 Train_loss: 0.00025462626945227385\n",
      "Epoch: 68 Iter 159 Train_loss: 0.00019643361156340688\n",
      "Epoch: 68 Iter 179 Train_loss: 0.0001889905397547409\n",
      "Epoch: 68 Iter 199 Train_loss: 0.00019885669462382793\n",
      "Epoch: 68 Iter 219 Train_loss: 0.00022569963766727597\n",
      "Epoch: 68 Iter 239 Train_loss: 0.00020558293908834457\n",
      "Epoch: 68 Iter 259 Train_loss: 0.00024004482838790864\n",
      "Epoch: 68 Iter 279 Train_loss: 0.00020351976854726672\n",
      "Epoch: 68 Iter 299 Train_loss: 0.0002054374199360609\n",
      "Epoch: 68 Iter 319 Train_loss: 0.0002044426219072193\n",
      "Epoch: 68 Iter 339 Train_loss: 0.0001920846407301724\n",
      "Epoch: 68 Iter 359 Train_loss: 0.00027865570154972374\n",
      "Epoch: 68 Iter 379 Train_loss: 0.0001924833341035992\n",
      "Epoch: 68 Iter 399 Train_loss: 0.00017592743097338825\n",
      "Epoch: 68 Iter 419 Train_loss: 0.00023443932877853513\n",
      "Epoch: 68 Iter 439 Train_loss: 0.00021610682597383857\n",
      "Epoch: 68 Iter 459 Train_loss: 0.0002424659178359434\n",
      "Epoch: 68 Iter 479 Train_loss: 0.00019396396237425506\n",
      "Epoch: 68 Iter 499 Train_loss: 0.00018784623534884304\n",
      "Epoch: 68 Iter 519 Train_loss: 0.00018045477918349206\n",
      "Epoch: 68 Iter 539 Train_loss: 0.000197347515495494\n",
      "Epoch: 68 Iter 559 Train_loss: 0.00017552330973558128\n",
      "Epoch: 68 Iter 579 Train_loss: 0.00020579335978254676\n",
      "Epoch: 68 Iter 599 Train_loss: 0.0002040153631241992\n",
      "Epoch: 68 Iter 619 Train_loss: 0.0002017935912590474\n",
      "Epoch: 68 Iter 639 Train_loss: 0.00016656734806019813\n",
      "Epoch: 68 Iter 659 Train_loss: 0.00022524148516822606\n",
      "Epoch: 68 Iter 679 Train_loss: 0.0002679211611393839\n",
      "Epoch: 68 Iter 699 Train_loss: 0.00020271021639928222\n",
      "Epoch: 68 Iter 719 Train_loss: 0.00018891575746238232\n",
      "Epoch: 68 Iter 739 Train_loss: 0.00020406364637892693\n",
      "Epoch: 68 Iter 759 Train_loss: 0.000209616802749224\n",
      "Epoch: 68 Iter 779 Train_loss: 0.00022504435037262738\n",
      "Epoch: 68 Iter 799 Train_loss: 0.00020391684665810317\n",
      "Epoch: 68 Iter 819 Train_loss: 0.00021544670744333416\n",
      "Epoch: 68 Iter 839 Train_loss: 0.00019103317754343152\n",
      "Epoch: 68 Iter 859 Train_loss: 0.00015358359087258577\n",
      "Epoch: 68 Iter 879 Train_loss: 0.00021992942492943257\n",
      "Epoch: 68 Iter 899 Train_loss: 0.00019108093692921102\n",
      "Epoch: 68 Iter 919 Train_loss: 0.00020566419698297977\n",
      "Epoch: 68 Iter 939 Train_loss: 0.0002187310456065461\n",
      "Epoch: 68 Iter 959 Train_loss: 0.00030383735429495573\n",
      "Epoch: 68 Iter 979 Train_loss: 0.00019107645493932068\n",
      "Epoch: 68 Iter 999 Train_loss: 0.00020129831682424992\n",
      "Epoch: 68 Iter 1019 Train_loss: 0.00020117199164815247\n",
      "Epoch: 68 Iter 1039 Train_loss: 0.00023580464767292142\n",
      "Epoch: 68 Iter 1059 Train_loss: 0.00019920528575312346\n",
      "[ 68/100]train_loss:0.00020valid_loss:0.00025\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch: 69 Iter 19 Train_loss: 0.00018986289796885103\n",
      "Epoch: 69 Iter 39 Train_loss: 0.00017773777653928846\n",
      "Epoch: 69 Iter 59 Train_loss: 0.00018376662046648562\n",
      "Epoch: 69 Iter 79 Train_loss: 0.0001994177291635424\n",
      "Epoch: 69 Iter 99 Train_loss: 0.00017959398974198848\n",
      "Epoch: 69 Iter 119 Train_loss: 0.00020100598339922726\n",
      "Epoch: 69 Iter 139 Train_loss: 0.0002239452296635136\n",
      "Epoch: 69 Iter 159 Train_loss: 0.00018046620243694633\n",
      "Epoch: 69 Iter 179 Train_loss: 0.00018961640307679772\n",
      "Epoch: 69 Iter 199 Train_loss: 0.00019756646361202002\n",
      "Epoch: 69 Iter 219 Train_loss: 0.0001978729706024751\n",
      "Epoch: 69 Iter 239 Train_loss: 0.0001762525935191661\n",
      "Epoch: 69 Iter 259 Train_loss: 0.0001926666882354766\n",
      "Epoch: 69 Iter 279 Train_loss: 0.0001923145173350349\n",
      "Epoch: 69 Iter 299 Train_loss: 0.00024802814004942775\n",
      "Epoch: 69 Iter 319 Train_loss: 0.00017513967759441584\n",
      "Epoch: 69 Iter 339 Train_loss: 0.0001967569551197812\n",
      "Epoch: 69 Iter 359 Train_loss: 0.0002068421890726313\n",
      "Epoch: 69 Iter 379 Train_loss: 0.0002302562352269888\n",
      "Epoch: 69 Iter 399 Train_loss: 0.00018988426018040627\n",
      "Epoch: 69 Iter 419 Train_loss: 0.00023858239001128823\n",
      "Epoch: 69 Iter 439 Train_loss: 0.00022521619393955916\n",
      "Epoch: 69 Iter 459 Train_loss: 0.0002093005896313116\n",
      "Epoch: 69 Iter 479 Train_loss: 0.00020572605717461556\n",
      "Epoch: 69 Iter 499 Train_loss: 0.00019892830459866673\n",
      "Epoch: 69 Iter 519 Train_loss: 0.0002240595786133781\n",
      "Epoch: 69 Iter 539 Train_loss: 0.000219883891986683\n",
      "Epoch: 69 Iter 559 Train_loss: 0.00018940918380394578\n",
      "Epoch: 69 Iter 579 Train_loss: 0.00025354130775667727\n",
      "Epoch: 69 Iter 599 Train_loss: 0.00020746298832818866\n",
      "Epoch: 69 Iter 619 Train_loss: 0.00021417569951154292\n",
      "Epoch: 69 Iter 639 Train_loss: 0.00019438563322182745\n",
      "Epoch: 69 Iter 659 Train_loss: 0.00020200091239530593\n",
      "Epoch: 69 Iter 679 Train_loss: 0.00026309696841053665\n",
      "Epoch: 69 Iter 699 Train_loss: 0.00021525644115172327\n",
      "Epoch: 69 Iter 719 Train_loss: 0.00021177809685468674\n",
      "Epoch: 69 Iter 739 Train_loss: 0.00022846207139082253\n",
      "Epoch: 69 Iter 759 Train_loss: 0.00018733408069238067\n",
      "Epoch: 69 Iter 779 Train_loss: 0.00019803516624961048\n",
      "Epoch: 69 Iter 799 Train_loss: 0.00018519314471632242\n",
      "Epoch: 69 Iter 819 Train_loss: 0.00023045777925290167\n",
      "Epoch: 69 Iter 839 Train_loss: 0.00019771482038777322\n",
      "Epoch: 69 Iter 859 Train_loss: 0.00019621776300482452\n",
      "Epoch: 69 Iter 879 Train_loss: 0.0001922104856930673\n",
      "Epoch: 69 Iter 899 Train_loss: 0.00019901710038539022\n",
      "Epoch: 69 Iter 919 Train_loss: 0.0002058103127637878\n",
      "Epoch: 69 Iter 939 Train_loss: 0.00020895343914162368\n",
      "Epoch: 69 Iter 959 Train_loss: 0.0002327879483345896\n",
      "Epoch: 69 Iter 979 Train_loss: 0.00020609277999028563\n",
      "Epoch: 69 Iter 999 Train_loss: 0.0002461660769768059\n",
      "Epoch: 69 Iter 1019 Train_loss: 0.00022615787747781724\n",
      "Epoch: 69 Iter 1039 Train_loss: 0.00016617798246443272\n",
      "Epoch: 69 Iter 1059 Train_loss: 0.00020052469335496426\n",
      "[ 69/100]train_loss:0.00020valid_loss:0.00025\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch: 70 Iter 19 Train_loss: 0.00021044463210273534\n",
      "Epoch: 70 Iter 39 Train_loss: 0.0001930564467329532\n",
      "Epoch: 70 Iter 59 Train_loss: 0.00020746092195622623\n",
      "Epoch: 70 Iter 79 Train_loss: 0.00018407324387226254\n",
      "Epoch: 70 Iter 99 Train_loss: 0.00021434167865663767\n",
      "Epoch: 70 Iter 119 Train_loss: 0.00021647554240189493\n",
      "Epoch: 70 Iter 139 Train_loss: 0.0002209329541074112\n",
      "Epoch: 70 Iter 159 Train_loss: 0.00020771499839611351\n",
      "Epoch: 70 Iter 179 Train_loss: 0.0002476742083672434\n",
      "Epoch: 70 Iter 199 Train_loss: 0.00018957664724439383\n",
      "Epoch: 70 Iter 219 Train_loss: 0.00019370003428775817\n",
      "Epoch: 70 Iter 239 Train_loss: 0.00021309577277861536\n",
      "Epoch: 70 Iter 259 Train_loss: 0.00018028513295575976\n",
      "Epoch: 70 Iter 279 Train_loss: 0.00020232149108778685\n",
      "Epoch: 70 Iter 299 Train_loss: 0.00018790480680763721\n",
      "Epoch: 70 Iter 319 Train_loss: 0.00017523662245366722\n",
      "Epoch: 70 Iter 339 Train_loss: 0.00018177150923293084\n",
      "Epoch: 70 Iter 359 Train_loss: 0.00019138454808853567\n",
      "Epoch: 70 Iter 379 Train_loss: 0.00019927161338273436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 Iter 399 Train_loss: 0.00017713778652250767\n",
      "Epoch: 70 Iter 419 Train_loss: 0.000185938406502828\n",
      "Epoch: 70 Iter 439 Train_loss: 0.00020656998094636947\n",
      "Epoch: 70 Iter 459 Train_loss: 0.00018234015442430973\n",
      "Epoch: 70 Iter 479 Train_loss: 0.0002058217505691573\n",
      "Epoch: 70 Iter 499 Train_loss: 0.00021509345970116556\n",
      "Epoch: 70 Iter 519 Train_loss: 0.0002208306541433558\n",
      "Epoch: 70 Iter 539 Train_loss: 0.00019300733401905745\n",
      "Epoch: 70 Iter 559 Train_loss: 0.0001975629711523652\n",
      "Epoch: 70 Iter 579 Train_loss: 0.0002205099444836378\n",
      "Epoch: 70 Iter 599 Train_loss: 0.00019521625654306263\n",
      "Epoch: 70 Iter 619 Train_loss: 0.0001992105826502666\n",
      "Epoch: 70 Iter 639 Train_loss: 0.00019586978305596858\n",
      "Epoch: 70 Iter 659 Train_loss: 0.00017179302813019603\n",
      "Epoch: 70 Iter 679 Train_loss: 0.00018135721620637923\n",
      "Epoch: 70 Iter 699 Train_loss: 0.00021965219639241695\n",
      "Epoch: 70 Iter 719 Train_loss: 0.0001937725319294259\n",
      "Epoch: 70 Iter 739 Train_loss: 0.0001980425586225465\n",
      "Epoch: 70 Iter 759 Train_loss: 0.00019513712322805077\n",
      "Epoch: 70 Iter 779 Train_loss: 0.0002022217377088964\n",
      "Epoch: 70 Iter 799 Train_loss: 0.00020034066983498633\n",
      "Epoch: 70 Iter 819 Train_loss: 0.00029899540822952986\n",
      "Epoch: 70 Iter 839 Train_loss: 0.0001774649426806718\n",
      "Epoch: 70 Iter 859 Train_loss: 0.00019465904915705323\n",
      "Epoch: 70 Iter 879 Train_loss: 0.00020817034237552434\n",
      "Epoch: 70 Iter 899 Train_loss: 0.00019963664817623794\n",
      "Epoch: 70 Iter 919 Train_loss: 0.00021330091112758964\n",
      "Epoch: 70 Iter 939 Train_loss: 0.0002971020876429975\n",
      "Epoch: 70 Iter 959 Train_loss: 0.00018543258192948997\n",
      "Epoch: 70 Iter 979 Train_loss: 0.00019231556507293135\n",
      "Epoch: 70 Iter 999 Train_loss: 0.00020426888659130782\n",
      "Epoch: 70 Iter 1019 Train_loss: 0.0002131933142663911\n",
      "Epoch: 70 Iter 1039 Train_loss: 0.0002072126226266846\n",
      "Epoch: 70 Iter 1059 Train_loss: 0.00021159532479941845\n",
      "[ 70/100]train_loss:0.00020valid_loss:0.00027\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch: 71 Iter 19 Train_loss: 0.0001921805669553578\n",
      "Epoch: 71 Iter 39 Train_loss: 0.0001781362370820716\n",
      "Epoch: 71 Iter 59 Train_loss: 0.0002335648750886321\n",
      "Epoch: 71 Iter 79 Train_loss: 0.00019784928008448333\n",
      "Epoch: 71 Iter 99 Train_loss: 0.0002181111922254786\n",
      "Epoch: 71 Iter 119 Train_loss: 0.00019411658286117017\n",
      "Epoch: 71 Iter 139 Train_loss: 0.00018404974252916873\n",
      "Epoch: 71 Iter 159 Train_loss: 0.00018596889276523143\n",
      "Epoch: 71 Iter 179 Train_loss: 0.00020578263502102345\n",
      "Epoch: 71 Iter 199 Train_loss: 0.0002000620443141088\n",
      "Epoch: 71 Iter 219 Train_loss: 0.00018744048429653049\n",
      "Epoch: 71 Iter 239 Train_loss: 0.00016069553385023028\n",
      "Epoch: 71 Iter 259 Train_loss: 0.00019321576110087335\n",
      "Epoch: 71 Iter 279 Train_loss: 0.00019331635849084705\n",
      "Epoch: 71 Iter 299 Train_loss: 0.00019275567319709808\n",
      "Epoch: 71 Iter 319 Train_loss: 0.00020526522712316364\n",
      "Epoch: 71 Iter 339 Train_loss: 0.00026096258079633117\n",
      "Epoch: 71 Iter 359 Train_loss: 0.00021125095372553915\n",
      "Epoch: 71 Iter 379 Train_loss: 0.00019460667681414634\n",
      "Epoch: 71 Iter 399 Train_loss: 0.0002258828462800011\n",
      "Epoch: 71 Iter 419 Train_loss: 0.00021948636276647449\n",
      "Epoch: 71 Iter 439 Train_loss: 0.00022118522610981017\n",
      "Epoch: 71 Iter 459 Train_loss: 0.00018929051293525845\n",
      "Epoch: 71 Iter 479 Train_loss: 0.00020596709509845823\n",
      "Epoch: 71 Iter 499 Train_loss: 0.00019408660591579974\n",
      "Epoch: 71 Iter 519 Train_loss: 0.00021923509484622627\n",
      "Epoch: 71 Iter 539 Train_loss: 0.00023689692898187786\n",
      "Epoch: 71 Iter 559 Train_loss: 0.00022100719797890633\n",
      "Epoch: 71 Iter 579 Train_loss: 0.0002022971457336098\n",
      "Epoch: 71 Iter 599 Train_loss: 0.00017768846009857953\n",
      "Epoch: 71 Iter 619 Train_loss: 0.0001958819048013538\n",
      "Epoch: 71 Iter 639 Train_loss: 0.0001993034384213388\n",
      "Epoch: 71 Iter 659 Train_loss: 0.00017717313312459737\n",
      "Epoch: 71 Iter 679 Train_loss: 0.00019144204270560294\n",
      "Epoch: 71 Iter 699 Train_loss: 0.00019306792819406837\n",
      "Epoch: 71 Iter 719 Train_loss: 0.0001716810220386833\n",
      "Epoch: 71 Iter 739 Train_loss: 0.0002011357864830643\n",
      "Epoch: 71 Iter 759 Train_loss: 0.00020385169773362577\n",
      "Epoch: 71 Iter 779 Train_loss: 0.000200531430891715\n",
      "Epoch: 71 Iter 799 Train_loss: 0.00020920103997923434\n",
      "Epoch: 71 Iter 819 Train_loss: 0.00019814552797470242\n",
      "Epoch: 71 Iter 839 Train_loss: 0.0002285112568642944\n",
      "Epoch: 71 Iter 859 Train_loss: 0.00020484838751144707\n",
      "Epoch: 71 Iter 879 Train_loss: 0.00019594373588915914\n",
      "Epoch: 71 Iter 899 Train_loss: 0.00020995379600208253\n",
      "Epoch: 71 Iter 919 Train_loss: 0.00020559097174555063\n",
      "Epoch: 71 Iter 939 Train_loss: 0.00021622110216412693\n",
      "Epoch: 71 Iter 959 Train_loss: 0.00020130274060647935\n",
      "Epoch: 71 Iter 979 Train_loss: 0.00021796743385493755\n",
      "Epoch: 71 Iter 999 Train_loss: 0.0002084593434119597\n",
      "Epoch: 71 Iter 1019 Train_loss: 0.00020416703773662448\n",
      "Epoch: 71 Iter 1039 Train_loss: 0.00017855773330666125\n",
      "Epoch: 71 Iter 1059 Train_loss: 0.0002012015029322356\n",
      "[ 71/100]train_loss:0.00020valid_loss:0.00025\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch: 72 Iter 19 Train_loss: 0.00018844586156774312\n",
      "Epoch: 72 Iter 39 Train_loss: 0.00020904181292280555\n",
      "Epoch: 72 Iter 59 Train_loss: 0.0001922146329889074\n",
      "Epoch: 72 Iter 79 Train_loss: 0.00018323645053897053\n",
      "Epoch: 72 Iter 99 Train_loss: 0.00023567212338093668\n",
      "Epoch: 72 Iter 119 Train_loss: 0.00018312984320800751\n",
      "Epoch: 72 Iter 139 Train_loss: 0.00020791760471183807\n",
      "Epoch: 72 Iter 159 Train_loss: 0.00021133865811862051\n",
      "Epoch: 72 Iter 179 Train_loss: 0.0002095479576382786\n",
      "Epoch: 72 Iter 199 Train_loss: 0.00018553240806795657\n",
      "Epoch: 72 Iter 219 Train_loss: 0.0001744481996865943\n",
      "Epoch: 72 Iter 239 Train_loss: 0.00020859477808699012\n",
      "Epoch: 72 Iter 259 Train_loss: 0.0002004964044317603\n",
      "Epoch: 72 Iter 279 Train_loss: 0.00019033114949706942\n",
      "Epoch: 72 Iter 299 Train_loss: 0.00021098932484164834\n",
      "Epoch: 72 Iter 319 Train_loss: 0.00019304548914078623\n",
      "Epoch: 72 Iter 339 Train_loss: 0.0002304070076206699\n",
      "Epoch: 72 Iter 359 Train_loss: 0.00018266623374074697\n",
      "Epoch: 72 Iter 379 Train_loss: 0.0001827559754019603\n",
      "Epoch: 72 Iter 399 Train_loss: 0.00020673325343523175\n",
      "Epoch: 72 Iter 419 Train_loss: 0.00027330589364282787\n",
      "Epoch: 72 Iter 439 Train_loss: 0.00017052450857590884\n",
      "Epoch: 72 Iter 459 Train_loss: 0.0001877241302281618\n",
      "Epoch: 72 Iter 479 Train_loss: 0.00025708304019644856\n",
      "Epoch: 72 Iter 499 Train_loss: 0.00023382509243674576\n",
      "Epoch: 72 Iter 519 Train_loss: 0.0001832769630709663\n",
      "Epoch: 72 Iter 539 Train_loss: 0.00020375539315864444\n",
      "Epoch: 72 Iter 559 Train_loss: 0.00022191416064742953\n",
      "Epoch: 72 Iter 579 Train_loss: 0.00023736512230243534\n",
      "Epoch: 72 Iter 599 Train_loss: 0.00021253686281852424\n",
      "Epoch: 72 Iter 619 Train_loss: 0.00023365177912637591\n",
      "Epoch: 72 Iter 639 Train_loss: 0.00018338378868065774\n",
      "Epoch: 72 Iter 659 Train_loss: 0.00023543664428871125\n",
      "Epoch: 72 Iter 679 Train_loss: 0.00019347186025697738\n",
      "Epoch: 72 Iter 699 Train_loss: 0.00016377853171434253\n",
      "Epoch: 72 Iter 719 Train_loss: 0.00020606910402420908\n",
      "Epoch: 72 Iter 739 Train_loss: 0.0001869675179477781\n",
      "Epoch: 72 Iter 759 Train_loss: 0.00021551160898525268\n",
      "Epoch: 72 Iter 779 Train_loss: 0.0002028898015851155\n",
      "Epoch: 72 Iter 799 Train_loss: 0.00020666497584898025\n",
      "Epoch: 72 Iter 819 Train_loss: 0.0002325034438399598\n",
      "Epoch: 72 Iter 839 Train_loss: 0.00020849000429734588\n",
      "Epoch: 72 Iter 859 Train_loss: 0.00019215894280932844\n",
      "Epoch: 72 Iter 879 Train_loss: 0.000196062566828914\n",
      "Epoch: 72 Iter 899 Train_loss: 0.00020516884978860617\n",
      "Epoch: 72 Iter 919 Train_loss: 0.00023518697707913816\n",
      "Epoch: 72 Iter 939 Train_loss: 0.00024134156410582364\n",
      "Epoch: 72 Iter 959 Train_loss: 0.00024784510605968535\n",
      "Epoch: 72 Iter 979 Train_loss: 0.00022289699700195342\n",
      "Epoch: 72 Iter 999 Train_loss: 0.00021354401542339474\n",
      "Epoch: 72 Iter 1019 Train_loss: 0.00020636533736251295\n",
      "Epoch: 72 Iter 1039 Train_loss: 0.0001996250794036314\n",
      "Epoch: 72 Iter 1059 Train_loss: 0.0001793627452570945\n",
      "[ 72/100]train_loss:0.00020valid_loss:0.00026\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch: 73 Iter 19 Train_loss: 0.0002039388637058437\n",
      "Epoch: 73 Iter 39 Train_loss: 0.00020714600395876914\n",
      "Epoch: 73 Iter 59 Train_loss: 0.00021956699492875487\n",
      "Epoch: 73 Iter 79 Train_loss: 0.0001869903499027714\n",
      "Epoch: 73 Iter 99 Train_loss: 0.00017815733735915273\n",
      "Epoch: 73 Iter 119 Train_loss: 0.0001865907688625157\n",
      "Epoch: 73 Iter 139 Train_loss: 0.00020295989816077054\n",
      "Epoch: 73 Iter 159 Train_loss: 0.000258888874668628\n",
      "Epoch: 73 Iter 179 Train_loss: 0.00020764980581589043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 Iter 199 Train_loss: 0.00018566740618553013\n",
      "Epoch: 73 Iter 219 Train_loss: 0.00019144799443893135\n",
      "Epoch: 73 Iter 239 Train_loss: 0.0002036505757132545\n",
      "Epoch: 73 Iter 259 Train_loss: 0.00018393952632322907\n",
      "Epoch: 73 Iter 279 Train_loss: 0.000217105116462335\n",
      "Epoch: 73 Iter 299 Train_loss: 0.00021415830997284502\n",
      "Epoch: 73 Iter 319 Train_loss: 0.00023402526858262718\n",
      "Epoch: 73 Iter 339 Train_loss: 0.00022540183272212744\n",
      "Epoch: 73 Iter 359 Train_loss: 0.00019176524074282497\n",
      "Epoch: 73 Iter 379 Train_loss: 0.00018405802256893367\n",
      "Epoch: 73 Iter 399 Train_loss: 0.0002487029996700585\n",
      "Epoch: 73 Iter 419 Train_loss: 0.000220115456613712\n",
      "Epoch: 73 Iter 439 Train_loss: 0.0003181002102792263\n",
      "Epoch: 73 Iter 459 Train_loss: 0.0001921240909723565\n",
      "Epoch: 73 Iter 479 Train_loss: 0.00019197077199351043\n",
      "Epoch: 73 Iter 499 Train_loss: 0.00018875008390750736\n",
      "Epoch: 73 Iter 519 Train_loss: 0.00018685820396058261\n",
      "Epoch: 73 Iter 539 Train_loss: 0.00019013034761883318\n",
      "Epoch: 73 Iter 559 Train_loss: 0.00018923054449260235\n",
      "Epoch: 73 Iter 579 Train_loss: 0.00020966226293239743\n",
      "Epoch: 73 Iter 599 Train_loss: 0.0001900869101518765\n",
      "Epoch: 73 Iter 619 Train_loss: 0.00019575213082134724\n",
      "Epoch: 73 Iter 639 Train_loss: 0.00022745545720681548\n",
      "Epoch: 73 Iter 659 Train_loss: 0.00019376439740881324\n",
      "Epoch: 73 Iter 679 Train_loss: 0.00023740410688333213\n",
      "Epoch: 73 Iter 699 Train_loss: 0.00021658625337295234\n",
      "Epoch: 73 Iter 719 Train_loss: 0.00018834254296962172\n",
      "Epoch: 73 Iter 739 Train_loss: 0.0001992888719541952\n",
      "Epoch: 73 Iter 759 Train_loss: 0.00019141248776577413\n",
      "Epoch: 73 Iter 779 Train_loss: 0.0001877194008557126\n",
      "Epoch: 73 Iter 799 Train_loss: 0.00019291733042337\n",
      "Epoch: 73 Iter 819 Train_loss: 0.00019053011783398688\n",
      "Epoch: 73 Iter 839 Train_loss: 0.00019069436530116946\n",
      "Epoch: 73 Iter 859 Train_loss: 0.00022156648628879339\n",
      "Epoch: 73 Iter 879 Train_loss: 0.000219553112401627\n",
      "Epoch: 73 Iter 899 Train_loss: 0.00023825942480470985\n",
      "Epoch: 73 Iter 919 Train_loss: 0.0002369542489759624\n",
      "Epoch: 73 Iter 939 Train_loss: 0.0002518171677365899\n",
      "Epoch: 73 Iter 959 Train_loss: 0.00017947315063793212\n",
      "Epoch: 73 Iter 979 Train_loss: 0.00022639604867435992\n",
      "Epoch: 73 Iter 999 Train_loss: 0.00018368441669736058\n",
      "Epoch: 73 Iter 1019 Train_loss: 0.00019335241813678294\n",
      "Epoch: 73 Iter 1039 Train_loss: 0.00019708192849066108\n",
      "Epoch: 73 Iter 1059 Train_loss: 0.00019327341578900814\n",
      "[ 73/100]train_loss:0.00020valid_loss:0.00025\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch: 74 Iter 19 Train_loss: 0.00025715911760926247\n",
      "Epoch: 74 Iter 39 Train_loss: 0.00021307369752321392\n",
      "Epoch: 74 Iter 59 Train_loss: 0.00021869043121114373\n",
      "Epoch: 74 Iter 79 Train_loss: 0.0001991366152651608\n",
      "Epoch: 74 Iter 99 Train_loss: 0.0002389498840784654\n",
      "Epoch: 74 Iter 119 Train_loss: 0.0001817832817323506\n",
      "Epoch: 74 Iter 139 Train_loss: 0.00019906550005543977\n",
      "Epoch: 74 Iter 159 Train_loss: 0.00018531965906731784\n",
      "Epoch: 74 Iter 179 Train_loss: 0.00024351217143703252\n",
      "Epoch: 74 Iter 199 Train_loss: 0.00019385649648029357\n",
      "Epoch: 74 Iter 219 Train_loss: 0.00017394918540958315\n",
      "Epoch: 74 Iter 239 Train_loss: 0.000251698395004496\n",
      "Epoch: 74 Iter 259 Train_loss: 0.0002474168431945145\n",
      "Epoch: 74 Iter 279 Train_loss: 0.00019723315199371427\n",
      "Epoch: 74 Iter 299 Train_loss: 0.0002290405536768958\n",
      "Epoch: 74 Iter 319 Train_loss: 0.00017395276518072933\n",
      "Epoch: 74 Iter 339 Train_loss: 0.00018267205450683832\n",
      "Epoch: 74 Iter 359 Train_loss: 0.00018863342120312154\n",
      "Epoch: 74 Iter 379 Train_loss: 0.0002030560135608539\n",
      "Epoch: 74 Iter 399 Train_loss: 0.00023415262694470584\n",
      "Epoch: 74 Iter 419 Train_loss: 0.00022852836991660297\n",
      "Epoch: 74 Iter 439 Train_loss: 0.00020847660198342055\n",
      "Epoch: 74 Iter 459 Train_loss: 0.00017817872867453843\n",
      "Epoch: 74 Iter 479 Train_loss: 0.00018477911362424493\n",
      "Epoch: 74 Iter 499 Train_loss: 0.0001879009505501017\n",
      "Epoch: 74 Iter 519 Train_loss: 0.00018603814532980323\n",
      "Epoch: 74 Iter 539 Train_loss: 0.00021693846792913973\n",
      "Epoch: 74 Iter 559 Train_loss: 0.00023621844593435526\n",
      "Epoch: 74 Iter 579 Train_loss: 0.00018723182438407093\n",
      "Epoch: 74 Iter 599 Train_loss: 0.00019957443873863667\n",
      "Epoch: 74 Iter 619 Train_loss: 0.0002483493590261787\n",
      "Epoch: 74 Iter 639 Train_loss: 0.0001989838492590934\n",
      "Epoch: 74 Iter 659 Train_loss: 0.0001868576800916344\n",
      "Epoch: 74 Iter 679 Train_loss: 0.0001996002101805061\n",
      "Epoch: 74 Iter 699 Train_loss: 0.00018530290981289\n",
      "Epoch: 74 Iter 719 Train_loss: 0.00017133349319919944\n",
      "Epoch: 74 Iter 739 Train_loss: 0.00024232665600720793\n",
      "Epoch: 74 Iter 759 Train_loss: 0.00019381828315090388\n",
      "Epoch: 74 Iter 779 Train_loss: 0.00023105967557057738\n",
      "Epoch: 74 Iter 799 Train_loss: 0.0001984092523343861\n",
      "Epoch: 74 Iter 819 Train_loss: 0.00021277624182403088\n",
      "Epoch: 74 Iter 839 Train_loss: 0.00020450030569918454\n",
      "Epoch: 74 Iter 859 Train_loss: 0.0002684005885384977\n",
      "Epoch: 74 Iter 879 Train_loss: 0.0001809084351407364\n",
      "Epoch: 74 Iter 899 Train_loss: 0.00020117407257203013\n",
      "Epoch: 74 Iter 919 Train_loss: 0.00019383332983125\n",
      "Epoch: 74 Iter 939 Train_loss: 0.00020037958165630698\n",
      "Epoch: 74 Iter 959 Train_loss: 0.00023635603429283947\n",
      "Epoch: 74 Iter 979 Train_loss: 0.0002085819432977587\n",
      "Epoch: 74 Iter 999 Train_loss: 0.00018867471953853965\n",
      "Epoch: 74 Iter 1019 Train_loss: 0.000214723200770095\n",
      "Epoch: 74 Iter 1039 Train_loss: 0.00021926074987277389\n",
      "Epoch: 74 Iter 1059 Train_loss: 0.0001920526847243309\n",
      "[ 74/100]train_loss:0.00020valid_loss:0.00025\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "def to_variable(x, requires_grad = True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, requires_grad)\n",
    "\n",
    "\"\"\"\n",
    "if os.path.exists(history_file):\n",
    "    checkpoint = torch.load(history_file)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print('load epoch {} successfully'.format(start_epoch))\n",
    "    \n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('no saved model, train from scratch')\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (img, real_video) in enumerate(dataloader_train):\n",
    "        #print('Epoch:{} | num:{} | data_shape:{} | label_shape:{}'.format(epoch,i,data.size(),label.size()))\n",
    "        \n",
    "        img = Variable(img).cuda().float()\n",
    "        #label = torch.squeeze(label)\n",
    "        real_video = Variable(real_video).cuda().float()\n",
    "        #print('real_img_shape{}'.format(real_img.size()))\n",
    "        real_label = to_variable(torch.LongTensor(np.ones(batchSize, dtype = int)), requires_grad = False)\n",
    "        fake_label = to_variable(torch.LongTensor(np.zeros(batchSize, dtype = int)), requires_grad = False)\n",
    "        \n",
    "        # Discriminator train \n",
    "        real_out = D(real_video)\n",
    "        d_loss_real = criterion(real_out, real_label)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_video = G(img).detach()\n",
    "        fake_out = D(fake_video)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Generator train \n",
    "        fake_video = G(img)\n",
    "        output = D(fake_video)\n",
    "        g_mse_loss = nn.MSELoss(fake_video, real_video)*10\n",
    "        g_loss = criterion(output, real_label) + g_mse_loss\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "              \n",
    "        train_losses.append(g_loss.item())\n",
    "        if (i+1) % 20 == 0:\n",
    "            print('Epoch:', epoch, 'Iter', i, 'Train_loss:', loss.item())\n",
    "\n",
    "    #evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (img, real_video) in enumerate(dataloader_valid):\n",
    "            img = Variable(img).cuda().float()\n",
    "            #label = torch.squeeze(label)\n",
    "            real_video = Variable(real_video).cuda().float()\n",
    "            fake_video = G(img)\n",
    "            output = D(fake_video)\n",
    "            #pred = torch.squeeze(pred)\n",
    "            g_mse_loss = nn.MSELoss(fake_video, real_video)*10\n",
    "            g_val_loss = criterion(output, real_label) + g_mse_loss\n",
    " \n",
    "            valid_losses.append(g_val_loss.item())\n",
    "\n",
    "    train_loss = np.average(train_losses)\n",
    "    valid_loss = np.average(valid_losses)\n",
    "    \n",
    "    #last_train_losses.append(train_loss[-1])\n",
    "    avg_train_losses.append(train_loss)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "    \n",
    "    epoch_len = len(str(epochs))\n",
    "    print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}]'+\n",
    "                f'train_loss:{train_loss:.5f}'+\n",
    "                f'valid_loss:{valid_loss:.5f}')\n",
    "    \n",
    "    print(print_msg)\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    early_stopping(valid_loss, G)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    state = {'model':G.state_dict(), 'optimizer':g_optimizer.state_dict(), 'epoch':epoch}\n",
    "    torch.save(state, history_file)\n",
    "    #torch.save(model.state_dict(), model_output_path+'epoch_%d.pth'%(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1,len(avg_train_losses)+1),avg_train_losses, 'bo', label='Training Loss')\n",
    "plt.plot(range(1,len(avg_valid_losses)+1),avg_valid_losses, 'b', label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = avg_valid_losses.index(min(avg_valid_losses))+1\n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 0.001) # consistent scale\n",
    "plt.xlim(0, len(avg_valid_losses)+1) # consistent scale\n",
    "\n",
    "my_x_ticks = np.arange(0, len(avg_valid_losses)+1, 5)\n",
    "plt.xticks(my_x_ticks)\n",
    "\n",
    "#plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot_GAN.jpg', nbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "tensor([0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def to_variable(x, requires_grad = True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, requires_grad)\n",
    "\n",
    "batchSize = 6\n",
    "real_label = to_variable(torch.LongTensor(np.ones(batchSize, dtype = int)), requires_grad = False)\n",
    "fake_label = to_variable(torch.LongTensor(np.zeros(batchSize, dtype = int)), requires_grad = False)\n",
    "print(real_label.size())\n",
    "print(fake_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
